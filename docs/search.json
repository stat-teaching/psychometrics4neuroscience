[
  {
    "objectID": "teamworks/03-meta-analysis/03-meta-analysis.html",
    "href": "teamworks/03-meta-analysis/03-meta-analysis.html",
    "title": "Lavoro di Gruppo 3 - Metanalisi",
    "section": "",
    "text": "Dataset\nQuesto lavoro di gruppo richiede di effettuare una metanalisi su un dataset che raccoglie diversi studi di efficacia della psicoterapia cognitivo-comportamentale per i disturbi d’ansia. In questo caso per una tipologia specifica di disturbi d’ansia ovvero l’ansia sociale.\n\nAnsia sociale (o fobia sociale) è un disturbo d’ansia caratterizzato da una paura intensa e persistente di essere giudicati negativamente o di sentirsi in imbarazzo in situazioni sociali o prestazionali. Le persone con ansia sociale tendono a evitare queste situazioni o le affrontano con notevole disagio, compromettendo la qualità della vita e il funzionamento quotidiano (American Psychiatric Association, 2013).\n\nIl dataset si trova nella repository principale del corso dentro la cartella teamworks/03-meta-analysis/social-anxiety-psychotherapy.csv.\n\ndat &lt;- read.csv(\"social-anxiety-psychotherapy.csv\")\nhead(dat)\n\n  id            paper    g   se year   n recruitment           format\n1  1 Abramowitz, 2009 0.54 0.39 2009  21   Community Guided Self-Help\n2  2   Anderson, 2013 0.73 0.23 2013  67   Community    Group Therapy\n3  3   Anderson, 2013 0.64 0.24 2013  58   Community            Mixed\n4  4  Andersson, 2006 0.64 0.21 2006  64   Community            Mixed\n5  5  Andersson, 2012 0.73 0.12 2012 204   Community Guided Self-Help\n6  6     Beidel, 2014 1.11 0.25 2014  60       Other       Individual\n           intervention_type control_type p_women sessions       country\n1 Cognitive Behavior Therapy     Waitlist     76%        8 North America\n2 Cognitive Behavior Therapy     Waitlist     62%        8 North America\n3 Cognitive Behavior Therapy     Waitlist     62%        8 North America\n4 Cognitive Behavior Therapy     Waitlist     52%       11        Europe\n5 Cognitive Behavior Therapy     Waitlist     60%        9        Europe\n6                   Exposure     Waitlist     52%       24 North America\n  age_group mean_age     risk_bias\n1    Adults       43 Some concerns\n2    Adults       39          High\n3    Adults       39          High\n4    Adults       37 Some concerns\n5    Adults       38 Some concerns\n6    Adults       36          High\n\n\nLe variabili sono le seguenti:\n\nid: identificativo dell’effetto\npaper: identificativo del paper\ng: effect size (Hedges’s \\(g\\))\nse: effect size standard error\nyear: anno di pubblicazione\nn: sample size\nrecruitement: luogo di reclutamente dei pazienti/controlli\nformat: modalità di psicoterapia\nintervention_type: tipo di psicoterapia\ncontrol_tupe: tipologia di gruppo di controllo\np_women: percentuale di donne nel campione\nsessions: numero di sessioni di psicoterapia\ncountry: dove è stato eseguito lo studio\nage_group: categoria d’età\nmean_age: età media del campione\nrisk_bias: livello di rischio che quello studio abbia delle problematiche che potrebbero influenzare i risultati\n\n\n\nSteps\nGli step da eseguire sono i seguenti:\n\ndescrizione dettagliata del dataset in modo discorsivo con statistiche descrittive e grafici adeguati ad ogni tipo di variabile\neffettuare la metanalisi usando diversi modelli e confrontando i risultati.\n\nmodello a due livelli random-effects e fixed-effects\nmodello a due livelli random-effects e fixed-effects aggregando gli effetti nello stesso paper. Si veda il capitolo borenstein-aggregation.pdf ed implementare manualmente la formula adeguata.\nmodello a tre livelli per gestire la struttura nested dei dati\n\nvalutare e commentare l’effetto dei moderatori e se possibile della loro interazione sia per il modello a due livelli che quello a tre livelli\nvalutare il publication bias usando tutti i metodi che sono stati presentati a lezione. Per quanto riguarda i selection models scegliere almeno 3 modelli diversi e confrontare i risultati.\nprodurre grafici e tabelle per ogni risultato. in particolare:\n\nriprodurre i forest plot e funnel plot usando ggplot2 (senza usare pacchetti aggiuntivi) che siano più simili possibili a quelli di metafor\nprodurre dei grafici per l’effetto dei moderatori che rappresentino i risultati in modo adeguato\nprodurre delle tabelle che rappresentino i risultati in modo adeguato. Utilizzare il pacchetto e la modalità che si preferisce.\n\nimplementare senza utilizzare pacchetti aggiuntivi un test di permutazione per il modello random-effects a due livelli per l’effetto generale\nvalutare per il modello a due livelli random-effects (senza aggregare) l’impatto dei singoli paper con una leave-one-out analysis con relativa rappresentazione grafica\n\n\n\nAspetti generali\n\nOgni step deve essere accompagnato da una spiegazione narrativa e dove pertinente da rappresentazioni grafiche e tabelle che spieghino in maniera chiara i risultati\nTutti gli step devono essere prodotti in un documento Quarto (html o pdf) riproducibile e self-contained\nChi vuole può preparare una presentazione in Quarto da utilizzare durante l’esame"
  },
  {
    "objectID": "teamworks/01-power-simulation/01-power-simulation.html",
    "href": "teamworks/01-power-simulation/01-power-simulation.html",
    "title": "Lavoro di Gruppo 1 - Simulazione Monte Carlo",
    "section": "",
    "text": "Descrizione\nQuesto lavoro di gruppo richiede di effettuare una design analysis per un esperimento in Psicologia. Un gruppo di ricercatori è interessato a testare l’accuratezza per l’elaborazione di volti con espressione facciale in gruppi clinici e di controllo. L’idea di ricerca riguarda il fatto che in alcuni disturbi psicologici come i disturbi d’ansia ci sia un’elaborazione diversa di stimoli a valenza negativa. In questo caso i ricercatori vogliono confrontare soggetti con e senza disturbo d’ansia nell’elaborazione di volti con espressione facciale negativa (rabbia) e neutra.\nL’ipotesi principale riguarda un’accuratezza maggiore nei soggetti ansiosi rispetto a soggetti non ansiosi solo nel caso di volti con espressione di rabbia. L’ipotesi è rappresentata in Figura 1. Chiaramente i valori effettivi variano in base agli scenari di simulazione. Per semplificare il disegno di simulazione si può assumere a zero la differenza tra gruppi nella condizione di volti neutri.\nOltre all’ipotesi principale i ricercatori vogliono raccogliere le seguenti covariate che dovranno essere inserite nella simulazione e nel modello ma senza essere variate nei vari scenari di simulazione:\n\nsesso: i ricercatori si aspettano in base alla letteratura un’accuratezza maggiore (effetto piccolo) globale nei soggetti di sesso femminile\nla percentuale di soggetti di sesso femminile globale è dell’80%\netà: l’età è distribuita in modo uniforme tra 20 e 40 anni. Inoltre l’accuratezza globale diminuisce leggermente (un massimo di 5-10% per il range di età) al crescere dell’età\n\nLa simulazione deve mostrare la potenza statistica nei vari scenari con l’idea sia di avere un quadro completo che sapere quanti soggetti/trial raccogliere per avere una potenza di circa 80%.\n\nlibrary(ggplot2)\n\ndd &lt;- expand.grid(\n    face = c(\"Neutral\", \"Anger\"),\n    group = c(\"Control\", \"Anxiety\")\n) \n\ndd$p &lt;- c(0.55, 0.65, 0.55, 0.8)\ndd$face &lt;- factor(dd$face, levels = c(\"Neutral\", \"Anger\"))    \n    \nggplot(dd, aes(x = face, y = p, color = group)) +\n    geom_line(aes(group = group)) +\n    geom_point() +\n    ylim(c(0.4, 1))\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\nvalutare il modello più adeguato per questo tipo di dati e giustificare chiaramente il motivo.\ni ricercatori spesso non sanno che anche il numero di trials può aumentare la potenza fissando il numero di soggetti. Trovare un modo chiaro ma formalmente corretto di spiegare questo punto usando grafici, piccole simulazioni, etc.\ndefinire valori plausibili per i parametri\n\ncoefficienti fissi dell’esperimento (gruppo ed emozione) e covariate\ncoefficienti random (quali è plausibile ipotizzare?)\n\neffetturare la simulazione in diversi scenari plausibili variando:\n\neffect size: piccolo, medio e grande\nnumbero di soggetti e numero di trials per soggetto\nvariabilità tra soggetti negli effetti fissi (i.e., effetti random): bassa e media\n\nrispetto al numero di simulazione, scegliere un numero secondo voi adeguato cercando di giustificarlo adeguatamente\nrappresentare graficamente i risultati delle varie simulazioni commentando i risultati in modo critico. considerare il bilanciamento tra soggetti e trials.\nI ricercatori in psicologia sono abituati ad usare i modelli lineari (t-test, ANOVA, etc.) a prescindere dal tipo di variabile. Questo può creare dei bias nelle stime oppure portare a vere e proprie conclusioni erronee. Fare una ulteriore simulazione per dimostrare quali possono essere i problemi nell’utilizzare un modello lineare e non un GLM per questo tipo di dati. Per questa simulazione si possono omettere le covariate e concentrarsi sulle ipotesi sperimentale. Mostrare almeno una problematica. Suggerimento: valutare gli errori di primo tipo per interazioni testate con modelli lineari quando i dati non rispettano queste assunzioni (come in questo caso).\n\n\n\nSuggerimenti\nSolitamente i ricercatori in psicologia ragionano con effect sizes standardizzati (e.g., Cohen’s \\(d\\), standardized mean difference). Provare ad impostare i parametri del modello riguardo le ipotesi sperimentali convertendoli da valori di Cohen’s \\(d\\). Si veda ad esempio Sánchez-Meca, Marín-Martínez, and Chacón-Moscoso (2003).\n\n\nAspetti generali\n\nOgni step deve essere accompagnato da una spiegazione narrativa e dove pertinente da rappresentazioni grafiche e tabelle che spieghino in maniera chiara i risultati\nTutti gli step devono essere prodotti in un documento Quarto (html o pdf) riproducibile e self-contained\nChi vuole può preparare una presentazione in Quarto da utilizzare durante l’esame\nSi faccia particolare attenzione a scrivere codice leggibile, efficiente e che gestisca adeguatamente errori di convergenza e problematiche varie nella simulazione. Cercare di velocizzare il più possibile la simulazione trovando varie strategie online. Per ogni simulazione salvare anche il tempo di computazione.\n\n\n\n\n\n\nReferences\n\nSánchez-Meca, Julio, Fulgencio Marín-Martínez, and Salvador Chacón-Moscoso. 2003. “Effect-Size Indices for Dichotomized Outcomes in Meta-Analysis.” Psychological Methods 8 (December): 448–67. https://doi.org/10.1037/1082-989X.8.4.448."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell",
    "title": "Power analysis",
    "section": "Power in a nutshell1",
    "text": "Power in a nutshell1\nThe stastistical power is defined as the probability of correctly rejecting the null hypothesis \\(H_0\\).\n\n\n\n\n\n\n\n\n\nThanks to https://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell-1",
    "title": "Power analysis",
    "section": "Power in a nutshell",
    "text": "Power in a nutshell\nFor simple designs such as t-test, ANOVA, etc. the power can be computed analytically. For example, let’s find the power of detecting an effect size of \\(d = 0.5\\) with \\(n1 = n2 = 30\\).\n\nd &lt;- 0.5\nalpha &lt;- 0.05\nn1 &lt;- n2 &lt;- 30\nsp &lt;- 1\n\n# Calculate non-centrality parameter (delta)\ndelta &lt;- d * sqrt(n1 * n2 / (n1 + n2))\n\n# Calculate degrees of freedom\ndf &lt;- n1 + n2 - 2\n\n# Calculate critical t-value\ncritical_t &lt;- qt(1 - alpha / 2, df)\n\n# Calculate non-central t-distribution value\nnon_central_t &lt;- delta / sp\n\n# Calculate power\n1 - pt(critical_t - non_central_t, df)\n#&gt; [1] 0.4741093"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell-2",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell-2",
    "title": "Power analysis",
    "section": "Power in a nutshell",
    "text": "Power in a nutshell\nThe same can be done using the pwr package:\n\npower &lt;- pwr::pwr.t.test(n = n1, d = 0.5)\npower\n#&gt; \n#&gt;      Two-sample t test power calculation \n#&gt; \n#&gt;               n = 30\n#&gt;               d = 0.5\n#&gt;       sig.level = 0.05\n#&gt;           power = 0.4778965\n#&gt;     alternative = two.sided\n#&gt; \n#&gt; NOTE: n is number in *each* group"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell-3",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-in-a-nutshell-3",
    "title": "Power analysis",
    "section": "Power in a nutshell",
    "text": "Power in a nutshell\n\nplot(power)"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-by-simulations",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-by-simulations",
    "title": "Power analysis",
    "section": "Power by simulations",
    "text": "Power by simulations\nSometimes the analytical solution is not available or we can estimate the power for complex scenarios (missing data, unequal variances, etc.). The general workflow is:\n\nGenerate data under the parametric assumptions\nFit the appropriate model\nExtract the relevant metric (e.g., p-value)\nRepeat 1-3 several times (1000, 10000 or more)\nSummarise the results\n\nFor example, the power is the number of p-values lower than \\(\\alpha\\) over the total number of simulations."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-by-simulations-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-by-simulations-1",
    "title": "Power analysis",
    "section": "Power by simulations",
    "text": "Power by simulations\nLet’s see the previous example using simulations:\n\nnsim &lt;- 5000\np &lt;- rep(NA, nsim)\nfor(i in 1:nsim){\n    g1 &lt;- rnorm(n1, 0, 1)\n    g2 &lt;- rnorm(n2, d, 1)\n    p[i] &lt;- t.test(g1, g2)$p.value\n}\nmean(p &lt;= alpha)\n#&gt; [1] 0.4842\n\nThe estimated value is pretty close to the analytical value."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#what-about-meta-analysis",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#what-about-meta-analysis",
    "title": "Power analysis",
    "section": "What about meta-analysis",
    "text": "What about meta-analysis\nAlso for meta-analysis we have the two approaches analytical and simulation-based.\n\nThe analytical approach for (intercept-only) random-effects and equal-effects model can be found on Borenstein et al. (2009) (Chapter 29). See also Valentine, Pigott, and Rothstein (2010) and L. V. Hedges and Pigott (2001)\nJackson and Turner (2017) proposed a similar but improved approach"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach",
    "title": "Power analysis",
    "section": "Analytical approach",
    "text": "Analytical approach\nFor the analytical approach we need to make some assumptions:\n\n\\(\\tau^2\\) and \\(\\mu_{\\theta}\\) (or \\(\\theta\\)) are estimated without errors\nThe \\(\\sigma^2_i\\) (thus the sample size) of each \\(k\\) study is the same\n\nUnder these assumptions the power is:\n\\[\n(1 - \\Phi(c_{\\alpha} - \\lambda)) + \\Phi(-c_{\\alpha} - \\lambda)\n\\]\nWhere \\(c_{\\alpha}\\) is the critical \\(z\\) value and \\(\\lambda\\) is the observed statistics."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---ee-model",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---ee-model",
    "title": "Power analysis",
    "section": "Analytical approach - EE model",
    "text": "Analytical approach - EE model\nFor an EE model the only source of variability is the sampling variability, thus \\(\\lambda\\):\n\\[\n\\lambda_{EE} = \\frac{\\theta}{\\sqrt{\\sigma^2_{\\theta}}}\n\\]\nAnd recalling previous assuptions where \\(\\sigma^2_1 = \\dots = \\sigma^2_k\\):\n\\[\n\\sigma^2_{\\theta} = \\frac{\\sigma^2}{k}\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---ee-model-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---ee-model-1",
    "title": "Power analysis",
    "section": "Analytical approach - EE model",
    "text": "Analytical approach - EE model\nFor example, a meta-analysis of \\(k = 15\\) studies where each study have a sample size of \\(n1 = n2 = 20\\) (assuming again unstandardized mean difference as effect size):\n\nk &lt;- 10\ntheta &lt;- 0.3\nn1 &lt;- n2 &lt;- 25\nvt &lt;- 1/n1 + 1/n2\nvtheta &lt;- vt/k\nlambda &lt;- theta/sqrt(vtheta)\nzcrit &lt;- abs(qnorm(0.05/2))\n(1 - pnorm(zcrit - lambda)) + pnorm(-zcrit - lambda)\n#&gt; [1] 0.9183621\n\nBe careful that the EE model is assuming \\(\\tau^2 = 0\\) thus is like having a huge study with \\(k \\times n_1\\) participants per group."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---re-model",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---re-model",
    "title": "Power analysis",
    "section": "Analytical approach - RE model",
    "text": "Analytical approach - RE model\nFor the RE model we just need to include \\(\\tau^2\\) in the \\(\\lambda\\) calculation, thus:\n\\[\n\\sigma^{2\\star}_{\\theta} = \\frac{\\sigma^2 + \\tau^2}{k}\n\\]\nThe other calculations are the same as the EE model."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---re-model-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---re-model-1",
    "title": "Power analysis",
    "section": "Analytical approach - RE model",
    "text": "Analytical approach - RE model\n\nk &lt;- 10\nmu &lt;- 0.3\ntau2 &lt;- 0.1\nn1 &lt;- n2 &lt;- 25\nvt &lt;- 1/n1 + 1/n2\nvtheta &lt;- (vt + tau2)/k\nlambda &lt;- mu/sqrt(vtheta)\nzcrit &lt;- abs(qnorm(0.05/2))\n(1 - pnorm(zcrit - lambda)) + pnorm(-zcrit - lambda)\n#&gt; [1] 0.6087795\n\nThe power is reduced because we are considering another source of heterogeneity. Clearly the maximal power of \\(k\\) studies is achieved when \\(\\tau^2 = 0\\). Hypothetically we can increase the power either increasing \\(k\\) (the number of studies) or reducing \\(\\sigma^2_k\\) (increasing the number of participants in each study)."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---power-curves",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---power-curves",
    "title": "Power analysis",
    "section": "Analytical approach - Power curves",
    "text": "Analytical approach - Power curves\nThe most informative approach is plotting the power curves for different values of \\(\\tau^2\\), \\(\\sigma^2_k\\) and \\(\\theta\\) (or \\(\\mu_{\\theta}\\)).\nYou can use the power_meta() function:\npower_meta &lt;- function(es, k, tau2 = 0, n1, n2 = NULL, alpha = 0.05){\n  if(is.null(n2)) n2 &lt;- n1\n  zc &lt;- qnorm(1 - alpha/2)\n  vt &lt;- 1/n1 + 1/n2\n  ves &lt;- (vt + tau2)/k\n  lambda &lt;- es/sqrt(ves)\n  (1 - pnorm(zc - lambda)) + pnorm(-zc - lambda)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---power-curves-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---power-curves-1",
    "title": "Power analysis",
    "section": "Analytical approach - Power curves",
    "text": "Analytical approach - Power curves\n\n\nCode\nk &lt;- c(5, 10, 30, 50, 100)\nes &lt;- c(0.1, 0.3)\ntau2 &lt;- c(0, 0.05, 0.1, 0.2)\nn &lt;- c(10, 30, 50, 100, 1000)\n\npower &lt;- expand_grid(es, k, tau2, n1 = n)\npower$power &lt;- power_meta(power$es, power$k, power$tau2, power$n1)\n\npower$es &lt;- factor(power$es, labels = latex2exp::TeX(sprintf(\"$\\\\mu_{\\\\theta} = %s$\", es)))\npower$tau2 &lt;- factor(power$tau2, labels = latex2exp::TeX(sprintf(\"$\\\\tau^2 = %s$\", tau2)))\n\nggplot(power, aes(x = factor(k), y = power, color = factor(n1))) +\n  geom_point() +\n  geom_line(aes(group = factor(n1))) +\n  facet_grid(es~tau2, labeller = label_parsed) +\n  xlab(\"Number of Studies (k)\") +\n  ylab(\"Power\") +\n  labs(\n    color = latex2exp::TeX(\"$n_1 = n_2$\")\n  )"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---power-curves-2",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#analytical-approach---power-curves-2",
    "title": "Power analysis",
    "section": "Analytical approach - Power curves",
    "text": "Analytical approach - Power curves\nWith the analytical approach we can (quickly) do interesting stuff. For example, we fix the total \\(N = n_1 + n_2\\) for a series of \\(k\\) and check the power.\n\n\nCode\n# average meta k = 20, n = 30\nkavg &lt;- 20\nnavg &lt;- 30\nN &lt;- kavg * (navg*2)\nes &lt;- 0.3\ntau2 &lt;- c(0, 0.05, 0.1, 0.2)\nk &lt;- seq(10, 100, 10)\nn1 &lt;- n2 &lt;- round((N/k)/ 2)\n\nsim &lt;- data.frame(es, k, n1, n2)\nsim &lt;- expand_grid(sim, tau2 = tau2)\nsim$power &lt;- power_meta(sim$es, sim$k, sim$tau2, sim$n1, sim$n2)\nsim$N &lt;- with(sim, k * (n1 + n2))\n\nggplot(sim, aes(x = k, y = power, color = factor(tau2))) +\n  geom_line() +\n  ggtitle(latex2exp::TeX(\"Total N ($n_1 + n_2$) = 1200\")) +\n  labs(x = \"Number of Studies (k)\",\n       y = \"Power\",\n       color = latex2exp::TeX(\"$\\\\tau^2$\"))\n\n\n\nAs long as \\(\\tau^2 \\neq 0\\) we need more studies (even if the total sample size is the same)."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#simulation-based-power",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#simulation-based-power",
    "title": "Power analysis",
    "section": "Simulation-based power",
    "text": "Simulation-based power\nWith simulations we can fix or relax the previous assumptions. For example, let’s compute the power for an EE model:\n\nk &lt;- 10\nes &lt;- 0.3\ntau2 &lt;- 0\nn1 &lt;- n2 &lt;- rep(25, k)\nnsim &lt;- 1000 # more is better\npval &lt;- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  dat &lt;- sim_studies(k, es, tau2, n1, n2)\n  fit &lt;- rma(yi, vi, data = dat, method = \"EE\")\n  pval[i] &lt;- fit$pval\n}\n\nmean(pval &lt;= 0.05)\n#&gt; [1] 0.924\n\nThe value is similar to the analytical simulation. But we can improve it e.g. generating heterogeneous sample sizes."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#simulation-based-power-curve",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#simulation-based-power-curve",
    "title": "Power analysis",
    "section": "Simulation-based power curve",
    "text": "Simulation-based power curve\nBy repeating the previous approach for a series of parameters we can easily draw a power curve:\n\nk &lt;- c(5, 10, 50, 100)\nes &lt;- 0.1\ntau2 &lt;- c(0, 0.05, 0.1, 0.2)\nnsim &lt;- 1000\n\ngrid &lt;- expand_grid(k, es, tau2)\npower &lt;- rep(NA, nrow(grid))\n\nfor(i in 1:nrow(grid)){\n  pval &lt;- rep(NA, nsim)\n  for(j in 1:nsim){\n    n &lt;- rpois(grid$k[i], 40)\n    dat &lt;- sim_studies(grid$k[i], grid$es[i], grid$tau2[i], n)\n    fit &lt;- rma(yi, vi, data = dat)\n    pval[j] &lt;- fit$pval\n  }\n  power[i] &lt;- mean(pval &lt;= 0.05)\n}\ngrid$power &lt;- power"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#simulation-based-power-curve-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#simulation-based-power-curve-1",
    "title": "Power analysis",
    "section": "Simulation-based power curve",
    "text": "Simulation-based power curve\n\n\nCode\nggplot(grid, aes(x = factor(k), y = power, color = factor(tau2))) +\n  geom_point() +\n  geom_line(aes(group = factor(tau2))) +\n  labs(\n    y = \"Power\",\n    x = \"Number of studies (k)\",\n    color = latex2exp::TeX(\"$\\\\tau^2$\")\n  )"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-analysis-for-meta-regression",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-analysis-for-meta-regression",
    "title": "Power analysis",
    "section": "Power analysis for meta-regression",
    "text": "Power analysis for meta-regression\nThe power for a meta-regression can be easily computed by simulating the moderator effect. For example, let’s simulate the effect of a binary predictor \\(x\\).\n\nk &lt;- seq(10, 100, 10)\nb0 &lt;- 0.2 # average of group 1\nb1 &lt;- 0.1 # difference between group 1 and 2\ntau2r &lt;- 0.2 # residual tau2\nnsim &lt;- 1000\npower &lt;- rep(NA, length(k))\n\nfor(i in 1:length(k)){\n  es &lt;- b0 + b1 * rep(0:1, each = k[i]/2)\n  pval &lt;- rep(NA, nsim)\n  for(j in 1:nsim){\n    n &lt;- round(runif(k[i], 10, 100))\n    dat &lt;- sim_studies(k[i], es, tau2r, n)\n    fit &lt;- rma(yi, vi, data = dat)\n    pval[j] &lt;- fit$pval\n  }\n  power[i] &lt;- mean(pval &lt;= 0.05)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-analysis-for-meta-regression-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#power-analysis-for-meta-regression-1",
    "title": "Power analysis",
    "section": "Power analysis for meta-regression",
    "text": "Power analysis for meta-regression\nThen we can plot the results:\n\n\nCode\npower &lt;- data.frame(k = k, power = power)\nggplot(power, aes(x = k, y = power)) +\n  geom_line()"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#multilab-studies-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#multilab-studies-1",
    "title": "Power analysis",
    "section": "Multilab studies",
    "text": "Multilab studies\nMultilab studies can be seen as a meta-analysis that is planned (a prospective meta-analysis) compared to standard retrospective meta-analysis.\nThe statistical approach is (roughly) the same with the difference that we have control both on \\(k\\) (the number of experimental units) and \\(n\\) the sample size within each unit.\nIn multilab studies we have also the raw data (i.e., participant-level data) thus we can do more complex multilevel modeling."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel model",
    "text": "Meta-analysis as multilevel model\nAssuming that we have \\(k\\) studies with raw data available there is no need to aggregate, calculate the effect size and variances and then use an EE or RE model.\n\nk &lt;- 50\nes &lt;- 0.4\ntau2 &lt;- 0.1\nn &lt;- round(runif(k, 10, 100))\ndat &lt;- vector(mode = \"list\", k)\nthetai &lt;- rnorm(k, 0, sqrt(tau2))\n\nfor(i in 1:k){\n  g1 &lt;- rnorm(n[i], 0, 1)\n  g2 &lt;- rnorm(n[i], es + thetai[i], 1)\n  d &lt;- data.frame(id = 1:(n[i]*2), unit = i, y = c(g1, g2), group = rep(c(0, 1), each = n[i]))\n  dat[[i]] &lt;- d\n}\n\ndat &lt;- do.call(rbind, dat)\nht(dat)\n#&gt;      id unit          y group\n#&gt; 1     1    1 -0.4359058     0\n#&gt; 2     2    1  1.5799758     0\n#&gt; 3     3    1  0.7015053     0\n#&gt; 4     4    1  0.1376932     0\n#&gt; 5     5    1 -1.7018263     0\n#&gt; 5257 63   50  1.0430772     1\n#&gt; 5258 64   50 -0.7878105     1\n#&gt; 5259 65   50 -0.4609004     1\n#&gt; 5260 66   50  1.5076526     1\n#&gt; 5261 67   50  0.9963187     1\n#&gt; 5262 68   50 -0.2518844     1"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-1",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel model",
    "text": "Meta-analysis as multilevel model\nThis is a simple multilevel model (pupils within classrooms or trials within participants). We can fit the model using lme4::lmer():\n\nlibrary(lme4)\nfit_lme &lt;- lmer(y ~ group + (1|unit), data = dat)\nsummary(fit_lme)\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ group + (1 | unit)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: 15282.1\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.6473 -0.6764  0.0169  0.6663  3.5499 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  unit     (Intercept) 0.03605  0.1899  \n#&gt;  Residual             1.05226  1.0258  \n#&gt; Number of obs: 5262, groups:  unit, 50\n#&gt; \n#&gt; Fixed effects:\n#&gt;              Estimate Std. Error t value\n#&gt; (Intercept) 0.0006038  0.0341201   0.018\n#&gt; group       0.3992543  0.0282823  14.117\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;       (Intr)\n#&gt; group -0.414"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-2",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-2",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel model",
    "text": "Meta-analysis as multilevel model\nLet’s do the same as a meta-analysis. Firstly we compute the effect sizes for each unit:\n\ndatagg &lt;- dat |&gt; \n  group_by(unit, group) |&gt; \n  summarise(m = mean(y),\n            sd = sd(y),\n            n = n()) |&gt; \n  pivot_wider(names_from = group, values_from = c(m, sd, n), names_sep = \"\")\n\ndatagg &lt;- escalc(\"MD\", m1i = m1, m2i = m0, sd1i = sd1, sd2i = sd0, n1i = n1, n2i = n0, data = datagg)"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-3",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-3",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel model",
    "text": "Meta-analysis as multilevel model\n\nht(datagg)\n#&gt; \n#&gt;    unit           m0          m1       sd0       sd1 n0 n1      yi     vi \n#&gt; 1     1 -0.067197098  0.40582612 0.9304467 1.0147085 42 42  0.4730 0.0451 \n#&gt; 2     2 -0.091403369 -0.39447251 1.1524521 1.0145999 22 22 -0.3031 0.1072 \n#&gt; 3     3 -0.003808028  0.16236294 0.9414775 0.7959424 20 20  0.1662 0.0760 \n#&gt; 4     4  0.074297764  0.14426023 0.9656452 1.0081848 97 97  0.0700 0.0201 \n#&gt; 5     5 -0.068813812  0.26518665 0.9798539 1.1045266 26 26  0.3340 0.0838 \n#&gt; 45   45 -0.030328846  0.18885527 0.9490194 1.0119891 96 96  0.2192 0.0200 \n#&gt; 46   46  0.076619304  0.24552547 1.0223705 0.8317036 37 37  0.1689 0.0469 \n#&gt; 47   47 -0.123421255  0.80612492 0.8958121 1.2418829 41 41  0.9295 0.0572 \n#&gt; 48   48 -0.012340409 -0.27712644 1.0127637 0.9681938 85 85 -0.2648 0.0231 \n#&gt; 49   49  0.351899444 -0.08890696 0.9262625 1.0037785 46 46 -0.4408 0.0406 \n#&gt; 50   50 -0.231551420  0.21903620 1.1221262 0.9182845 34 34  0.4506 0.0618"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-4",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-model-4",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel model",
    "text": "Meta-analysis as multilevel model\nThen we can fit the model:\n\nfit_rma &lt;- rma(yi, vi, data = datagg)\nfit_rma\n#&gt; \n#&gt; Random-Effects Model (k = 50; tau^2 estimator: REML)\n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.1623 (SE = 0.0419)\n#&gt; tau (square root of estimated tau^2 value):      0.4028\n#&gt; I^2 (total heterogeneity / total variability):   81.04%\n#&gt; H^2 (total variability / sampling variability):  5.28\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 49) = 260.7313, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt;   0.3711  0.0647  5.7356  &lt;.0001  0.2443  0.4979  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-modeling",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-modeling",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel modeling",
    "text": "Meta-analysis as multilevel modeling\nActually the results are very similar where the standard deviation of the intercepts of the lme4 model is \\(\\approx \\tau\\) and the group effect is the intercept of the rma model.\n\ndata.frame(\n  b = c(fixef(fit_lme)[2], fit_rma$b),\n  se = c(summary(fit_lme)$coefficients[2, 2], fit_rma$se),\n  tau2 = c(as.numeric(VarCorr(fit_lme)[[1]]), fit_rma$tau2),\n  model = c(\"lme4\", \"metafor\")\n)\n#&gt;               b         se       tau2   model\n#&gt; group 0.3992543 0.02828232 0.03604771    lme4\n#&gt;       0.3710964 0.06470033 0.16226242 metafor\n\nActually the two model are not exactly the same, especially when using only the aggregated data. See https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-modeling-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#meta-analysis-as-multilevel-modeling-1",
    "title": "Power analysis",
    "section": "Meta-analysis as multilevel modeling",
    "text": "Meta-analysis as multilevel modeling\nTo note, aggregating data and then computing a standard (non-weighted) model (sometimes this is done with trial-level data) is wrong and should be avoided. Using meta-analysis is clear that aggregating without taking into account the cluster (e.g., study or subject) precision is misleading.\n\ndataggl &lt;- datagg |&gt; \n  select(unit, m0, m1) |&gt;\n  pivot_longer(c(m0, m1), values_to = \"y\", names_to = \"group\")\n\nsummary(lmer(y ~ group + (1|unit), data = dataggl))\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ group + (1 | unit)\n#&gt;    Data: dataggl\n#&gt; \n#&gt; REML criterion at convergence: 63.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.5460 -0.5662 -0.1141  0.4252  4.0163 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  unit     (Intercept) 0.0000   0.0000  \n#&gt;  Residual             0.1034   0.3215  \n#&gt; Number of obs: 100, groups:  unit, 50\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept) 0.009959   0.045473   0.219\n#&gt; groupm1     0.365573   0.064309   5.685\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;         (Intr)\n#&gt; groupm1 -0.707\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#mulitlab-sample-size-vs-unit",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#mulitlab-sample-size-vs-unit",
    "title": "Power analysis",
    "section": "Mulitlab sample size vs unit",
    "text": "Mulitlab sample size vs unit\nWhen planning a multilab study there is an important decision between increasing the sample size within each unit (more effort for each lab) or recruiting more units with less participants per unit (more effort for the organization).\nWe could have the situation where the number of units \\(k\\) is fixed and we can only increase the sample size.\nWe can also simulate scenarios where some units collect all data while others did not complete the data collection."
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#fixed-k-increasing-n",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#fixed-k-increasing-n",
    "title": "Power analysis",
    "section": "Fixed \\(k\\), increasing \\(n\\)",
    "text": "Fixed \\(k\\), increasing \\(n\\)\nLet’s assume that the maximum number of labs is \\(10\\). How many participants are required assuming a certain amount of heterogeneity?\n\nes &lt;- 0.2\nk &lt;- 10\nn1 &lt;- n2 &lt;- seq(10, 500, 10)\ntau2 &lt;- c(0.01, 0.05, 0.1, 0.2)\nsim &lt;- expand_grid(k, es, tau2, n1)\nsim$n2 &lt;- sim$n1\nsim$vt &lt;- with(sim, 1/n1 + 1/n2)\nsim$I2 &lt;- round(with(sim, tau2 / (tau2 + vt)) * 100, 3)\nsim$power &lt;- power_meta(sim$es, sim$k, sim$tau2, sim$n1, sim$n2)\n\nht(sim)\n#&gt; # A tibble: 11 × 8\n#&gt;        k    es  tau2    n1    n2      vt    I2 power\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1    10   0.2  0.01    10    10 0.2      4.76 0.281\n#&gt;  2    10   0.2  0.01    20    20 0.1      9.09 0.479\n#&gt;  3    10   0.2  0.01    30    30 0.0667  13.0  0.627\n#&gt;  4    10   0.2  0.01    40    40 0.05    16.7  0.733\n#&gt;  5    10   0.2  0.01    50    50 0.04    20    0.807\n#&gt;  6    10   0.2  0.2    450   450 0.00444 97.8  0.288\n#&gt;  7    10   0.2  0.2    460   460 0.00435 97.9  0.288\n#&gt;  8    10   0.2  0.2    470   470 0.00426 97.9  0.288\n#&gt;  9    10   0.2  0.2    480   480 0.00417 98.0  0.288\n#&gt; 10    10   0.2  0.2    490   490 0.00408 98    0.288\n#&gt; 11    10   0.2  0.2    500   500 0.004   98.0  0.288"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#fixed-k-increasing-n-1",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#fixed-k-increasing-n-1",
    "title": "Power analysis",
    "section": "Fixed \\(k\\), increasing \\(n\\)",
    "text": "Fixed \\(k\\), increasing \\(n\\)\nWith a fixed \\(k\\), we could reach a plateau even increasing \\(n\\). This depends also on \\(\\mu_{\\theta}\\) and \\(\\tau^2\\).\n\nggplot(sim, aes(x = n1, y = power, color = factor(tau2))) +\n  geom_line() +\n  labs(\n    y = \"Power\",\n    x = \"N per group\",\n    color = latex2exp::TeX(\"$\\\\tau^2$\")\n  )"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#multilab-replication-studies",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#multilab-replication-studies",
    "title": "Power analysis",
    "section": "Multilab replication studies",
    "text": "Multilab replication studies\nA special type of multilab studies are the replication projects. There are some paper discussing how to view replication studies as meta-analyses and how to plan them.\n\nLarry V. Hedges and Schauer (2021)\nJacob M. Schauer (2022)\nJacob M. Schauer and Hedges (2020)\nJ. M. Schauer and Hedges (2021)\nJacob M. Schauer (2023)\nLarry V. Hedges and Schauer (2019)"
  },
  {
    "objectID": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#references",
    "href": "slides/06-meta-analysis/06-power-analysis/power-analysis.html#references",
    "title": "Power analysis",
    "section": "References",
    "text": "References\n\n\nBorenstein, Michael, Larry V Hedges, Julian P T Higgins, and Hannah R Rothstein. 2009. “Introduction to Meta-Analysis.” https://doi.org/10.1002/9780470743386.\n\n\nHedges, L V, and T D Pigott. 2001. “The Power of Statistical Tests in Meta-Analysis.” Psychological Methods 6 (September): 203–17. https://www.ncbi.nlm.nih.gov/pubmed/11570228.\n\n\nHedges, Larry V, and Jacob M Schauer. 2019. “Statistical Analyses for Studying Replication: Meta-Analytic Perspectives.” Psychological Methods 24 (October): 557–70. https://doi.org/10.1037/met0000189.\n\n\n———. 2021. “The Design of Replication Studies.” Journal of the Royal Statistical Society. Series A, (Statistics in Society) 184 (July): 868–86. https://doi.org/10.1111/rssa.12688.\n\n\nJackson, Dan, and Rebecca Turner. 2017. “Power Analysis for Random-Effects Meta-Analysis.” Research Synthesis Methods 8 (September): 290–302. https://doi.org/10.1002/jrsm.1240.\n\n\nSchauer, J M, and L V Hedges. 2021. “Reconsidering Statistical Methods for Assessing Replication.” Psychological Methods 26 (February): 127–39. https://doi.org/10.1037/met0000302.\n\n\nSchauer, Jacob M. 2022. “Replicability and Meta-Analysis.” In Avoiding Questionable Research Practices in Applied Psychology, edited by William O’Donohue, Akihiko Masuda, and Scott Lilienfeld, 301–42. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-04968-2_14.\n\n\n———. 2023. “On the Accuracy of Replication Failure Rates.” Multivariate Behavioral Research 58 (May): 598–615. https://doi.org/10.1080/00273171.2022.2066500.\n\n\nSchauer, Jacob M, and Larry V Hedges. 2020. “Assessing Heterogeneity and Power in Replications of Psychological Experiments.” Psychological Bulletin 146 (August): 701–19. https://doi.org/10.1037/bul0000232.\n\n\nValentine, Jeffrey C, Therese D Pigott, and Hannah R Rothstein. 2010. “How Many Studies Do You Need?: A Primer on Statistical Power for Meta-Analysis.” Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association 35 (April): 215–47. https://doi.org/10.3102/1076998609346961."
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#ma-as-weighted-linear-regression",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#ma-as-weighted-linear-regression",
    "title": "Meta-regression",
    "section": "MA as (weighted) linear regression",
    "text": "MA as (weighted) linear regression\nBoth the EE and RE model can be seen as standard (weighted) linear regression models. Precisely, there is a difference in fitting a meta-analysis using lm or lme4::lmer() and rma (see https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer).\n\nBeyond these differences a general the EE and RE models are intercept-only linear regressions.\n\\[\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\nThe EE model:\n\\[\ny_i = \\beta_0 + \\epsilon_i\n\\]\nThe RE model:\n\\[\ny_i = \\beta_0 + \\beta_{0_i} + \\epsilon_i\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#ma-as-weighted-linear-regression-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#ma-as-weighted-linear-regression-1",
    "title": "Meta-regression",
    "section": "MA as (weighted) linear regression",
    "text": "MA as (weighted) linear regression\nIn the EE model \\(\\beta_0\\) is \\(\\theta\\) and \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)\\)\n\\[\ny_i = \\beta_0 + \\epsilon_i\n\\]\nIn the RE model \\(\\beta_0\\) is \\(\\mu_{\\theta}\\) and \\(\\beta_{0_i}\\) are the \\(\\delta_i\\)."
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2",
    "title": "Meta-regression",
    "section": "Explaining \\(\\tau^2\\)",
    "text": "Explaining \\(\\tau^2\\)\nSo far we simply assumed \\(\\tau^2 = 0\\) (for the EE model) or estimated it using the RE model.\n\nWe can extend the intercept-only meta-analysis by including study-level predictors (as in standard linear regression) to explain the estimated true heterogeneity."
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2-1",
    "title": "Meta-regression",
    "section": "Explaining \\(\\tau^2\\)",
    "text": "Explaining \\(\\tau^2\\)\nLet’s make an example where we simulate a meta-analysis with \\(k = 100\\) studies. Beyond the effect size, we extracted an experimental condition where 50 studies where lab-based experiments \\(x_{lab}\\) and 50 studies where online experiments.\nWe assume that there could be a lab effect thus we included a predictor in the model.\n\nk &lt;- 100\nn &lt;- 10 + rpois(k, 40 - 10)\nexp &lt;- rep(c(\"lab\", \"online\"), each = k/2)"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2-2",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2-2",
    "title": "Meta-regression",
    "section": "Explaining \\(\\tau^2\\)",
    "text": "Explaining \\(\\tau^2\\)\nNow the model have a predictor \\(x\\) (the type of experiment) and two parameters \\(\\beta_0\\) and \\(\\beta_1\\). Depending on the contrast coding (default to contr.treatment() in R) the \\(\\beta_0\\) is different. Coding exp as 0 for lab-based experiments and 1 for online experiments:\n\\[\ny_i = \\beta_0 + \\beta_1X_{1_i} + \\epsilon_i\n\\]\n\\[\ny_{\\text{lab}_i} = \\beta_0 + \\epsilon_i\n\\]\n\\[\ny_{\\text{online}_i} = \\beta_0 + \\beta_1 + \\epsilon_i\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2-3",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#explaining-tau2-3",
    "title": "Meta-regression",
    "section": "Explaining \\(\\tau^2\\)",
    "text": "Explaining \\(\\tau^2\\)\nWhat is missing is the random-effect. Basically we still have \\(\\tau^2\\) determining the \\(\\delta_i \\sim \\mathcal{N}(0, \\tau^2)\\) but now is the residual \\(\\tau^2_r\\). The heterogeneity after including the predictor.\n\\[\ny_i = \\beta_0 + \\beta_{0_i} + \\beta_1X_{1_i} + \\epsilon_i\n\\tag{1}\\]\n\\[\n\\beta_{0_i} \\sim \\mathcal{N}(0, \\tau^2_r)\n\\]\nClearly the difference between \\(\\tau^2\\) (the total heterogeneity) and \\(\\tau^2_r\\) (residual heterogeneity) is an index of the impact of \\(X\\)."
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#simulating-the-x-effect",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#simulating-the-x-effect",
    "title": "Meta-regression",
    "section": "Simulating the \\(X\\) effect",
    "text": "Simulating the \\(X\\) effect\nTo simulate a meta-regression we just need to choose the parameters values (\\(\\beta_0\\) and \\(\\beta_1\\)) and implement Equation 1. Using treatment coding, \\(\\beta_0\\) is the effect size when \\(X = 0\\) (i.e., lab-based experiments) and \\(\\beta_1\\) is the difference between lab and online experiments.\n\nb0 &lt;- 0.3 # lab-based effect size\nb1 &lt;- 0.5 # online - lab-based --&gt; online = b0 + b1\nexp_dummy &lt;- ifelse(exp == \"lab\", 0, 1) # dummy version\nes &lt;- b0 + b1 * exp_dummy\nht(data.frame(exp, exp_dummy, es))\n#&gt;        exp exp_dummy  es\n#&gt; 1      lab         0 0.3\n#&gt; 2      lab         0 0.3\n#&gt; 3      lab         0 0.3\n#&gt; 4      lab         0 0.3\n#&gt; 5      lab         0 0.3\n#&gt; 95  online         1 0.8\n#&gt; 96  online         1 0.8\n#&gt; 97  online         1 0.8\n#&gt; 98  online         1 0.8\n#&gt; 99  online         1 0.8\n#&gt; 100 online         1 0.8"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#simulating-the-x-effects",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#simulating-the-x-effects",
    "title": "Meta-regression",
    "section": "Simulating the \\(X\\) effects",
    "text": "Simulating the \\(X\\) effects\nNow we can use the sim_studies() function as usual. The difference is that es is no longer a single value but a vector (with different values according to the \\(X\\) level) and tau2 is \\(\\tau^2_r\\) (this the leftover heterogeneity after including the \\(X\\) effect)\n\ntau2r &lt;- 0.05 # residual heterogeneity\ndat &lt;- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(exp = exp))\nht(dat)\n#&gt; \n#&gt;      id      yi     vi n1 n2    exp \n#&gt; 1     1  0.4809 0.0504 36 36    lab \n#&gt; 2     2  0.2216 0.0385 46 46    lab \n#&gt; 3     3  0.6249 0.0733 29 29    lab \n#&gt; 4     4  0.3596 0.0484 36 36    lab \n#&gt; 5     5 -0.3642 0.0353 60 60    lab \n#&gt; 95   95  0.2620 0.0439 41 41 online \n#&gt; 96   96  0.7063 0.0661 35 35 online \n#&gt; 97   97  0.2812 0.0549 36 36 online \n#&gt; 98   98  0.7043 0.0537 41 41 online \n#&gt; 99   99  0.6778 0.0582 37 37 online \n#&gt; 100 100  0.6097 0.0550 35 35 online"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#fitting-a-meta-regression-model",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#fitting-a-meta-regression-model",
    "title": "Meta-regression",
    "section": "Fitting a meta-regression Model",
    "text": "Fitting a meta-regression Model\nTo fit a meta-regression we still use the metafor::rma() function, adding the mods = ~ parameter with the model formula (same as the right-hand side of a y ~ x call in lm). The name of the predictor in the formula need to match a column of the data = dataframe.\n\nfit &lt;- rma(yi, vi, mods = ~ exp, data = dat, method = \"REML\")\nsummary(fit)\n#&gt; \n#&gt; Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#&gt; \n#&gt;   logLik  deviance       AIC       BIC      AICc   \n#&gt; -20.2793   40.5587   46.5587   54.3136   46.8140   \n#&gt; \n#&gt; tau^2 (estimated amount of residual heterogeneity):     0.0369 (SE = 0.0126)\n#&gt; tau (square root of estimated tau^2 value):             0.1922\n#&gt; I^2 (residual heterogeneity / unaccounted variability): 41.96%\n#&gt; H^2 (unaccounted variability / sampling variability):   1.72\n#&gt; R^2 (amount of heterogeneity accounted for):            66.76%\n#&gt; \n#&gt; Test for Residual Heterogeneity:\n#&gt; QE(df = 98) = 168.1380, p-val &lt; .0001\n#&gt; \n#&gt; Test of Moderators (coefficient 2):\n#&gt; QM(df = 1) = 84.6513, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt;            estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt; intrcpt      0.2357  0.0420  5.6173  &lt;.0001  0.1535  0.3180  *** \n#&gt; exponline    0.5488  0.0596  9.2006  &lt;.0001  0.4319  0.6657  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#intepreting-a-meta-regression-model",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#intepreting-a-meta-regression-model",
    "title": "Meta-regression",
    "section": "Intepreting a meta-regression Model",
    "text": "Intepreting a meta-regression Model\nThe output is similar to the RE model with few additions:\n\nEverything related to the heterogeneity (\\(H^2\\), \\(I^2\\), \\(Q\\), etc.) is now about residual heterogeneity\nThere is the (pseudo) \\(R^2\\)\nThere is an overall test for the moderators \\(Q_M\\)\nThere is a section (similar to standard regression models) with the estimated parameters, standard error and Wald test"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#model-parameters",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#model-parameters",
    "title": "Meta-regression",
    "section": "Model parameters",
    "text": "Model parameters\nintrcpt and exponline are the estimates of \\(\\beta_0\\) and \\(\\beta_1\\). The interpretation depends on the scale of the effect size and the contrast coding.\nWe can plot the model results using the metafor::regplot()1.\n\nregplot(fit)\n\n\n\n\n\n\n\n\nThe functions is made for numerical variables thus is less appropriate for categorical variables"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#omnibus-moderator-test",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#omnibus-moderator-test",
    "title": "Meta-regression",
    "section": "Omnibus Moderator Test",
    "text": "Omnibus Moderator Test\nThe Test of Moderators section report the so-called omnibus test for model coeffiecients. Is a simultaneous test for 1 or more coefficients where \\(H_0: \\beta_j = 0\\).\nIn this case, coefficient 2 means that we are testing only the 2nd coefficient \\(\\beta_1\\). By default, the intercept is ignored. In fact, the exponline line and the omnibus test are the same (the \\(\\chi^2\\) is just the \\(z^2\\))\n\n#&gt; Test of Moderators (coefficient 2):\n#&gt; QM(df = 1) = 84.6513, p-val &lt; .0001\n#&gt;            estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt; intrcpt      0.2357  0.0420  5.6173  &lt;.0001  0.1535  0.3180  *** \n#&gt; exponline    0.5488  0.0596  9.2006  &lt;.0001  0.4319  0.6657  ***"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht",
    "title": "Meta-regression",
    "section": "General Linear Hypotheses Testing (GLHT)",
    "text": "General Linear Hypotheses Testing (GLHT)\nWe can also test any combination of parameters. For example we could test if lab-based experiments and online experiments are both different from 0. This is the same as fitting a model without the intercept1 thus estimating the cell means (see Schad et al. 2020).\n\n# now we are testing two coefficients\nfit_no_int &lt;- rma(yi, vi, mods = ~ 0 + exp, data = dat)\n\nsee https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept on removing the intercept"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht-1",
    "title": "Meta-regression",
    "section": "General Linear Hypotheses Testing (GLHT)",
    "text": "General Linear Hypotheses Testing (GLHT)\n\nfit_no_int\n#&gt; \n#&gt; Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#&gt; \n#&gt; tau^2 (estimated amount of residual heterogeneity):     0.0369 (SE = 0.0126)\n#&gt; tau (square root of estimated tau^2 value):             0.1922\n#&gt; I^2 (residual heterogeneity / unaccounted variability): 41.96%\n#&gt; H^2 (unaccounted variability / sampling variability):   1.72\n#&gt; \n#&gt; Test for Residual Heterogeneity:\n#&gt; QE(df = 98) = 168.1380, p-val &lt; .0001\n#&gt; \n#&gt; Test of Moderators (coefficients 1:2):\n#&gt; QM(df = 2) = 374.2227, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt;            estimate      se     zval    pval   ci.lb   ci.ub      \n#&gt; explab       0.2357  0.0420   5.6173  &lt;.0001  0.1535  0.3180  *** \n#&gt; exponline    0.7845  0.0424  18.5113  &lt;.0001  0.7014  0.8676  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht-2",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht-2",
    "title": "Meta-regression",
    "section": "General Linear Hypotheses Testing (GLHT)",
    "text": "General Linear Hypotheses Testing (GLHT)\nA more elegant way is by using the GLHT framework. Basically we provide a contrast matrix expressing linear combinations of model parameters to be tested. In our case \\(\\text{lab} = \\beta_0 = 0\\) and \\(\\text{online} = \\beta_0 + \\beta_1 = 0\\).\nPractically, the matrix formulation is the following:\n\\[\n\\begin{pmatrix}  \n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}  \n\\beta_0\\\\\n\\beta_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}  \n0\\\\\n0\n\\end{pmatrix}\n\\]\nIn R:\n\nC &lt;- rbind(c(1, 0), c(1, 1))\nB &lt;- coef(fit)\nC %*% B # same as coef(fit)[1] and coef(fit)[1] +  coef(fit)[2]\n#&gt;           [,1]\n#&gt; [1,] 0.2357498\n#&gt; [2,] 0.7845130"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht-3",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#general-linear-hypotheses-testing-glht-3",
    "title": "Meta-regression",
    "section": "General Linear Hypotheses Testing (GLHT)",
    "text": "General Linear Hypotheses Testing (GLHT)\nWe can use the anova() function providing the model and the hypothesis matrix.\n\nanova(fit) # the default\n#&gt; \n#&gt; Test of Moderators (coefficient 2):\n#&gt; QM(df = 1) = 84.6513, p-val &lt; .0001\nanova(fit, X = C)\n#&gt; \n#&gt; Hypotheses:                           \n#&gt; 1:             intrcpt = 0 \n#&gt; 2: intrcpt + exponline = 0 \n#&gt; \n#&gt; Results:\n#&gt;    estimate     se    zval   pval     \n#&gt; 1:   0.2357 0.0420  5.6173 &lt;.0001 *** \n#&gt; 2:   0.7845 0.0424 18.5113 &lt;.0001 *** \n#&gt; \n#&gt; Omnibus Test of Hypotheses:\n#&gt; QM(df = 2) = 374.2227, p-val &lt; .0001\n\nNotice that is the same as the model without the intercept."
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#likelihood-ratio-test-lrt",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#likelihood-ratio-test-lrt",
    "title": "Meta-regression",
    "section": "Likelihood Ratio Test (LRT)",
    "text": "Likelihood Ratio Test (LRT)\nAs in standard regression modelling, we can also compare models using LRT. The anova() function will compute the LRT when two (nested) models are provided. In this case we compared a null (intercept-only) model with the model including the predictor.\n\n# the null model\nfit0 &lt;- rma(yi, vi, data = dat, method = \"REML\")\nanova(fit0, fit, refit = TRUE) # refit = TRUE because LRT with REML is not meaningful, using ML instead\n#&gt; \n#&gt;         df      AIC      BIC     AICc   logLik     LRT   pval       QE  tau^2 \n#&gt; Full     3  45.3744  53.1899  45.6244 -19.6872                168.1380 0.0352 \n#&gt; Reduced  2 105.8863 111.0966 106.0100 -50.9431 62.5118 &lt;.0001 314.8233 0.1095 \n#&gt;              R^2 \n#&gt; Full             \n#&gt; Reduced 67.8604%"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2",
    "title": "Meta-regression",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe \\(R^2\\) value reported in the model output is not calculated as in standard regression analysis.\n\\[\nR^2 = 1 - \\frac{\\tau^2_r}{\\tau^2}\n\\]\nBasically is the percentage of heterogeneity reduction from the intercept-only model to the model including predictors.\nIn R:\n\n(1 - fit$tau2/fit0$tau2)*100\n#&gt; [1] 66.76063\nfit$R2\n#&gt; [1] 66.76063"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2-1",
    "title": "Meta-regression",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nDespite useful, the \\(R^2\\) has some limitations:\n\nLópez-López et al. (2014) showed that precise estimations require a large number of studies \\(k\\)\nSometimes could results in negative values (usually truncated to zero)\nDepends on the \\(\\tau^2\\) estimator\n\nMore about \\(R^2\\) and limitations can be found:\n\nhttps://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i\nhttps://www.metafor-project.org/doku.php/tips:ci_for_r2"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#numerical-predictor",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#numerical-predictor",
    "title": "Meta-regression",
    "section": "Numerical predictor",
    "text": "Numerical predictor\nThe same logic of simulating a meta-regression can be applied to numerical predictors. We still have \\(\\beta_0\\) and \\(\\beta_1\\) but \\(X\\) has more levels. Let’s simulate an impact of the average participants’ age on the effect size.\n\n\\(\\beta_0\\) is the effect size when age is zero\n\\(\\beta_1\\) is the expected increase in the effect size for a unit increase in age\n\nHow we can choose plausible values for the parameters and parametrize the model correctly?"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#parametrize-beta_0",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#parametrize-beta_0",
    "title": "Meta-regression",
    "section": "Parametrize \\(\\beta_0\\)",
    "text": "Parametrize \\(\\beta_0\\)\nThe intepretation (and the inference) of \\(\\beta_0\\) is strongly dependent on the type of numerical predictor. An age of zero is (probably) empirically meaningless thus the \\(\\beta_0\\) is somehow not useful.\nWe can for example mean-center (or other type of centering procedure) moving the zero on a meaningful value.\n\nage &lt;- 10:50 # the raw vector\nage0 &lt;- age - mean(age) # centering on the mean\nage20 &lt;- age - min(age) # centering on the minimum\n\nht(data.frame(age, age0, age20))\n#&gt;    age age0 age20\n#&gt; 1   10  -20     0\n#&gt; 2   11  -19     1\n#&gt; 3   12  -18     2\n#&gt; 4   13  -17     3\n#&gt; 5   14  -16     4\n#&gt; 36  45   15    35\n#&gt; 37  46   16    36\n#&gt; 38  47   17    37\n#&gt; 39  48   18    38\n#&gt; 40  49   19    39\n#&gt; 41  50   20    40"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#parametrize-beta_0-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#parametrize-beta_0-1",
    "title": "Meta-regression",
    "section": "Parametrize \\(\\beta_0\\)",
    "text": "Parametrize \\(\\beta_0\\)"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#parametrize-beta_0-2",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#parametrize-beta_0-2",
    "title": "Meta-regression",
    "section": "Parametrize \\(\\beta_0\\)",
    "text": "Parametrize \\(\\beta_0\\)\nUsing different parametrizations will only affect the estimation (and the interpretation) of \\(\\beta_0\\). Other parameters and indexes will be the same.\n\nk &lt;- 100\nb0 &lt;- 0.2 # effect size when age 0\nb1 &lt;- 0.05 # slope (random for now)\nage &lt;- round(runif(k, 20, 50)) # sampling from uniform distribution\ntau2r &lt;- 0.05\nn &lt;- 10 + rpois(k, 30 - 10)\n\nes &lt;- b0 + b1 * age # raw\n\nage0 &lt;- age - mean(age)\nage20 &lt;- age - 20\n\ndat &lt;- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(age = age, age0 = age0, age20 = age20))\n\nfit &lt;- rma(yi, vi, mods = ~ age, data = dat)\nfit0 &lt;- rma(yi, vi, mods = ~ age0, data = dat)\nfit20 &lt;- rma(yi, vi, mods = ~ age20, data = dat)\n\n# showing the intercept\ncompare_rma(fit, fit0, fit20, extra_params = \"R2\") |&gt; \n  round(3)\n#&gt; fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#&gt; fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#&gt; fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#&gt;                fit   fit0  fit20\n#&gt; b (intrcpt)  0.155  1.963  1.190\n#&gt; se           0.164  0.039  0.078\n#&gt; zval         0.947 50.555 15.241\n#&gt; pval         0.344  0.000  0.000\n#&gt; ci.lb       -0.166  1.887  1.037\n#&gt; ci.ub        0.476  2.040  1.342\n#&gt; R2          68.810 68.810 68.810\n#&gt; I2          58.854 58.854 58.854\n#&gt; tau2         0.087  0.087  0.087\n\n  # showing the intercept\ncompare_rma(fit, fit0, fit20, b = \"age\", extra_params = \"R2\") |&gt; \n  round(3)\n#&gt; fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#&gt; fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#&gt; fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#&gt;            fit   fit0  fit20\n#&gt; b (age)  0.052  0.052  0.052\n#&gt; se       0.005  0.005  0.005\n#&gt; zval    11.340 11.340 11.340\n#&gt; pval     0.000  0.000  0.000\n#&gt; ci.lb    0.043  0.043  0.043\n#&gt; ci.ub    0.061  0.061  0.061\n#&gt; R2      68.810 68.810 68.810\n#&gt; I2      58.854 58.854 58.854\n#&gt; tau2     0.087  0.087  0.087"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#choosing-beta_1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#choosing-beta_1",
    "title": "Meta-regression",
    "section": "Choosing \\(\\beta_1\\)",
    "text": "Choosing \\(\\beta_1\\)\nThe core of the model is \\(\\beta_1\\) that is the age effect. Compared to the categorical case where \\(\\beta_1\\) is just the standardized difference between two conditions, with numerical \\(X\\) choosing a meaningful \\(\\beta_1\\) is more challenging.\nTwo (maybe more) strategies:\n\nsimulating a lot of effects sizes fixing \\(beta_0\\) and \\(\\beta_1\\) and see the expected range of \\(y_i\\)\nfixing a certain \\(R^2\\) and choose the \\(\\beta_1\\) producing that \\(R^2\\)\n…"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#beta_1-by-simulations",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#beta_1-by-simulations",
    "title": "Meta-regression",
    "section": "\\(\\beta_1\\) by simulations",
    "text": "\\(\\beta_1\\) by simulations\nA strategy could be to simulate from the generative model a large number of studies and see the expected range of effect size (Gelman, Hill, and Vehtari 2020, chap. 5 and p. 97). A large number of unplausible values suggest that the chosen \\(\\beta_1\\) is probably not appropriate.\n\nk &lt;- 1e3\nn &lt;- 30\ntau2 &lt;- 0\nx &lt;- runif(k, 20, 50) # age\nb0 &lt;- 0.1\nb1 &lt;- c(0.001, 0.05, 0.2)\nesl &lt;- lapply(b1, function(b) b0 + b*x)\ndatl &lt;- lapply(esl, function(es) sim_studies(k = k, es = es, tau2 = tau2, n1 = n, add = list(x = x)))\nnames(datl) &lt;- b1\ndat &lt;- dplyr::bind_rows(datl, .id = \"b1\")\nht(dat)\n#&gt; \n#&gt;         b1   id     yi     vi n1 n2        x \n#&gt; 1    0.001    1 0.0249 0.0743 30 30 39.41982 \n#&gt; 2    0.001    2 0.3599 0.0850 30 30 24.53982 \n#&gt; 3    0.001    3 0.1112 0.0552 30 30 47.02552 \n#&gt; 4    0.001    4 0.3305 0.0705 30 30 42.67976 \n#&gt; 5    0.001    5 0.0313 0.0537 30 30 37.48619 \n#&gt; 2995   0.2  995 9.5151 0.0613 30 30 47.89667 \n#&gt; 2996   0.2  996 4.9303 0.0749 30 30 23.45822 \n#&gt; 2997   0.2  997 9.4805 0.0696 30 30 45.64827 \n#&gt; 2998   0.2  998 7.3192 0.0603 30 30 36.08561 \n#&gt; 2999   0.2  999 5.0941 0.0863 30 30 24.74852 \n#&gt; 3000   0.2 1000 5.8356 0.0882 30 30 28.56949"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#beta_1-by-simulations-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#beta_1-by-simulations-1",
    "title": "Meta-regression",
    "section": "\\(\\beta_1\\) by simulations",
    "text": "\\(\\beta_1\\) by simulations\nClearly given the limited range of the \\(x\\) variable (age) some \\(\\beta_1\\) values are implausible leading to effect sizes that are out of a meaningful empirical range.\n\n\nCode\ndat$b1 &lt;- factor(dat$b1, labels = latex2exp::TeX(sprintf(\"$\\\\beta_1 = %s$\", unique(dat$b1))))\ndat |&gt; \n  ggplot(aes(x = x, y = yi)) +\n  geom_point() +\n  facet_wrap(~b1, scales = \"free_y\", labeller = label_parsed) +\n  xlab(\"Age\") +\n  ylab(latex2exp::TeX(\"$y_i$\"))"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#fixing-r2",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#fixing-r2",
    "title": "Meta-regression",
    "section": "Fixing \\(R^2\\)",
    "text": "Fixing \\(R^2\\)\nWe can use the approach by López-López et al. (2014) where predictors \\(x\\) are sampled from a standard normal distribution (or standardized). \\(\\beta_1\\) is calculated as \\(\\beta_1 = \\sqrt{\\tau^2 R^2}\\) and the residual heterogeneity as \\(\\tau^2_r = \\tau^2 - \\beta^2_1\\).\n\nk &lt;- 100\nn &lt;- 30\ntau2 &lt;- 0.3\nR2 &lt;- 0.4\nb0 &lt;- 0.1\nb1_2 &lt;- tau2 * R2\nb1 &lt;- sqrt(b1_2)\ntau2r &lt;- tau2 - b1_2"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#fixing-r2-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#fixing-r2-1",
    "title": "Meta-regression",
    "section": "Fixing \\(R^2\\)",
    "text": "Fixing \\(R^2\\)\nWe can check the simulation approach:\n\nk &lt;- 1e3\n1 - tau2r/tau2\n#&gt; [1] 0.4\nx &lt;- rnorm(k)\nes &lt;- b0 + b1 * x\ndat &lt;- sim_studies(k, es, tau2r, n1 = 1e3, add = list(x = x))\nfit &lt;- rma(yi, vi, data = dat, mods = ~x)\nsummary(fit)\n#&gt; \n#&gt; Mixed-Effects Model (k = 1000; tau^2 estimator: REML)\n#&gt; \n#&gt;    logLik   deviance        AIC        BIC       AICc   \n#&gt; -547.4249  1094.8498  1100.8498  1115.5671  1100.8740   \n#&gt; \n#&gt; tau^2 (estimated amount of residual heterogeneity):     0.1734 (SE = 0.0079)\n#&gt; tau (square root of estimated tau^2 value):             0.4164\n#&gt; I^2 (residual heterogeneity / unaccounted variability): 98.86%\n#&gt; H^2 (unaccounted variability / sampling variability):   87.86\n#&gt; R^2 (amount of heterogeneity accounted for):            41.74%\n#&gt; \n#&gt; Test for Residual Heterogeneity:\n#&gt; QE(df = 998) = 87658.6376, p-val &lt; .0001\n#&gt; \n#&gt; Test of Moderators (coefficient 2):\n#&gt; QM(df = 1) = 708.4432, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt;          estimate      se     zval    pval   ci.lb   ci.ub      \n#&gt; intrcpt    0.1000  0.0133   7.5463  &lt;.0001  0.0740  0.1260  *** \n#&gt; x          0.3474  0.0131  26.6166  &lt;.0001  0.3219  0.3730  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2-using-simulations",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2-using-simulations",
    "title": "Meta-regression",
    "section": "\\(R^2\\) using simulations",
    "text": "\\(R^2\\) using simulations\nThe results from López-López et al. (2014) (and also our previous simulation) suggested that we need a large number of studies for precise \\(R^2\\) estimations. Let’s check using simulations the sampling distribution of \\(R^2\\) using a plausible meta-analysis scenario.\n\nk &lt;- 40 # number of studies\nn &lt;- 10 + rpois(k, 40 - 10) # sample size\ntau2 &lt;- 0.05 # tau ~ 0.22\nR2 &lt;- 0.3\nb0 &lt;- 0.1\nb1_2 &lt;- tau2 * R2\nb1 &lt;- sqrt(b1_2)\ntau2r &lt;- tau2 - b1_2\nnsim &lt;- 1e3\n\nR2i &lt;- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  x &lt;- rnorm(k)\n  dat &lt;- sim_studies(k = k, es = b0 + b1*x, tau2 = tau2r, n1 = n, add = list(x))\n  fit &lt;- rma(yi, vi, data = dat, mods = ~x)\n  R2i[i] &lt;- fit$R2\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2-using-simulations-1",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#r2-using-simulations-1",
    "title": "Meta-regression",
    "section": "\\(R^2\\) using simulations",
    "text": "\\(R^2\\) using simulations\nWe estimated the true \\(R^2\\) correctly but there is a lot of uncertainty with a plausible meta-analysis scenario. There are a lot of meta-analysis also with lower \\(k\\) worsening the results."
  },
  {
    "objectID": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#references",
    "href": "slides/06-meta-analysis/04-meta-regression/meta-regression.html#references",
    "title": "Meta-regression",
    "section": "References",
    "text": "References\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press. https://doi.org/10.1017/9781139161879.\n\n\nLópez-López, José Antonio, Fulgencio Marín-Martínez, Julio Sánchez-Meca, Wim Van den Noortgate, and Wolfgang Viechtbauer. 2014. “Estimation of the Predictive Power of the Model in Mixed-Effects Meta-Regression: A Simulation Study.” The British Journal of Mathematical and Statistical Psychology 67 (February): 30–48. https://doi.org/10.1111/bmsp.12002.\n\n\nSchad, Daniel J, Shravan Vasishth, Sven Hohenstein, and Reinhold Kliegl. 2020. “How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: A Tutorial.” Journal of Memory and Language 110 (February): 104038. https://doi.org/10.1016/j.jml.2019.104038."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#meta-analysis-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#meta-analysis-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Meta-analysis",
    "text": "Meta-analysis\n\nThe meta-analysis is a statistical procedure to combine evidence from a group of studies.\n\n\n\nThe idea is to “switch” the statistical unit from e.g., participants to studies\n\n\n\n\nThe motto could be that (appropriately) combining similar studies with a similar aim is the best way to understand something about a phenomenon"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#meta-analysis-and-systematic-review",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#meta-analysis-and-systematic-review",
    "title": "Introduction to Meta-Analysis",
    "section": "Meta-analysis and Systematic Review",
    "text": "Meta-analysis and Systematic Review\nUsually a meta-analysis work follows these steps:\n\nIdentify the research question: is the treatment x effective?, Does the experimental effect y exist?\nDefine inclusion/exclusion criteria: From the research question (1), keep only e.g., randomized controlled trials, studies with healthy participants, etc.\nSystematically search for studies: Analyze the literature to find all relevant studies\nExtract relevant information: Read, extract and organize relevant information e.g., sample size, treatment type, age, etc.\nSummarize the results: Create a narrative (flowcharts, tables, etc.) summary of included studies. This is the Systematic review part.\nChoose an effect size: Choose a way to standardize the effect across included studies\nMeta-analysis model: Choose and implement a meta-analysis model\nInterpret and report results"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#before-the-fun-part",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#before-the-fun-part",
    "title": "Introduction to Meta-Analysis",
    "section": "Before the fun part…",
    "text": "Before the fun part…\n\n\nWe are dealing only with the statistical part. The study selection, data extraction, studies evaluation etc. is another story\nThe quality of the meta-analysis is the quality of included studies"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes",
    "title": "Introduction to Meta-Analysis",
    "section": "Unstandardized effect sizes",
    "text": "Unstandardized effect sizes\nThe basic idea of an effect size is just using the raw measure. For example studies using reaction times we can calculate the difference between two conditions as \\(\\overline X_1 - \\overline X_2\\):"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Unstandardized effect sizes",
    "text": "Unstandardized effect sizes\nBut another study (with the same research question) could use another measure, e.g., accuracy. We can still (not the best strategy but) compute the difference between the group means."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes-2",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes-2",
    "title": "Introduction to Meta-Analysis",
    "section": "Unstandardized effect sizes",
    "text": "Unstandardized effect sizes\nClearly we cannot directly compare the two effects but we need to standardize the measure."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-effect-sizes",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-effect-sizes",
    "title": "Introduction to Meta-Analysis",
    "section": "Standardized effect sizes",
    "text": "Standardized effect sizes\nTo compare results from different studies, we should use a common metric. Frequently meta-analysts use standardized effect sizes. For example the Pearson correlation or the Cohen’s \\(d\\).\n\\[\nr = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sqrt{\\sum{(x_i - \\bar{x})^2}\\sum{(y_i - \\bar{y})^2}}}\n\\tag{1}\\]\n\\[\nd = \\frac{\\bar{x_1} - \\bar{x_2}}{s_p}\n\\]\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-effect-sizes-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-effect-sizes-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Standardized effect sizes",
    "text": "Standardized effect sizes\nThe advantage of standardized effect size is that regardless the original variable, the interpretation and the scale is the same. For example the pearson correlation ranges between -1 and 1 and the Cohen’s \\(d\\) between \\(- \\infty\\) and \\(\\infty\\) and is interpreted as how many standard deviations the two groups/conditions differs.\n\n\nCode\nS &lt;- matrix(c(1, 0.7, 0.7, 1), nrow = 2)\nX &lt;- MASS::mvrnorm(100, c(0, 2), S, empirical = TRUE)\n\npar(mfrow = c(1,2))\nplot(X, xlab = \"x\", ylab = \"y\", cex = 1.3, pch = 19,\n     cex.lab = 1.2, cex.axis = 1.2,\n     main = latex2exp::TeX(sprintf(\"$r = %.2f$\", cor(X[, 1], X[, 2]))))\nabline(lm(X[, 2] ~ X[, 1]), col = \"firebrick\", lwd = 2)\n\n\nplot(density(X[, 1]), xlim = c(-5, 7), ylim = c(0, 0.5), col = \"dodgerblue\", lwd = 2,\n     main = latex2exp::TeX(sprintf(\"$d = %.2f$\", lsr::cohensD(X[, 1], X[, 2]))),\n     xlab = \"\")\nlines(density(X[, 2]), col = \"firebrick\", lwd = 2)"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-vs-unstandardized",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-vs-unstandardized",
    "title": "Introduction to Meta-Analysis",
    "section": "Standardized vs unstandardized",
    "text": "Standardized vs unstandardized\nThe main difference is (usually) the absence of a effect-size-variance relationship for unstandardized effects. For example, the variance of the difference between two groups is:\n\\[\nV_d = \\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}\n\\tag{2}\\]\nWhile the variance of a Cohen’s \\(d\\) can be calculated as:\n\\[\nV_d = \\frac{n_1 + n_2}{n_1 n_2} + \\frac{d^2}{2(n_1 + n_2)}\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-vs-unstandardized-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-vs-unstandardized-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Standardized vs unstandardized",
    "text": "Standardized vs unstandardized\nIn this amazing blog post James Pustejovsky explained where the equations comes from. Basically, the \\(\\frac{n_1 + n_2}{n_1 n_2}\\) term is the same as the \\(\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}\\) while the extra \\(\\frac{d^2}{2(n_1 + n_2)}\\) is for the non-centrality induced by the standardized difference."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-vs-unstandardized-2",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#standardized-vs-unstandardized-2",
    "title": "Introduction to Meta-Analysis",
    "section": "Standardized vs unstandardized",
    "text": "Standardized vs unstandardized\n\n\nCode\nn &lt;- c(10, 50, 100)\nd &lt;- seq(0, 2, 0.001)\n\ndd &lt;- expand.grid(n = n, d = d)\n\ndd$vumd &lt;- with(dd, 1/n + 1/n)\ndd$vd &lt;- with(dd, (n + n) / (n * n) + d^2/(2 * (n + n)))\n\ntidyr::pivot_longer(dd, 3:4) |&gt; \n  ggplot(aes(x = d, y = value, color = name, linetype = factor(n))) +\n  geom_line() +\n  labs(linetype = \"Sample Size\",\n       color = NULL)"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#sec-effsize-se",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#sec-effsize-se",
    "title": "Introduction to Meta-Analysis",
    "section": "Effect size sampling variability",
    "text": "Effect size sampling variability\nCrucially, we can calculate also the sampling variability of each effect size. The sampling variability is the precision of estimated value.\nFor example, there are multiple methods to estimate the Cohen’s \\(d\\) sampling variability. For example:\n\\[\nV_d = \\frac{n_1 + n_2}{n_1 n_2} + \\frac{d^2}{2(n_1 + n_2)}\n\\]\nEach effect size has a specific formula for the sampling variability. The sample size is usually the most important information. Studies with higher sample size have lower sampling variability."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#effect-size-sampling-variability",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#effect-size-sampling-variability",
    "title": "Introduction to Meta-Analysis",
    "section": "Effect size sampling variability",
    "text": "Effect size sampling variability\nAs the sample size grows and tends to infinity, the sampling variability approach zero."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes-3",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#unstandardized-effect-sizes-3",
    "title": "Introduction to Meta-Analysis",
    "section": "Unstandardized effect sizes",
    "text": "Unstandardized effect sizes\nFor the examples and plots I’m going to use simulated data. We simulate unstandardized effect sizes (UMD) because the computations are easier and the estimator is unbiased (e.g., Viechtbauer 2005)\nMore specifically we simulate hypothetical studies where two independent groups are compared:\n\\[\n\\Delta = \\overline{X_1} - \\overline{X_2}\n\\tag{3}\\]\n\\[\nSE_{\\Delta} = \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}\n\\]\nWith \\(X_{1_i} \\sim \\mathcal{N}(0, 1)\\) and \\(X_{2_i} \\sim \\mathcal{N}(\\Delta, 1)\\)\nThe main advantage is that, compared to standardized effect size, the sampling variability do not depends on the effect size itself, simplifying the computations."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---umd",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---umd",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - UMD",
    "text": "Simulating a single study - UMD\nTo simulate a single study using a UMD we need to generate data according to the appropriate model. Here we have a difference between two groups. We can assume that the two groups comes from a normal distribution where group 1 \\(g_1 \\sim \\mathcal{N}(0, 1)\\) and group 2 \\(g_2 \\sim \\mathcal{N}(D, 1)\\) where \\(D\\) is the effect size. Then using Equations 2, 3 we can estimate the effect size and the variance.\n\nD &lt;- 1  # effect size\nn &lt;- 50 # sample size\ng1 &lt;- rnorm(n, mean = 0, sd = 1)\ng2 &lt;- rnorm(n, mean = D, sd = 1)\n\n# effect size\nmean(g2) - mean(g1)\n#&gt; [1] 0.7525521\n\n# variance\nvar(g1)/n + var(g2)/n\n#&gt; [1] 0.04732674"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---umd-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---umd-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - UMD",
    "text": "Simulating a single study - UMD\nFor simplicity we can wrap everything within a function:\n\n# default sd = 1\nsim_umd &lt;- function(n1, n2 = NULL, D, sd = 1){\n  if(is.null(n2)) n2 &lt;- n1 # same to n1 if null \n  g1 &lt;- rnorm(n1, mean = 0, sd = sd)\n  g2 &lt;- rnorm(n2, mean = D, sd = sd)\n  yi &lt;- mean(g2) - mean(g1)\n  vi &lt;- var(g1)/n1 + var(g2)/n2\n  data.frame(yi, vi)\n}\n\nsim_umd(100, D = 0.5)\n#&gt;          yi         vi\n#&gt; 1 0.5779448 0.01802745\nsim_umd(50, D = 0.1)\n#&gt;           yi         vi\n#&gt; 1 0.01265824 0.04348705"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---umd-2",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---umd-2",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - UMD",
    "text": "Simulating a single study - UMD\nWe can also generate a large number of studies and check the distribution of effect size and sampling variances. Note that the real \\(D = 1\\) and the real variance \\(V_D = 1/50 + 1/50 = 0.04\\)\n\nstudies &lt;- replicate(1000, sim_umd(n1 = 50, D = 1), simplify = FALSE) # simplify = FALSE return a list\nstudies &lt;- do.call(rbind, studies) # to dataframe\nhead(studies)\n\n#&gt;          yi         vi\n#&gt; 1 1.0297445 0.03928089\n#&gt; 2 0.8790549 0.03991526\n#&gt; 3 1.0135863 0.04407775\n#&gt; 4 1.1086738 0.03915357\n#&gt; 5 1.2811220 0.04387874\n#&gt; 6 1.1326733 0.02765962"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#sec-umd-sampling-distribution",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#sec-umd-sampling-distribution",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - UMD",
    "text": "Simulating a single study - UMD\nThen we can plot the sampling distributions:"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---smd",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---smd",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - SMD",
    "text": "Simulating a single study - SMD\nThe idea is the same when simulating a SDM but we need extra steps. Let’s adjust the previous function:\n\nsim_smd &lt;- function(n1, n2 = NULL, D){\n  if(is.null(n2)) n2 &lt;- n1 # same to n1 if null \n  g1 &lt;- rnorm(n1, mean = 0, sd = 1)\n  g2 &lt;- rnorm(n2, mean = D, sd = 1)\n  \n  v1 &lt;- var(g1)\n  v2 &lt;- var(g2)\n  \n  # pooled standard deviation\n  sp &lt;- sqrt((v1 * (n1 - 1) + v2 * (n2 - 1)) / (n1 + n2 - 2))\n  \n  yi &lt;- (mean(g2) - mean(g1)) / sp\n  vi &lt;- (n1 + n2) / (n1 * n2) + yi^2/(2*(n1 + n2))\n  data.frame(yi, vi)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---smd-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---smd-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - SMD",
    "text": "Simulating a single study - SMD\nWhen working with SMD, calculating the sampling variance can be challenging. Veroniki et al. (2016) identified 16 different estimators with different properties. Furthermore, it is a common practice to correct the SDM effect and variance using the Hedges’s correction (Hedges 1989).\nYou can directly implement another equation for the sampling variance or the Hedges’s correction directly in the simulation function."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - Pearson \\(\\rho\\)",
    "text": "Simulating a single study - Pearson \\(\\rho\\)\nAnother common effect size is the Pearson correlation coefficient \\(\\rho\\) (and the estimate \\(r\\), see Equation 1). The variance of the correlation is calculated as:\n\\[\nV_{r} = \\frac{(1 - r^2)^2}{n - 1}\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - Pearson \\(\\rho\\)",
    "text": "Simulating a single study - Pearson \\(\\rho\\)\nThere is a huge dependency between \\(r\\) and it’s sampling variance (similar to the Cohen’s \\(d\\)):\n\n\nCode\nn &lt;- 50\nr &lt;- seq(0, 1, 0.01)\nv &lt;- (1 - r^2)^2 / (n - 1) \n\nplot(r, v, type = \"l\", main = \"N = 50\", xlab = \"r\", ylab = latex2exp::TeX(\"$V_r$\"))"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-2",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-2",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - Pearson \\(\\rho\\)",
    "text": "Simulating a single study - Pearson \\(\\rho\\)\nFor this reason the so-called Fisher’s \\(z\\) transformation is used to stabilize the relationship.\n\\[\nz = \\frac{\\log{\\frac{1 + r}{1 - r}}}{2}\n\\]\n\\[\nV_z = \\frac{1}{n - 3}\n\\]\nNow the variance is completely independent from the correlation value."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-3",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-3",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - Pearson \\(\\rho\\)",
    "text": "Simulating a single study - Pearson \\(\\rho\\)\nThis is the relationship between \\(r\\) and \\(z\\):\n\n\nCode\nn &lt;- 50\nr &lt;- seq(-1, 1, 0.01)\nv &lt;- (1 - r^2)^2 / (n - 1) \nz &lt;- log((1 + r)/(1 - r))/2\n\nplot(z, r, type = \"l\", xlab = \"Fisher's z\", ylab = \"Correlation\", main = \"Correlation to Fisher's z\")"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-4",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-4",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - Pearson \\(\\rho\\)",
    "text": "Simulating a single study - Pearson \\(\\rho\\)\nTo simulate a study using correlations we can use the MASS::mvrnorm() function that can generate correlated data from a multivariate normal distribution.\n\nsim_r &lt;- function(n, r){\n  R &lt;- r + diag(1 - r, nrow = 2) # 2 x 2 correlation matrix\n  X &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma = R) # the means are not relevant here\n  r &lt;- cor(X)[1, 2] # extract correlation\n  vr &lt;- (1 - r^2)^2 / (n - 1)  # variance of r\n  yi &lt;- log((1 + r)/(1 - r))/2 # fisher z\n  vi &lt;- 1 / (n - 3) # fisher z variance\n  data.frame(yi, vi, r, vr) # including also the pearson correlation and variance\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-5",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-a-single-study---pearson-rho-5",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating a single study - Pearson \\(\\rho\\)",
    "text": "Simulating a single study - Pearson \\(\\rho\\)\n\nsim_r(100, 0.5)\n#&gt;          yi         vi         r          vr\n#&gt; 1 0.4011993 0.01030928 0.3809746 0.007381644\nsim_r(50, 0.8)\n#&gt;         yi        vi         r          vr\n#&gt; 1 1.102976 0.0212766 0.8015655 0.002608184\n\n# also here the sampling distributions\nstudies &lt;- replicate(1000, sim_r(50, 0.7), simplify = FALSE)\nstudies &lt;- do.call(rbind, studies)\nsummary(studies)\n#&gt;        yi               vi                r                vr          \n#&gt;  Min.   :0.4892   Min.   :0.02128   Min.   :0.4536   Min.   :0.001323  \n#&gt;  1st Qu.:0.7616   1st Qu.:0.02128   1st Qu.:0.6420   1st Qu.:0.004001  \n#&gt;  Median :0.8629   Median :0.02128   Median :0.6978   Median :0.005373  \n#&gt;  Mean   :0.8648   Mean   :0.02128   Mean   :0.6913   Mean   :0.005654  \n#&gt;  3rd Qu.:0.9650   3rd Qu.:0.02128   3rd Qu.:0.7465   3rd Qu.:0.007051  \n#&gt;  Max.   :1.3065   Max.   :0.02128   Max.   :0.8634   Max.   :0.012875"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#more-on-effect-sizes",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#more-on-effect-sizes",
    "title": "Introduction to Meta-Analysis",
    "section": "More on effect sizes",
    "text": "More on effect sizes\nThe same logic can be applied to any situation. Just understand the data generation process, find the effect size equations and generate data.\n\nBorenstein et al. (2009) for all effect sizes equations. Also with equations to convert among effect sizes (useful in real-world meta-analyses)\n\nthe metafor::escalc() function implements basically any effect size. You can see also the source code to see the actual R implementation.\nGuide to effect sizes: a modern and complete overview of effect sizes"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating from sampling distributions",
    "text": "Simulating from sampling distributions\nThe previous simulation examples are participant-level simulations. In fact we simulated \\(n\\) observations then we aggregated calculating the effect sizes.\n\nThis is the most flexible and general data simulation strategy but is computationally not efficient.\n\n\nAnother strategy individuate the exact effect size sampling distribution. Then we can sample directly from it. The downside is that we need to derive (or find) the equation."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-1",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-1",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating from sampling distributions",
    "text": "Simulating from sampling distributions\nFor example, when generating UMD we can simulate from the sampling distribution presented in Section 2.4.\n\\[\ny_i \\sim \\mathcal{N}(\\theta, \\sqrt{\\sigma^2_i})\n\\] \\[\n\\sigma^2_i \\sim \\frac{\\chi^2_{n_1 + n_2 - 2}}{n_1 + n_2 - 2} (\\frac{1}{n_1} + \\frac{1}{n_2})\n\\]\nIn this way we can sample \\(k\\) effects and sampling variances directly from the sampling distributions. Without generating data and then aggregate."
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-2",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-2",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating from sampling distributions",
    "text": "Simulating from sampling distributions\nWe can again put everything within a function:\nsim_k_umd &lt;- function(k, D, n1, n2 = NULL){\n  if(is.null(n2)) n2 &lt;- n1\n  yi &lt;- rnorm(k, D, sqrt(1/n1 + 1/n2))\n  vi &lt;- (rchisq(k, n1 + n2 - 2) / (n1 + n2 - 2)) * (1/n1 + 1/n2)\n  data.frame(yi, vi)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-3",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-3",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating from sampling distributions",
    "text": "Simulating from sampling distributions\n\nsim_k_umd(k = 10, D = 0.5, n1 = 50)\n#&gt;           yi         vi\n#&gt; 1  0.3996257 0.03693858\n#&gt; 2  0.4423115 0.03663911\n#&gt; 3  0.6478248 0.04068844\n#&gt; 4  0.3214638 0.04067210\n#&gt; 5  0.4190199 0.04956667\n#&gt; 6  0.7020633 0.03216789\n#&gt; 7  0.6749959 0.04166325\n#&gt; 8  0.1224306 0.03932716\n#&gt; 9  0.5745258 0.04535562\n#&gt; 10 0.2726013 0.04182736"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-4",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-4",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating from sampling distributions",
    "text": "Simulating from sampling distributions\nWe can compare the two methods and see that we are sampling from the same data generation process.\n\n\nCode\nk &lt;- 1e4\ns_umd &lt;- sim_k_umd(k, D = 1, n1 = 50)\nip_umd &lt;- replicate(k, sim_umd(n1 = 50, D = 1), simplify = FALSE)\nip_umd &lt;- do.call(rbind, ip_umd)"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-5",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#simulating-from-sampling-distributions-5",
    "title": "Introduction to Meta-Analysis",
    "section": "Simulating from sampling distributions",
    "text": "Simulating from sampling distributions\nThe actual advantage is in terms of computational speed. To simulate \\(k = 10\\) studies for 1000 times (similar to a standard Monte Carlo simulation):\n\nbench &lt;- microbenchmark::microbenchmark(\n  sampling = sim_k_umd(k = 10, n1 = 50, D = 1),\n  participant = replicate(10, sim_umd(n1 = 50, D = 1)),\n  times = 1000 \n)\n\n(bench &lt;- summary(bench))\n#&gt;          expr      min        lq      mean    median       uq      max neval\n#&gt; 1    sampling  121.017  127.5495  147.8443  135.2085  145.162 5771.075  1000\n#&gt; 2 participant 1546.187 1598.3900 1745.4717 1627.2745 1708.858 7836.305  1000\n#&gt;   cld\n#&gt; 1  a \n#&gt; 2   b\n\nbench$mean[2] / bench$mean[1] # faster\n#&gt; [1] 11.80615"
  },
  {
    "objectID": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#references",
    "href": "slides/06-meta-analysis/02-intro-meta-analysis/intro-meta-analysis.html#references",
    "title": "Introduction to Meta-Analysis",
    "section": "References",
    "text": "References\n\n\nBorenstein, Michael, Larry V Hedges, Julian P T Higgins, and Hannah R Rothstein. 2009. “Introduction to Meta-Analysis.” https://doi.org/10.1002/9780470743386.\n\n\nHedges, Larry V. 1989. “An Unbiased Correction for Sampling Error in Validity Generalization Studies.” The Journal of Applied Psychology 74 (June): 469–77. https://doi.org/10.1037/0021-9010.74.3.469.\n\n\nVeroniki, Areti Angeliki, Dan Jackson, Wolfgang Viechtbauer, Ralf Bender, Jack Bowden, Guido Knapp, Oliver Kuss, Julian P T Higgins, Dean Langan, and Georgia Salanti. 2016. “Methods to Estimate the Between-Study Variance and Its Uncertainty in Meta-Analysis.” Research Synthesis Methods 7 (March): 55–79. https://doi.org/10.1002/jrsm.1164.\n\n\nViechtbauer, Wolfgang. 2005. “Bias and Efficiency of Meta-Analytic Variance Estimators in the Random-Effects Model.” Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association 30 (September): 261–93. https://doi.org/10.3102/10769986030003261."
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#literate-programming-1",
    "href": "slides/04-quarto/04-quarto.html#literate-programming-1",
    "title": "Literate programming with Quarto",
    "section": "Literate Programming1",
    "text": "Literate Programming1\n\nDonald Knuth first defined literate programming as a script, notebook, or computational document that contains an explanation of the program logic in a natural language, interspersed with snippets of macros and source code, which can be compiled and rerun\n\nFor example jupyter notebooks, R Markdown and now Quarto are literate programming frameworks to integrate code and text.\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Literate_programming"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#literate-programming-the-markup-language",
    "href": "slides/04-quarto/04-quarto.html#literate-programming-the-markup-language",
    "title": "Literate programming with Quarto",
    "section": "Literate Programming, the markup language",
    "text": "Literate Programming, the markup language\nBeyond the coding part, the markup language is the core element of a literate programming framework. The idea of a markup language is separating the result from what you actually write. Some examples are:\n\nLaTeX\nHTML\nMarkdown\nXML\n…"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#latex",
    "href": "slides/04-quarto/04-quarto.html#latex",
    "title": "Literate programming with Quarto",
    "section": "LaTeX 1",
    "text": "LaTeX 1\n\nhttps://latexbase.com/"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#html",
    "href": "slides/04-quarto/04-quarto.html#html",
    "title": "Literate programming with Quarto",
    "section": "HTML",
    "text": "HTML\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;body&gt;\n\n&lt;h1&gt;My First Heading&lt;/h1&gt;\n\nLorem Ipsum è un testo segnaposto utilizzato nel settore della tipografia e della stampa. Lorem Ipsum è considerato il testo segnaposto standard sin dal sedicesimo secolo, quando un anonimo tipografo prese una cassetta di caratteri e li assemblò per preparare un testo campione. È sopravvissuto non solo a più di cinque secoli, ma anche al passaggio alla videoimpaginazione, pervenendoci sostanzialmente inalterato. Fu reso popolare, negli anni ’60, con la diffusione dei fogli di caratteri trasferibili “Letraset”, che contenevano passaggi del Lorem Ipsum, e più recentemente da software di impaginazione come Aldus PageMaker, che includeva versioni del Lorem Ipsum.\n\n&lt;h2&gt;My Second Heading&lt;/h2&gt;\n\nLorem Ipsum è un testo segnaposto utilizzato nel settore della tipografia e della stampa. \n\nLorem Ipsum è considerato il testo segnaposto standard sin dal sedicesimo secolo, quando un anonimo \n\ntipografo prese una cassetta di caratteri e li assemblò per preparare un testo campione. \n\nÈ sopravvissuto non solo a più di cinque secoli, ma anche al passaggio alla videoimpaginazione, pervenendoci sostanzialmente inalterato. \n\nFu reso popolare, negli anni ’60, con la diffusione dei \n\nfogli di caratteri trasferibili “Letraset”, che contenevano passaggi del Lorem Ipsum\n\npiù recentemente da software di impaginazione come Aldus PageMaker, che includeva versioni del Lorem Ipsum.\n\n&lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#markdown",
    "href": "slides/04-quarto/04-quarto.html#markdown",
    "title": "Literate programming with Quarto",
    "section": "Markdown1",
    "text": "Markdown1\n\n\nhttps://markdownlivepreview.com/"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#markdown-1",
    "href": "slides/04-quarto/04-quarto.html#markdown-1",
    "title": "Literate programming with Quarto",
    "section": "Markdown",
    "text": "Markdown\nMarkdown is one of the most popular markup languages for several reasons:\n\neasy to write and read compared to Latex and HTML\neasy to convert from Markdown to basically every other format using pandoc\neasy to implement new features"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#markdown-source-code",
    "href": "slides/04-quarto/04-quarto.html#markdown-source-code",
    "title": "Literate programming with Quarto",
    "section": "Markdown (source code)",
    "text": "Markdown (source code)\n## Markdown\n\nMarkdown is one of the most popular markup languages for several reasons:\n\n- easy to write and read compared to Latex and HTML\n- easy to convert from Markdown to basically every other format using `pandoc`\n- easy to implement new features\n\nAlso the source code can be used, compared to Latex or HTML, to take notes and read. Latex and HTML need to be compiled otherwise they are very hard to read."
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#whats-wrong-about-microsoft-word",
    "href": "slides/04-quarto/04-quarto.html#whats-wrong-about-microsoft-word",
    "title": "Literate programming with Quarto",
    "section": "What’s wrong about Microsoft Word?",
    "text": "What’s wrong about Microsoft Word?\nMS Word is a WYSIWYG (what you see is what you get editor) that force users to think about formatting, numbering, etc. Markup languages receive the content (plain text) and the rules and creates the final document."
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#whats-wrong-about-microsoft-word-1",
    "href": "slides/04-quarto/04-quarto.html#whats-wrong-about-microsoft-word-1",
    "title": "Literate programming with Quarto",
    "section": "What’s wrong about Microsoft Word?",
    "text": "What’s wrong about Microsoft Word?\nBeyond the pure writing process, there are other aspects related to research data.\n\n\nwriting math formulas\nreporting statistics in the text\nproducing tables\nproducing plots\n\n\nIn MS Word (or similar) we need to produce everything outside and then manually put figures and tables."
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#the-solution-quarto",
    "href": "slides/04-quarto/04-quarto.html#the-solution-quarto",
    "title": "Literate programming with Quarto",
    "section": "The solution… Quarto",
    "text": "The solution… Quarto\nQuarto (https://quarto.org/) is the evolution of R Markdown that integrate a programming language with the Markdown markup language. It is very simple but quite powerful."
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#basic-markdown",
    "href": "slides/04-quarto/04-quarto.html#basic-markdown",
    "title": "Literate programming with Quarto",
    "section": "Basic Markdown",
    "text": "Basic Markdown\nMarkdown can be learned in minutes. You can go to the following link https://quarto.org/docs/authoring/markdown-basics.html and try to understand the syntax."
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#more-about-quarto-and-r-markdown",
    "href": "slides/04-quarto/04-quarto.html#more-about-quarto-and-r-markdown",
    "title": "Literate programming with Quarto",
    "section": "More about Quarto and R Markdown",
    "text": "More about Quarto and R Markdown\nThe topic is extremely vast. You can do everything in Quarto, a website, thesis, your CV, etc.\n\nYihui Xie - R Markdown Cookbook https://bookdown.org/yihui/rmarkdown-cookbook/\nYihui Xie - R Markdown: The Definitive Guide https://bookdown.org/yihui/rmarkdown/\nQuarto documentation https://quarto.org/docs/guide/"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#writing-papers-papaja",
    "href": "slides/04-quarto/04-quarto.html#writing-papers-papaja",
    "title": "Literate programming with Quarto",
    "section": "Writing papers, papaja",
    "text": "Writing papers, papaja\n\nhttps://github.com/crsh/papaja"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#writing-papers-apaquarto",
    "href": "slides/04-quarto/04-quarto.html#writing-papers-apaquarto",
    "title": "Literate programming with Quarto",
    "section": "Writing papers, apaquarto",
    "text": "Writing papers, apaquarto\n\nhttps://github.com/wjschne/apaquarto"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#collaborating-tbh-not-so-easy",
    "href": "slides/04-quarto/04-quarto.html#collaborating-tbh-not-so-easy",
    "title": "Literate programming with Quarto",
    "section": "Collaborating! (TBH not so easy)",
    "text": "Collaborating! (TBH not so easy)\nThe trackdown package can be used to collaborate on Rmd or qmd documents using Google Docs.\n\nhttps://github.com/ClaudioZandonella/trackdown"
  },
  {
    "objectID": "slides/04-quarto/04-quarto.html#collaborating-overleaf",
    "href": "slides/04-quarto/04-quarto.html#collaborating-overleaf",
    "title": "Literate programming with Quarto",
    "section": "Collaborating! Overleaf",
    "text": "Collaborating! Overleaf\nWith Overleaf you can collaborate on .tex documents but also .Rnw documents. No Rmd or qmd unfortunately. See an example document."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#paradigmi-sperimentali",
    "href": "slides/01-psychological-research/01-psychological-research.html#paradigmi-sperimentali",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Paradigmi sperimentali",
    "text": "Paradigmi sperimentali\n\nCon il prof. Maffei avete affrontato come rilevare attività celebrale ad esempio con fMRI o EEG/ERP.\nSolitamente (ma non sempre) queste rilevazioni sono eseguite mentre il soggetto sperimentale esegue un compito.\nOltre al dato neurofisiologico abbiamo quindi anche sempre un dato comportamentale che viene analizzato separatamente o in relazione a quello cerebrale.\nCi sono anche casi dove ai fini della ricerca è rilevante solo il dato comportamentale."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#paradigmi-sperimentali-1",
    "href": "slides/01-psychological-research/01-psychological-research.html#paradigmi-sperimentali-1",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Paradigmi sperimentali",
    "text": "Paradigmi sperimentali\nQuando si parla di paradigma sperimentale, si intende un insieme di stimoli (visivi, uditivi, tattili, etc.) che vengono presentati ai soggetti.\nSolitamente i paradigmi vengono studiati e programmati nel dettaglio controllando il numero dei trials, le proprieta fisiche (durata, dimensione, etc.) degli stimoli, l’organizzazione temporale (durata esperimento, pause, ordine degli stimoli)."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#change-detection-task",
    "href": "slides/01-psychological-research/01-psychological-research.html#change-detection-task",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Change-detection Task",
    "text": "Change-detection Task\nQuesto compito è utilizzato per stimare la capacità della memoria visiva a breve termine. Possiamo vedere un esempio pratico a questo link https://run.pavlovia.org/demos/change_detection/.\nCon questo tipo di esperimenti è possibile stimare la quantità di informazione che riusciamo a memorizzare.\n\nRouder et al. (2011)"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#facial-expressions",
    "href": "slides/01-psychological-research/01-psychological-research.html#facial-expressions",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Facial expressions",
    "text": "Facial expressions\nAltri ricercatori sono più interessati ad utilizzare stimoli con una valenza sociale ed evoluzionistica come i volti. C’è moltissima ricerca riguardo il modo in cui elaboriamo volti ed espressioni facciali. Un altro esempio qui http://run.pavlovia.org/demos/emotion_rating/.\n\nMünkler et al. (2015)"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#unconscious-processing",
    "href": "slides/01-psychological-research/01-psychological-research.html#unconscious-processing",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Unconscious processing",
    "text": "Unconscious processing\nAltri (tipo me) si sono interessati a come elaboriamo informazioni (ad esempio visive) in modo non consapevole o subliminale. Trovate un esempio con volti qui https://www.youtube.com/watch?v=ln-uXcC2Y_8&t=6s."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#altri-paradigmi-da-provare",
    "href": "slides/01-psychological-research/01-psychological-research.html#altri-paradigmi-da-provare",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Altri paradigmi da provare",
    "text": "Altri paradigmi da provare\nSe volete provare altri esperimenti potete andare su https://pavlovia.org/explore?sort=DEFAULT&search=demos. Alcuni interessanti sono:\n\nStroop https://run.pavlovia.org/demos/stroop/\nDigit Span https://run.pavlovia.org/demos/digit_span/\nSemantic Priming https://run.pavlovia.org/demos/semantic_priming/"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#quali-misure",
    "href": "slides/01-psychological-research/01-psychological-research.html#quali-misure",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Quali misure?",
    "text": "Quali misure?\nSolitamente a livello comportamentale siamo interessati a:\n\ntempi di reazione/risposta: i vari software permettono di rilevare con estrema precisione la velocità di risposta\naccuratezza nelle varie condizioni sperimentali\nstile di risposta\n…"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#tempi-di-reazione",
    "href": "slides/01-psychological-research/01-psychological-research.html#tempi-di-reazione",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Tempi di reazione",
    "text": "Tempi di reazione\nAd esempio possiamo ipotizzare che una condizione sperimentale più difficile richieda maggiore tempo di risposta. Spesso si parla di qualche decina di millisecondi."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#tempi-di-reazione-1",
    "href": "slides/01-psychological-research/01-psychological-research.html#tempi-di-reazione-1",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Tempi di reazione",
    "text": "Tempi di reazione\nE possiamo anche essere interessati a stimare le differenze individuali che in Psicologia sono consistenti."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#esperimenti-complessi",
    "href": "slides/01-psychological-research/01-psychological-research.html#esperimenti-complessi",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Esperimenti complessi",
    "text": "Esperimenti complessi\nSpesso siamo interessati non tanto ad effetti principali ma a interazioni tra condizioni sperimentali. Ad esempio, se vogliamo studiare come elaboriamo le espressioni facciali possiamo indagare:\n\nsiamo più veloci e/o accurati ad elaborare volti rispetto ad altri stimoli (effetto principale della categoria)\nsiamo più veloci e/o accurati ad elaborare alcune espressioni facciali rispetto ad altre? (effetto principale dell’espressione facciale)\nsiamo più veloci e/o accurati ad elaborare espressioni facciali di diversa intensità (effetto principale dell’espressione facciale)?"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#esperimenti-complessi-1",
    "href": "slides/01-psychological-research/01-psychological-research.html#esperimenti-complessi-1",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Esperimenti complessi",
    "text": "Esperimenti complessi\nMentre alcuni effetti sono noti in letteratura (alcune emozioni sono più facili da riconoscere) possiamo essere interessati a vedere se la relazione tra intensità ed accuratezza cambia in funzione dell’emozione (interazione):\n\nShimizu et al. (2024)"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#esperimenti-complessi-2",
    "href": "slides/01-psychological-research/01-psychological-research.html#esperimenti-complessi-2",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Esperimenti complessi",
    "text": "Esperimenti complessi\nIn questo tipo di esperimenti ci sono diverse cose da considerare:\n\nquanti trial per ogni condizione?\nquanti soggetti mi servono?\nesperimenti più lunghi portano a maggiore precisione di stima ma anche maggiore stanchezza\nquali stimoli utilizzo? il tipo di stimolo può avere un effetto?\n…"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#altre-misure-in-psicologia",
    "href": "slides/01-psychological-research/01-psychological-research.html#altre-misure-in-psicologia",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Altre misure in Psicologia",
    "text": "Altre misure in Psicologia"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#altre-misure-in-psicologia-1",
    "href": "slides/01-psychological-research/01-psychological-research.html#altre-misure-in-psicologia-1",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Altre misure in Psicologia",
    "text": "Altre misure in Psicologia"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#ma-anche-variabili-più-complesse",
    "href": "slides/01-psychological-research/01-psychological-research.html#ma-anche-variabili-più-complesse",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Ma anche variabili più complesse…",
    "text": "Ma anche variabili più complesse…\nDati circolari (e.g., distribuzione Von Mises) per stimare la precisione di un processo cognitivo/percettivo. Cremers and Klugkist (2018) hanno pubblicato un tutorial per dati circolari in psicologia.\n\nZhang and Luck (2008)"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#mixture-models",
    "href": "slides/01-psychological-research/01-psychological-research.html#mixture-models",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Mixture-models",
    "text": "Mixture-models\nLa situazione precedente, può essere modellata come una mistura di due processi cognitivamente diversi, una stima ed una risposta casuale."
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#procedure-adattive",
    "href": "slides/01-psychological-research/01-psychological-research.html#procedure-adattive",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Procedure adattive",
    "text": "Procedure adattive\nIn alcune discipline (e.g., psicofisica) si utilizzano delle procedure che adattano gli stimoli presentati in base alle risposte. Questo permette di stimare in modo efficiente dei parametri di interesse.\n\nLeek (2001)"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#procedure-adattive-1",
    "href": "slides/01-psychological-research/01-psychological-research.html#procedure-adattive-1",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Procedure adattive",
    "text": "Procedure adattive\nLa procedura, detta staircase adatta la difficoltà dell’esperimento per tenere l’accuratezza al 50% (o altri valori)"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#procedure-adattive-2",
    "href": "slides/01-psychological-research/01-psychological-research.html#procedure-adattive-2",
    "title": "Experimental Psychology and Neuroscience",
    "section": "Procedure adattive",
    "text": "Procedure adattive\nDove questa è la relazione vera da stimare:"
  },
  {
    "objectID": "slides/01-psychological-research/01-psychological-research.html#references",
    "href": "slides/01-psychological-research/01-psychological-research.html#references",
    "title": "Experimental Psychology and Neuroscience",
    "section": "References",
    "text": "References\n\n\n\n\nCremers, Jolien, and Irene Klugkist. 2018. “One Direction? A Tutorial for Circular Data Analysis Using r with Examples in Cognitive Psychology.” Frontiers in Psychology 9 (October): 2040. https://doi.org/10.3389/fpsyg.2018.02040.\n\n\nLeek, Marjorie R. 2001. “Adaptive Procedures in Psychophysical Research.” Perception & Psychophysics 63 (November): 1279–92. https://doi.org/10.3758/bf03194543.\n\n\nMünkler, Paula, Marcus Rothkirch, Yasmin Dalati, Katharina Schmack, and Philipp Sterzer. 2015. “Biased Recognition of Facial Affect in Patients with Major Depressive Disorder Reflects Clinical State.” PloS One 10 (June): e0129863. https://doi.org/10.1371/journal.pone.0129863.\n\n\nRouder, Jeffrey N, Richard D Morey, Candice C Morey, and Nelson Cowan. 2011. “How to Measure Working Memory Capacity in the Change Detection Paradigm.” Psychonomic Bulletin & Review 18 (April): 324–30. https://doi.org/10.3758/s13423-011-0055-3.\n\n\nShimizu, Yunoshin, Kazumi Ogawa, Masanori Kimura, Ken Fujiwara, and Nobuyuki Watanabe. 2024. “The Influence of Emotional Facial Expression Intensity on Decoding Accuracy: High Intensity Does Not Yield High Accuracy.” The Japanese Psychological Research 66 (October): 521–40. https://doi.org/10.1111/jpr.12529.\n\n\nZhang, Weiwei, and Steven J Luck. 2008. “Discrete fixed-resolution representations in visual working memory.” Nature 453 (May): 233–35. https://doi.org/10.1038/nature06860."
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Psychometrics4Neuroscience",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nscript\n\n\n\n\n\n\nIntroduzione al corso\n\n\n \n\n\n\n\nExperimental Psychology and Neuroscience\n\n\n \n\n\n\n\nModern R\n\n\n \n\n\n\n\nLiterate programming with Quarto\n\n\n \n\n\n\n\nGit and Github\n\n\n \n\n\n\n\nIntroduction to Meta-Analysis\n\n\n \n\n\n\n\nMeta-analysis Models\n\n\n \n\n\n\n\nMeta-regression\n\n\n \n\n\n\n\nPower analysis\n\n\n \n\n\n\n\nPublication Bias\n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "scripts-lectures/2025-04-08.html",
    "href": "scripts-lectures/2025-04-08.html",
    "title": "2025-04-08",
    "section": "",
    "text": "Simuliamo dati fissando una certa correlazione pre-post come ICC:\n\nlibrary(lme4)\n\nn &lt;- 1e4\nr &lt;- 0.7 # icc = r\nb0 &lt;- 0\nb1 &lt;- 0.3\nsb0 &lt;- sqrt(r)\ns &lt;- sqrt(1 - sb0^2)\n\ndat &lt;- data.frame(\n    x = rep(0:1, each = n),\n    id = rep(1:n, 2)\n)\n\nb0i &lt;- rnorm(n, 0, sb0)\ndat$y &lt;- rnorm(n*2, with(dat, b0 + b0i[id] + b1 * x), s)\n\nfit &lt;- lmer(y ~ x + (1|id), data = dat)\nsummary(fit)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + (1 | id)\n   Data: dat\n\nREML criterion at convergence: 50018.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1288 -0.5133 -0.0030  0.5213  3.2586 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.6961   0.8343  \n Residual             0.3007   0.5484  \nNumber of obs: 20000, groups:  id, 10000\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept) -0.008000   0.009984  -0.801\nx            0.303728   0.007755  39.166\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.388\n\nsb0^2 / (sb0^2 + s^2)\n\n[1] 0.7\n\nsummary(fit)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + (1 | id)\n   Data: dat\n\nREML criterion at convergence: 50018.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.1288 -0.5133 -0.0030  0.5213  3.2586 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.6961   0.8343  \n Residual             0.3007   0.5484  \nNumber of obs: 20000, groups:  id, 10000\n\nFixed effects:\n             Estimate Std. Error t value\n(Intercept) -0.008000   0.009984  -0.801\nx            0.303728   0.007755  39.166\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.388\n\nperformance::icc(fit)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.698\n  Unadjusted ICC: 0.683\n\n\nSimuliamo random-intercepts e slopes con anche l’effetto di una covariata al livello del soggetto.\n\nn &lt;- 10\nnt &lt;- 10\n\nage &lt;- round(runif(n, 20, 30))\n\ndat &lt;- expand.grid(\n    id = 1:n,\n    trial = 1:nt,\n    x = c(0, 1)\n)\n\ndat$age &lt;- age[dat$id]\n\nb0 &lt;- 0.1\nb1 &lt;- 0.5\nb2 &lt;- 0.1\nsb0 &lt;- 0.2\nsb1 &lt;- 0.1\ns &lt;- 1\n\nrb0b1 &lt;- 0.5\n\nR &lt;- rb0b1 + diag(1 - rb0b1, 2)\nS &lt;- diag(c(sb0, sb1)) %*% R %*% diag(c(sb0, sb1))\n\nZ &lt;- MASS::mvrnorm(n, c(0, 0), S)\n\nb0i &lt;- Z[, 1]\nb1i &lt;- Z[, 2]\n\ndat$age0 &lt;- dat$age - mean(dat$age)\ndat$lp &lt;- b0 + b0i[dat$id] + (b1 + b1i[dat$id]) * dat$x + b2 * dat$age0\ndat$y &lt;- rnorm(nrow(dat), dat$lp, s)\nfit &lt;- lmer(y ~ x + age + (x|id), dat = dat)\n\nsummary(fit)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + age + (x | id)\n   Data: dat\n\nREML criterion at convergence: 582.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2763 -0.5854  0.0459  0.6215  2.4063 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr\n id       (Intercept) 7.060e-02 0.265698     \n          x           4.231e-06 0.002057 1.00\n Residual             9.979e-01 0.998936     \nNumber of obs: 200, groups:  id, 10\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) -3.03737    0.87610  -3.467\nx            0.35413    0.14127   2.507\nage          0.12548    0.03282   3.824\n\nCorrelation of Fixed Effects:\n    (Intr) x     \nx   -0.080       \nage -0.989  0.000\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\nperformance::r2(fit)\n\nRandom effect variances not available. Returned R2 does not account for random effects.\n\n\n# R2 for Mixed Models\n\n  Conditional R2: NA\n     Marginal R2: 0.173\n\nlibrary(ggplot2)\n\ndat |&gt; \n    ggplot(aes(x = age, y = y)) +\n    geom_point(aes(color = factor(x)))\n\n\n\n\n\n\n\n\nSimuliamo un modello logit:\n\nn &lt;- 100\nnt &lt;- 1e3\nb0 &lt;- qlogis(0.01)\nb1 &lt;- 10\nsb0 &lt;- 1\n\n# plogis(qlogis(0.01) + rnorm(1e4, 0, sb0)) |&gt; \n#     hist()\n\n\ndd &lt;- expand.grid(\n    id = 1:n,\n    nt = 1:nt\n)\n\ndd$x &lt;- runif(nrow(dd), 0, 1)\nb0i &lt;- rnorm(n, 0, sb0)\n\ndd$lp &lt;-  + b1 * dd$x\ndd$p &lt;- plogis(dd$lp)\n\n# dd |&gt; \n#     ggplot(aes(x = x, y = p, group = id)) +\n#     geom_line()\n\ndd$y &lt;- rbinom(nrow(dd), 1, dd$p)\n\nlibrary(lme4)\n\nfit &lt;- glmer(y ~ x + (1|id),\n             data = dd, \n             family = binomial())\n\nperformance::icc(fit)\n\n[1] NA\n\nsummary(fit)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: y ~ x + (1 | id)\n   Data: dd\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  32799.4   32828.0  -16396.7   32793.4     99997 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-67.165   0.016   0.056   0.204   1.008 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0        0       \nNumber of obs: 100000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.01598    0.02193  -0.729    0.466    \nx           10.12262    0.12273  82.476   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.764\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n# intraclass correlation con varianza della logistica come costante\n0.8821 / (0.8821 + pi^2/3)\n\n[1] 0.211435"
  },
  {
    "objectID": "scripts-lectures/2025-04-07.html",
    "href": "scripts-lectures/2025-04-07.html",
    "title": "2025-04-07",
    "section": "",
    "text": "Facciamo un’approfondimento su un’applicazione interessante del modello probit alle decisioni signal detection theory"
  },
  {
    "objectID": "scripts-lectures/2025-04-07.html#topics",
    "href": "scripts-lectures/2025-04-07.html#topics",
    "title": "2025-04-07",
    "section": "",
    "text": "Facciamo un’approfondimento su un’applicazione interessante del modello probit alle decisioni signal detection theory"
  },
  {
    "objectID": "scripts-lectures/2025-04-07.html#assignment",
    "href": "scripts-lectures/2025-04-07.html#assignment",
    "title": "2025-04-07",
    "section": "Assignment",
    "text": "Assignment\nPer oggi facciamo una simulazione, descritta in questo documento"
  },
  {
    "objectID": "scripts-lectures/2025-04-07.html#simulazioni",
    "href": "scripts-lectures/2025-04-07.html#simulazioni",
    "title": "2025-04-07",
    "section": "Simulazioni",
    "text": "Simulazioni\nAbbiamo visto alcune strategie di simulazione, in particolare per calcolare la potenza statistica. Ad esempio nel caso di un t-test assumendo due popolazioni a varianza uguale (\\(\\sigma = 1\\)) e differenza tra le medie \\(d = 0.3\\) abbiamo:\n\nn &lt;- 30 # per gruppo\nd &lt;- 0.3 # effect size\ns &lt;- 1 # pooled standard deviation\ndf &lt;- n * 2 - 2 # degrees of freedom\nalpha &lt;- 0.05\n\nnu &lt;- d * sqrt((n * n) / (n + n)) # observed t-value (or non-centrality parameter)\ntc &lt;- qt(1 - alpha/2, df) # critical t-value\n\n1 - pt(tc, df, nu) + pt(-tc, df, nu) # potenza\n\n[1] 0.2078518\n\npwr::pwr.t.test(n, d)\n\n\n     Two-sample t test power calculation \n\n              n = 30\n              d = 0.3\n      sig.level = 0.05\n          power = 0.2078518\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nIn alternativa usando le simulazioni:\n\nnsim &lt;- 1e3\np &lt;- rep(NA, nsim)\n\nfor(i in 1:length(p)){\n    g0 &lt;- rnorm(n, 0, 1)\n    g1 &lt;- rnorm(n, d, 1)\n    p[i] &lt;- t.test(g1, g0)$p.value\n}\n\nmean(p &lt;= alpha)\n\n[1] 0.204\n\n\nLo stesso lo possiamo vedere come modello lineare:\n\nN &lt;- n * 2\nb0 &lt;- 0 # intercetta, media gruppo 0\nb1 &lt;- d # slope, differenza tra i due gruppi\ns &lt;- 1  # standard deviation residua\n\ndat &lt;- data.frame(\n    x = rep(0:1, each = n)\n)\n\ndat$y &lt;- rnorm(N, b0 + b1 * dat$x, s)\n\nfit &lt;- lm(y ~ x, data = dat)\nsummary(fit)\n\n\nCall:\nlm(formula = y ~ x, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.15553 -0.49610  0.01076  0.63257  2.38245 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  0.04311    0.17159   0.251    0.803\nx            0.25190    0.24266   1.038    0.304\n\nResidual standard error: 0.9398 on 58 degrees of freedom\nMultiple R-squared:  0.01824,   Adjusted R-squared:  0.001314 \nF-statistic: 1.078 on 1 and 58 DF,  p-value: 0.3035\n\n\nIn questo caso il parametro di effect size è:\n\nb1 / s # differenza tra gruppi diviso per standard deviation residua\n\n[1] 0.3\n\ncoef(fit)[2] / sigma(fit)\n\n        x \n0.2680318 \n\ndata.frame(effectsize::cohens_d(y ~ x, data = dat))\n\n    Cohens_d   CI     CI_low   CI_high\n1 -0.2680318 0.95 -0.7752847 0.2415063\n\n\nOvviamente anche la potenza sarà lo stesso.\nNel caso di un disegno pre-post, le osservazioni dello stesso soggetto sono correlate. Per simulare dei dati correlati posso usare il pacchetto MASS::mvrnorm() oppure con la formula di un mixed-model.\n\nr &lt;- 0.7\nR &lt;- r + diag(1 - r, 2) # matrice di correlazione\nX &lt;- MASS::mvrnorm(n, c(0, d), R)\napply(X, 2, mean)\n\n[1] 0.006866262 0.238129522\n\napply(X, 2, sd)\n\n[1] 1.183033 1.031994\n\ncor(X)\n\n          [,1]      [,2]\n[1,] 1.0000000 0.6902159\n[2,] 0.6902159 1.0000000\n\n\nPer quanto riguarda il mixed-model il parametro cruciale è la deviazione standard delle intercette. Possiamo partire dall’Intraclass Correlation Coefficient (ICC) che determina la correlazione tra osservazioni dentro un cluster.\n\\[\n\\mbox{ICC} = \\rho_{pre-post}\n\\] \\[\n\\mbox{ICC} = \\frac{\\sigma^2_{\\beta_0}}{\\sigma^2_{\\beta_0} + \\sigma^2_{\\epsilon}} \\\\\n\\] Se assumiamo che la varianza totale sia uno, allora:\n\\[\n\\sigma^2_{\\beta_0{_i}} + \\sigma^2_{\\epsilon} = 1\n\\]\n\\[\n\\mbox{ICC} = \\sigma^2_{\\beta_0{_i}}\n\\]\n\nlibrary(lme4)\n\nr &lt;- 0.7 # icc = r\nb0 &lt;- 0\nb1 &lt;- d\nsb0 &lt;- sqrt(r)\ns &lt;- sqrt(1 - sb0^2)\n\ndat &lt;- data.frame(\n    x = rep(0:1, each = n),\n    id = rep(1:n, 2)\n)\n\nb0i &lt;- rnorm(n, 0, sb0)\ndat$y &lt;- rnorm(N, with(dat, b0 + b0i[id] + b1 * x), s)\n\nfit &lt;- lmer(y ~ x + (1|id), data = dat)\nsummary(fit)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + (1 | id)\n   Data: dat\n\nREML criterion at convergence: 128.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7887 -0.5160  0.0831  0.6159  1.4381 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.1978   0.4448  \n Residual             0.3179   0.5639  \nNumber of obs: 60, groups:  id, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   0.1023     0.1311   0.780\nx             0.5246     0.1456   3.603\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.555\n\nperformance::icc(fit)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.384\n  Unadjusted ICC: 0.338"
  },
  {
    "objectID": "scripts-lectures/2025-04-07.html#icc",
    "href": "scripts-lectures/2025-04-07.html#icc",
    "title": "2025-04-07",
    "section": "ICC",
    "text": "ICC\nNei mixed-models è utile capire ed utilizzare l’ICC. Simuliamo dati pre-post con diversi gradi di intraclass correlation (simuliamo più osservazioni di pre-post così è più chiaro il pattern):\n\nlibrary(ggplot2)\nlibrary(tidyverse)\n\nicc &lt;- c(0, 0.5, 0.8)\nn &lt;- 10\nnt &lt;- 100\nb0 &lt;- 0\nb1 &lt;- 0\n\nsb0 &lt;- sqrt(icc)\ns &lt;- sqrt(1 - sb0^2)\n\ndat &lt;- expand.grid(\n    id = 1:n,\n    x = c(0, 1),\n    nt = 1:nt\n)\n\ny &lt;- vector(mode = \"list\", length = length(icc))\n\nfor(i in 1:length(y)){\n    b0i &lt;- rnorm(n, 0, sb0[i])\n    y[[i]] &lt;- rnorm(nrow(dat), with(dat, b0 + b0i[id] + b1 * x), s[i])\n}\n\nnames(y) &lt;- paste0(\"y_icc\", icc)\ndat &lt;- cbind(dat, y)\n\ndat |&gt; \n    pivot_longer(starts_with(\"y\"),\n                 names_to = \"icc\",\n                 values_to = \"y\") |&gt; \n    mutate(icc = parse_number(icc)) |&gt; \n    ggplot(aes(x = factor(id), y = y)) +\n    geom_boxplot() +\n    facet_wrap(~icc) +\n    xlab(\"Cluster\")"
  },
  {
    "objectID": "scripts-lectures/2025-04-04.html",
    "href": "scripts-lectures/2025-04-04.html",
    "title": "2025-04-04",
    "section": "",
    "text": "library(here)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(glmmTMB)\nlibrary(lmerTest)\n\n# fittare un modello specificato con formula per ogni id (|cluster)\n# model = lm/glm (o altro)\n# args = altri argomenti dentro la funzione (e.g., family = )\n# ad esempio, per stimare l'effetto di x1 + x2 per ogni cluster\n# y ~ x1 + x2 | cluster\n\nfit_by_cluster &lt;- function(formula, data, model = NULL, args = NULL){\n    if(is.null(model)){\n        model &lt;- lm\n    }\n    \n    parts &lt;- lme4:::modelFormula(formula)\n    groups &lt;- as.character(parts$groups)\n    datal &lt;- split(data, data[[groups]])\n    \n    args$formula &lt;- parts$model\n    \n    lapply(datal, function(x){\n        do.call(model, args = c(args, list(data = x)))\n    })\n}\n\n\ndat &lt;- readRDS(here(\"data/emoint.rds\"))\ndat &lt;- filter(dat, emotion_lbl != \"neutral\")\ndat$intensity0 &lt;- (dat$intensity/10) - 1\n\nfit1 &lt;- glmer(acc ~ intensity0 + (intensity0|id),\n             data = dat, \n             family = binomial(link = \"logit\"))\n\nfit10 &lt;- glmer(acc ~ 1 + (1|id),\n              data = dat, \n              family = binomial(link = \"logit\"))\n\nsummary(fit1)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: acc ~ intensity0 + (intensity0 | id)\n   Data: dat\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  30742.3   30783.2  -15366.2   30732.3     26265 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.2930 -0.7394  0.3993  0.7623  2.1703 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n id     (Intercept) 0.069921 0.26443       \n        intensity0  0.007283 0.08534  -0.43\nNumber of obs: 26270, groups:  id, 71\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.09351    0.04058  -26.94   &lt;2e-16 ***\nintensity0   0.33490    0.01148   29.17   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr)\nintensity0 -0.545\n\ncoeff &lt;- coefficients(fit1)$id\nhist(exp(coeff$intensity0))\n\n\n\n\n\n\n\nhist(coeff$intensity0)\n\n\n\n\n\n\n\nplot(fitted(fit1), residuals(fit1, type = \"response\"))\n\n\n\n\n\n\n\n# influence(fit1) # ci mette molto\n\ndat_agg &lt;- dat |&gt; \n    group_by(id, intensity0) |&gt; \n    summarise(nc = sum(acc),\n              nf = n() - nc,\n              p = nc / n(),\n              n = n())\n\n# aggregated vs binary model\n\nfit2 &lt;- glmer(cbind(nc, nf) ~ intensity0 + (intensity0|id),\n             data = dat_agg,\n             family = binomial(link = \"logit\"))\n\nfit20 &lt;- glmer(cbind(nc, nf) ~ 1 + (1|id),\n              data = dat_agg,\n              family = binomial(link = \"logit\"))\n\ncar::compareCoefs(fit1, fit2)\n\nCalls:\n1: glmer(formula = acc ~ intensity0 + (intensity0 | id), data = dat, family \n  = binomial(link = \"logit\"))\n2: glmer(formula = cbind(nc, nf) ~ intensity0 + (intensity0 | id), data = \n  dat_agg, family = binomial(link = \"logit\"))\n\n            Model 1 Model 2\n(Intercept) -1.0935 -1.0935\nSE           0.0406  0.0406\n                           \nintensity0   0.3349  0.3349\nSE           0.0115  0.0115\n                           \n\nanova(fit20, fit2)\n\nData: dat_agg\nModels:\nfit20: cbind(nc, nf) ~ 1 + (1 | id)\nfit2: cbind(nc, nf) ~ intensity0 + (intensity0 | id)\n      npar     AIC   BIC  logLik -2*log(L)  Chisq Df Pr(&gt;Chisq)    \nfit20    2 10100.1 10109 -5048.0   10096.1                         \nfit2     5  5356.2  5379 -2673.1    5346.2 4749.9  3  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(fit10, fit1)\n\nData: dat\nModels:\nfit10: acc ~ 1 + (1 | id)\nfit1: acc ~ intensity0 + (intensity0 | id)\n      npar   AIC   BIC logLik -2*log(L)  Chisq Df Pr(&gt;Chisq)    \nfit10    2 35486 35503 -17741     35482                         \nfit1     5 30742 30783 -15366     30732 4749.9  3  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# nella forma binomial, i residui sono leggermente meglio\n\nplot(fitted(fit2), residuals(fit2, type = \"response\"))\n\n\n\n\n\n\n\n# vediamo la variabilità nelle interazioni\n\nff &lt;- fit_by_cluster(acc ~ emotion_lbl * intensity0 | id,\n               data = dat,\n               model = glm,\n               args = list(family = binomial))\n\nff |&gt; \n    lapply(broom::tidy) |&gt; \n    bind_rows(.id = \"id\") |&gt; \n    filter(grepl(\":\", term)) |&gt; \n    filter(abs(estimate) &lt; 5) |&gt; \n    ggplot(aes(x = estimate, y = id)) +\n    geom_point() +\n    facet_wrap(~term) \n\n\n\n\n\n\n\nto_remove &lt;- ff |&gt; \n    lapply(broom::tidy) |&gt; \n    bind_rows(.id = \"id\") |&gt; \n    filter(grepl(\":\", term)) |&gt; \n    filter(abs(estimate) &gt; 5) |&gt; \n    pull(id) |&gt; \n    unique()\n\nAbbiamo inoltre visto alcuni esempi di Simpson’s Paradox (non nella sua forma più estrema) e come centrare le variabili in modo da separare l’effetto tra i cluster e dentro i cluster:\n\nEsempio con esperimento simulato di sensibilità al contrasto qmd"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html",
    "href": "scripts-lectures/2025-03-31.html",
    "title": "2025-03-31",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html#data",
    "href": "scripts-lectures/2025-03-31.html#data",
    "title": "2025-03-31",
    "section": "Data",
    "text": "Data\n\n# loading the cleaned data version\ndat &lt;- readRDS(here(\"data\", \"emoint.rds\"))"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html#participant-level",
    "href": "scripts-lectures/2025-03-31.html#participant-level",
    "title": "2025-03-31",
    "section": "Participant-level",
    "text": "Participant-level\nLet’s compute some statistics at the participant level:\nOverall accuracy of the experiment:\n\nchance_level &lt;- 1 / length(unique(dat$response))\n\ndat |&gt; \n    group_by(id) |&gt; \n    summarise(acc = mean(acc),\n              n_trials = n()) |&gt;\n    ggplot(aes(x = acc, y = id)) +\n    geom_point(aes(size = n_trials)) +\n    geom_vline(xintercept = chance_level, lwd = 1, lty = \"dashed\")\n\n\n\n\n\n\n\n\nAll the participants are clearly above the chance level. For each trial there was all the 7 options.\n\ndat |&gt; \n    filter(emotion_lbl != \"neutral\") |&gt; \n    group_by(id, emotion_lbl) |&gt; \n    summarise(acc = mean(acc),\n              n_trial = n()) |&gt; \n    ggplot(aes(x = emotion_lbl, y = acc, fill = emotion_lbl)) +\n    geom_point(aes(size = n_trial), position = position_jitter(width = 0.3, seed = 2025), alpha = 0.5, show.legend = FALSE) +\n    geom_boxplot(show.legend = FALSE)\n\n\n\n\n\n\n\n\n\ndat |&gt;\n    filter(emotion_lbl != \"neutral\") |&gt;  \n    group_by(id, intensity) |&gt; \n    summarise(acc = mean(acc)) |&gt; \n    ggplot(aes(x = intensity, y = acc)) +\n    geom_point() +\n    geom_line(aes(group = id), alpha = 0.5) +\n    geom_boxplot(aes(group = intensity))"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html#errors",
    "href": "scripts-lectures/2025-03-31.html#errors",
    "title": "2025-03-31",
    "section": "Errors",
    "text": "Errors\n\ndat |&gt; \n    group_by(emotion_lbl, response_lbl) |&gt; \n    count() |&gt; \n    group_by(emotion_lbl)  |&gt; \n    mutate(tot = sum(n)) |&gt; \n    ungroup() |&gt; \n    mutate(p = n / tot) |&gt; \n    mutate(is_correct = ifelse(emotion_lbl == response_lbl, 1, 0)) |&gt; \n    ggplot(aes(x = response_lbl, fill = factor(is_correct), y = p)) +\n    geom_col(position = position_dodge(), show.legend = FALSE) +\n    facet_wrap(~emotion_lbl, scales = \"free_y\") +\n    theme(\n        axis.text.x = element_text(angle = 90)\n    ) +\n        ylim(c(0,1)) +\n        scale_fill_manual(values = c(scales::alpha(\"black\", 0.5), \"firebrick\"))\n\n\n\n\n\n\n\n\nThis is the proportion of responses for each emotion label as a function of the intensity.\n\ndat |&gt; \n    filter(emotion_lbl != \"neutral\") |&gt; \n    group_by(emotion_lbl, response_lbl, intensity) |&gt; \n    count() |&gt; \n    group_by(emotion_lbl, intensity) |&gt; \n    mutate(tot = sum(n))  |&gt; \n    ungroup() |&gt; \n    mutate(p = n / tot) |&gt; \n    mutate(is_correct = ifelse(emotion_lbl == response_lbl, 1, 0)) |&gt; \n    ggplot(aes(x = intensity, y = p, color = response_lbl)) +\n    facet_wrap(~emotion_lbl) +\n    geom_line(aes(lty = factor(is_correct)), lwd = 1) +\n    scale_linetype_manual(values = c(\"dashed\", \"solid\"), guide = \"none\")"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html#variability-measures",
    "href": "scripts-lectures/2025-03-31.html#variability-measures",
    "title": "2025-03-31",
    "section": "Variability measures",
    "text": "Variability measures\nHere I’m calculating a variability measure (Shannon Entropy) to capture the variability of responses for a specific intensity level for each emotion. Higher entropy means a more uncertain response.\n\nentropy &lt;- function(p, relative = FALSE) {\n  p &lt;- p[p &gt; 0]  # Exclude zero probabilities to avoid log(0)\n  H &lt;- -sum(p * log2(p))\n  \n  if (relative) {\n    H &lt;- H / log2(length(p))\n  }\n  return(H)\n}\n\ndat |&gt; \n    filter(emotion_lbl != \"neutral\") |&gt; \n    group_by(emotion_lbl, response_lbl, intensity) |&gt; \n    count() |&gt; \n    group_by(emotion_lbl, intensity) |&gt; \n    mutate(tot = sum(n))  |&gt; \n    ungroup() |&gt; \n    mutate(p = n / tot) |&gt; \n    mutate(is_correct = ifelse(emotion_lbl == response_lbl, 1, 0)) |&gt; \n    group_by(emotion_lbl, intensity) |&gt; \n    summarise(entropy = entropy(p, relative = TRUE)) |&gt; \n    ggplot(aes(x = intensity, y = entropy)) +\n    geom_line(aes(color = emotion_lbl), lwd = 1)\n\n\n\n\n\n\n\n\n\nget_intersection &lt;- function(y1, y2, x){\n    x[which.min(abs(y1 - y2))]\n}\n\nget_intersection_point &lt;- function(data){\n    data &lt;- data |&gt; \n        select(intensity, response_lbl, p) |&gt; \n        pivot_wider(names_from = response_lbl, values_from = p)\n    datat &lt;- select(data, -intensity)\n    idx &lt;- combn(1:ncol(datat), 2) # variables combination\n    datat &lt;- mutate(datat, across(everything(), replace_na, 0)) # replace NA with 0\n    x &lt;- unique(data$intensity)\n\n    res &lt;- vector(mode = \"list\", length = ncol(idx))\n\n    for(i in 1:length(res)){\n        rc &lt;- idx[, i]\n        ii &lt;- get_intersection(datat[[rc[1]]], datat[[rc[2]]], x)\n        res[[i]] &lt;- data.frame(intensity = ii, emo1 = names(datat)[rc[1]], emo2 = names(datat)[rc[2]])\n    }\n    do.call(rbind, res)\n}\n\nint_point &lt;- dat |&gt; \n    filter(emotion_lbl != \"neutral\") |&gt; \n    group_by(emotion_lbl, response_lbl, intensity) |&gt; \n    count() |&gt; \n    group_by(emotion_lbl, intensity) |&gt; \n    mutate(tot = sum(n))  |&gt; \n    ungroup() |&gt; \n    mutate(p = n / tot) |&gt; \n    group_nest(emotion_lbl) |&gt; \n    mutate(int_point = map(data, get_intersection_point))"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html#face-specific-effects",
    "href": "scripts-lectures/2025-03-31.html#face-specific-effects",
    "title": "2025-03-31",
    "section": "Face-specific effects",
    "text": "Face-specific effects\nWe can also visualize some identity-specific effect to see if the pattern is the same for each face.\n\nby_face &lt;- dat |&gt; \n    filter(emotion_lbl != \"neutral\") |&gt; \n    group_by(face, emotion_lbl, response_lbl, intensity) |&gt; \n    count() |&gt; \n    group_by(emotion_lbl, intensity) |&gt; \n    mutate(tot = sum(n)) |&gt; \n    mutate(p = n/tot) |&gt; \n    group_by(emotion_lbl) |&gt; \n    nest() |&gt; \n    mutate(plt = map(data, function(x){\n        ggplot(x, aes(x = intensity, y = p, color = response_lbl)) +\n            geom_line() +\n            facet_wrap(~face)\n    }))\n\n\ndisgustfearhappinesssadnesssupriseanger"
  },
  {
    "objectID": "scripts-lectures/2025-03-31.html#overall-plot-try-to-reproduce",
    "href": "scripts-lectures/2025-03-31.html#overall-plot-try-to-reproduce",
    "title": "2025-03-31",
    "section": "Overall plot [try to reproduce :)]",
    "text": "Overall plot [try to reproduce :)]\n\ndat |&gt; \n    filter(emotion_lbl != \"neutral\") |&gt; \n    ggplot(aes(x = intensity, y = acc, color = emotion_lbl)) +\n    stat_smooth(aes(group = id), geom = \"line\", method = \"glm\", formula = y ~ x, method.args = list(family = binomial()), se = FALSE, alpha = 0.5) +\n    facet_wrap(~emotion_lbl) +\n    geom_point(position = position_jitter(height = 0.05),\n    alpha = 0.05, color = \"black\") +\n    xlab(\"Intensity\") +\n    ylab(\"Accuracy\") +\n    geom_smooth(aes(x = intensity, y = acc), method = \"glm\", formula = y ~ x, method.args = list(family = binomial()), se = FALSE, color = \"black\") +\n    theme_minimal(base_size = 20) +\n    theme(legend.position = \"none\")"
  },
  {
    "objectID": "scripts-lectures.html",
    "href": "scripts-lectures.html",
    "title": "Psychometrics4Neuroscience",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\n\n\n\n\n2025-04-15\n\n\n\n\n2025-04-08\n\n\n\n\n2025-04-07\n\n\n\n\n2025-04-04\n\n\n\n\n2025-04-01\n\n\n\n\n2025-03-31\n\n\n\n\n2025-03-28\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/three-level-meta-analysis.html",
    "href": "materials/three-level-meta-analysis.html",
    "title": "Three-level meta-analysis",
    "section": "",
    "text": "library(metafor)\ndevtools::load_all()\n\nsim_3l_studies &lt;- function(k,\n                           j,\n                           es = 0,\n                           tau2_k = 0,\n                           tau2_j = 0,\n                           n0,\n                           n1 = NULL,\n                           sample_j = FALSE,\n                           sample_n = NULL,\n                           min_n = NULL,\n                           max_n = NULL){\n    if(sample_j){\n        nj &lt;- sample(1:j, k, replace = TRUE)\n    } else{\n        nj &lt;- rep(j, k)\n    }\n    \n    study &lt;- unlist(lapply(nj, function(x) 1:x))\n    paper &lt;- rep(1:k, nj)\n    sim &lt;- data.frame(paper, study)\n    \n    delta_k &lt;- rnorm(k, 0, sqrt(tau2_k))\n    delta_j &lt;- rnorm(nrow(sim), 0, sqrt(tau2_j))\n    \n    kj &lt;- nrow(sim)\n    \n    if(!is.null(sample_n)){\n        n0 &lt;- round(sample_n(kj))\n        n1 &lt;- round(sample_n(kj))\n    } else{\n        if(length(n0) == 1) n0 &lt;- rep(n0, nrow(sim))\n        if(is.null(n1)) n1 &lt;- n0\n    }\n    \n    es_kj &lt;- es + delta_k[paper] + delta_j\n    ss &lt;- sim_studies(nrow(sim), es_kj, tau2 = 0, n0, n1)\n    cbind(sim, ss)\n}\n\ndat &lt;- sim_3l_studies(k = 100, j = 5, es = 0.3, \n               tau2_k = 0.1, tau2_j = 0.05,\n               n0 = 50, n1 = 50)\n\nfit &lt;- rma.mv(yi, vi, random = ~ 1|paper/id, data = dat, sparse = TRUE)\nsummary(fit)\n\n\nMultivariate Meta-Analysis Model (k = 500; method: REML)\n\n   logLik   Deviance        AIC        BIC       AICc   \n-212.1974   424.3949   430.3949   443.0327   430.4434   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed    factor \nsigma^2.1  0.0971  0.3117    100     no     paper \nsigma^2.2  0.0559  0.2363    500     no  paper/id \n\nTest for Heterogeneity:\nQ(df = 499) = 2434.2626, p-val &lt; .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.3089  0.0341  9.0627  &lt;.0001  0.2421  0.3757  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "materials/multivariate-meta-analysis.html",
    "href": "materials/multivariate-meta-analysis.html",
    "title": "multivariate-meta-analysis",
    "section": "",
    "text": "sim_multi_meta &lt;- function(k, \n                           p,\n                           mus,\n                           tau2s,\n                           ro = 0,\n                           rs = 0,\n                           n = NULL,\n                           sample_p = FALSE,\n                           sample_n = NULL,\n                           ranef = FALSE){\n    \n    RT &lt;- ro + diag(1 - ro, p)\n    RS &lt;- rs + diag(1 - rs, p)\n    S &lt;- diag(sqrt(tau2s)) %*% RT %*% diag(sqrt(tau2s))\n    \n    TT &lt;- MASS::mvrnorm(k, rep(0, p), S)\n    \n    yi &lt;- vi &lt;- deltai &lt;- vector(mode = \"list\", length = k)\n    \n    for(i in 1:k){\n        X0 &lt;- MASS::mvrnorm(n, rep(0, p), RS)\n        X1 &lt;- MASS::mvrnorm(n, mus + TT[i, ], RS)\n        mm0 &lt;- apply(X0, 2, mean)\n        mm1 &lt;- apply(X1, 2, mean)\n        \n        vv0 &lt;- apply(X0, 2, var)\n        vv1 &lt;- apply(X1, 2, var)\n        \n        yi[[i]] &lt;- mm1 - mm0\n        vi[[i]] &lt;- vv0/n + vv1/n\n        deltai[[i]] &lt;- TT[i, ]\n    }\n    \n    if(sample_p){\n        pi &lt;- sample(1:p, k, replace = TRUE)\n    } else{\n        pi &lt;- rep(p, k)\n    }\n    \n    study &lt;- rep(1:k, each = p)\n    outcome &lt;- rep(1:p, k)\n    \n    sim &lt;- data.frame(\n        study,\n        outcome\n    )\n    \n    sim$yi &lt;- unlist(yi)\n    sim$vi &lt;- unlist(vi)\n    \n    if(ranef){\n        sim$deltai &lt;- unlist(deltai)\n    }\n    \n    # selecting studies\n    siml &lt;- split(sim, sim$study)\n    for(i in 1:k){\n        siml[[i]] &lt;- siml[[i]][1:pi[i], ]\n    }\n    sim &lt;- do.call(rbind, siml)\n    sim$outcome &lt;- factor(paste0(\"o\", sim$outcome))\n    rownames(sim) &lt;- NULL\n    return(sim)\n}\n\n\ndat &lt;- sim_multi_meta(k = 500, \n                      p = 3, \n                      mus = c(0.1, 0.5, 0.1), \n                      tau2s = c(0.1, 0.1, 0.1), \n                      RT = 0.5,\n                      RS = 0.5, \n                      n = 1e3, \n                      ranef = FALSE)\n\n\nlibrary(metafor)\n\nV &lt;- vcalc(vi, cluster = study, obs = outcome, rho = 0.5, data = dat)\n\nfit &lt;- rma.mv(yi, \n              V, \n       mods = ~ 0 + outcome, \n       random = ~outcome|study, \n       data = dat,\n       struct = \"UN\",\n       sparse = TRUE)\n\n\nfit"
  },
  {
    "objectID": "materials/glmer/glmer.html",
    "href": "materials/glmer/glmer.html",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "",
    "text": "\\[\n\\mathbf{y}_{N \\times 1} = \\mathbf{X}_{N \\times p} \\boldsymbol{\\beta}_{p \\times 1} + \\sum_{i=1}^{m} \\mathbf{Z}_i^{(N \\times q_i)} \\mathbf{b}_i^{(q_i \\times 1)} + \\boldsymbol{\\varepsilon}_{N \\times 1}\n\\]\nWhere \\(N\\) is the number of observations, \\(p\\) is the number of predictors, \\(q\\) is the number of clusters (e.g., participants) and \\(m\\) is the number of random effects (e.g., nested or crossed)."
  },
  {
    "objectID": "materials/glmer/glmer.html#notation",
    "href": "materials/glmer/glmer.html#notation",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "",
    "text": "\\[\n\\mathbf{y}_{N \\times 1} = \\mathbf{X}_{N \\times p} \\boldsymbol{\\beta}_{p \\times 1} + \\sum_{i=1}^{m} \\mathbf{Z}_i^{(N \\times q_i)} \\mathbf{b}_i^{(q_i \\times 1)} + \\boldsymbol{\\varepsilon}_{N \\times 1}\n\\]\nWhere \\(N\\) is the number of observations, \\(p\\) is the number of predictors, \\(q\\) is the number of clusters (e.g., participants) and \\(m\\) is the number of random effects (e.g., nested or crossed)."
  },
  {
    "objectID": "materials/glmer/glmer.html#visualizing-the-mathbfz-matrix",
    "href": "materials/glmer/glmer.html#visualizing-the-mathbfz-matrix",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Visualizing the \\(\\mathbf{Z}\\) matrix",
    "text": "Visualizing the \\(\\mathbf{Z}\\) matrix\n\ndat &lt;- sleepstudy\nZ &lt;- get_Z_matrix(~ Days + (1|Subject), dat)\nrownames(Z) &lt;- NULL\ncolnames(Z) &lt;- NULL\n\nreshape2::melt(Z) |&gt;\n  ggplot(aes(x = Var1, y = Var2, fill = factor(value), color = factor(value))) +\n  geom_tile(show.legend = FALSE) +\n  scale_fill_manual(values = c(\"transparent\", scales::alpha(\"black\", 0.5))) +\n  scale_color_manual(values = c(\"transparent\", \"black\")) +\n  theme_bw(20) +\n  theme(panel.grid = element_blank(),\n        aspect.ratio = 1) +\n  ylab(latex2exp::TeX(\"$Cluster_q$\")) +\n  xlab(latex2exp::TeX(\"$Observation_i$\"))"
  },
  {
    "objectID": "materials/glmer/glmer.html#why-clustered-data-in-psychology",
    "href": "materials/glmer/glmer.html#why-clustered-data-in-psychology",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Why clustered data in Psychology?",
    "text": "Why clustered data in Psychology?\nIn Psychology and Neuroscience we (almost) always have clustered data. For example:\n\nChildrens nested within classrooms (maybe nested within schools)\nTrials of a cognitive experiments nested within participants\n…\n\nThe main point is that, clustered observations are not independent and we want to take into account the correlation."
  },
  {
    "objectID": "materials/glmer/glmer.html#example-with-lme4sleepstudy",
    "href": "materials/glmer/glmer.html#example-with-lme4sleepstudy",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Example with lme4::sleepstudy",
    "text": "Example with lme4::sleepstudy\nA very simple example is the lme4::sleepstudy where participants reaction times where evaluated under sleep deprivation.\n\ndat &lt;- lme4::sleepstudy\nhead(dat)\n\n#&gt;   Reaction Days Subject\n#&gt; 1 249.5600    0     308\n#&gt; 2 258.7047    1     308\n#&gt; 3 250.8006    2     308\n#&gt; 4 321.4398    3     308\n#&gt; 5 356.8519    4     308\n#&gt; 6 414.6901    5     308"
  },
  {
    "objectID": "materials/glmer/glmer.html#overall-model",
    "href": "materials/glmer/glmer.html#overall-model",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Overall model",
    "text": "Overall model\n\ndat |&gt; \n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point(position = position_jitter(width = 0.1)) +\n  scale_x_continuous(breaks = unique(dat$Days)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  ggtitle(\"Linear Model (ignore dependency)\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#by-participant-model",
    "href": "materials/glmer/glmer.html#by-participant-model",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "By-participant model",
    "text": "By-participant model\n\ndat |&gt; \n  ggplot(aes(x = Days, y = Reaction)) +\n  geom_point(position = position_jitter(width = 0.1)) +\n  facet_wrap(~Subject) +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "materials/glmer/glmer.html#by-participant-model-1",
    "href": "materials/glmer/glmer.html#by-participant-model-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "By-participant model",
    "text": "By-participant model\nFrom the by-participant models, we see a clear dependency. Observations within the same participant are more similar compared to observations across participant.\nIn addition, at Day 0, some participants have higher/lower reaction times compared to the overall trend. Similarly, some participants have higher/lower slopes.\nIndividual differences are the core of Psychology and we want to explictly model them!"
  },
  {
    "objectID": "materials/glmer/glmer.html#individual-differences",
    "href": "materials/glmer/glmer.html#individual-differences",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Individual differences",
    "text": "Individual differences\n\ndat |&gt; \n  ggplot(aes(x = Days, y = Reaction, group = Subject)) +\n  geom_point(position = position_jitter(width = 0.1)) +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "materials/glmer/glmer.html#are-the-observations-clustered",
    "href": "materials/glmer/glmer.html#are-the-observations-clustered",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Are the observations clustered?",
    "text": "Are the observations clustered?\nWe can start assessing the clustering structure by fitting a mixed-model with only the random-intercepts and calculating the intraclass-correlation.\n\\[\ny_{ij} = \\beta_0 + \\beta_{0_i} + \\epsilon_{ij}\n\\]"
  },
  {
    "objectID": "materials/glmer/glmer.html#are-the-observations-clustered-1",
    "href": "materials/glmer/glmer.html#are-the-observations-clustered-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Are the observations clustered?",
    "text": "Are the observations clustered?\nThe model can be fitted with the lme4::lmer() function:\n\nfit0 &lt;- lmer(Reaction ~ 1 + (1|Subject), data = dat)\nsummary(fit0)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Reaction ~ 1 + (1 | Subject)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: 1904.3\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.4983 -0.5501 -0.1476  0.5123  3.3446 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Subject  (Intercept) 1278     35.75   \n#&gt;  Residual             1959     44.26   \n#&gt; Number of obs: 180, groups:  Subject, 18\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   298.51       9.05   32.98"
  },
  {
    "objectID": "materials/glmer/glmer.html#are-the-observations-clustered-2",
    "href": "materials/glmer/glmer.html#are-the-observations-clustered-2",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Are the observations clustered?",
    "text": "Are the observations clustered?\n\n# using the insight::get_variance() function\nvv &lt;- insight::get_variance(fit0)\nvv$var.intercept / (vv$var.intercept + vv$var.residual)\n\n#&gt;   Subject \n#&gt; 0.3948896\n\n# or directly with performance::icc()\nperformance::icc(fit0)\n\n#&gt; # Intraclass Correlation Coefficient\n#&gt; \n#&gt;     Adjusted ICC: 0.395\n#&gt;   Unadjusted ICC: 0.395\n\n\nThus roughly 39% of the variance is explained by the clustering structure."
  },
  {
    "objectID": "materials/glmer/glmer.html#are-the-observations-clustered-3",
    "href": "materials/glmer/glmer.html#are-the-observations-clustered-3",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Are the observations clustered?",
    "text": "Are the observations clustered?\n\ndat |&gt; \n  ggplot(aes(x = Subject, y = Reaction)) +\n  #geom_point(position = position_jitter(width = 0.1))\n  geom_boxplot(fill = \"dodgerblue\") +\n  ggtitle(\"ICC = 39%\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#are-the-observations-clustered-4",
    "href": "materials/glmer/glmer.html#are-the-observations-clustered-4",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Are the observations clustered",
    "text": "Are the observations clustered\nWe can remove the subject-specific effect.\n\ndat |&gt; \n  mutate(Reaction_cmc = cmc(Reaction, Subject)) |&gt; \n  ggplot(aes(x = Subject, y = Reaction_cmc)) +\n  #geom_point(position = position_jitter(width = 0.1))\n  geom_boxplot(fill = \"dodgerblue\") +\n  ylab(\"Reaction (cluster-mean centered)\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#how-different-iccs-appear",
    "href": "materials/glmer/glmer.html#how-different-iccs-appear",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "How different ICCs appear…",
    "text": "How different ICCs appear…\nWe can simulate some datasets with different ICC:\n\nicc &lt;- c(0, 0.3, 0.8)\nsb0 &lt;- sqrt(icc)\n\nb0 &lt;- 0\n\nns &lt;- 10\nnt &lt;- 10\n\nid &lt;- rep(1:ns, each = nt)\n\ny &lt;- vector(mode = \"list\", length = length(icc))\n\nfor(i in 1:length(icc)){\n  b0i &lt;- rnorm(ns, 0, sb0[i])\n  y[[i]] &lt;- b0 + b0i[id] + rnorm(ns * nt, 0, 1 - sb0[i])\n}\n\ndd &lt;- data.frame(\n  id = rep(id, length(sb0)),\n  sb0 = rep(sb0, each = ns * nt),\n  icc = rep(icc, each = ns * nt),\n  y = unlist(y)\n)\n\ndd |&gt; \n  mutate(icc = sprintf(\"ICC = %s\", icc),\n         icc = factor(icc, levels = c(\"ICC = 0\", \"ICC = 0.3\",\"ICC = 0.8\"))) |&gt; \n  ggplot(aes(x = factor(id), y = y)) +\n  geom_boxplot() +\n  facet_wrap(~icc) +\n  xlab(\"Cluster\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#psychological-interpretation-of-random-intercepts",
    "href": "materials/glmer/glmer.html#psychological-interpretation-of-random-intercepts",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Psychological interpretation of random intercepts",
    "text": "Psychological interpretation of random intercepts\nThe random-intercepts are intepreted as baseline variation in the experiment. For example:\n\nvariability at time 0\nvariability pre treatment\nvariability for the reference condition\n…\n\nFurthemore, the ICC (that is related to the random-intercepts variance) affects the statistical power of the model."
  },
  {
    "objectID": "materials/glmer/glmer.html#statistical-power-and-icc",
    "href": "materials/glmer/glmer.html#statistical-power-and-icc",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Statistical power and ICC",
    "text": "Statistical power and ICC\nWe will see how to simulate data in a meaningful way, but here just an example on the impact of ICC on the statistical power.\nI estimate the statistical power (for an intercept-only model) using the analytical method by Hedges and Pigott (2001).\n\npowerICC &lt;- function(nc, ns, d, icc, alpha = 0.05){\n  tau2 &lt;- icc\n  vi &lt;- 1/ns + 1/ns\n  v &lt;- (vi + tau2)/nc\n  z &lt;- d / sqrt(v)\n  zc &lt;- abs(qnorm(alpha/2))\n  1 - pnorm(zc - z) + pnorm(-zc - z)\n}"
  },
  {
    "objectID": "materials/glmer/glmer.html#statistical-power-and-icc-1",
    "href": "materials/glmer/glmer.html#statistical-power-and-icc-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Statistical power and ICC",
    "text": "Statistical power and ICC\n\nsim &lt;- expand.grid(\n  nc = c(1, seq(5, 50, 10)),\n  ns = 20,\n  d = 0.3,\n  icc = c(0, 0.3, 0.5, 0.8)\n) \n\nsim$power &lt;- with(sim, powerICC(nc, ns, d, icc))\n\nsim |&gt; \n  ggplot(aes(x = icc, y = power, color = factor(nc))) +\n  geom_line() +\n  labs(color = \"Clusters\") +\n  xlab(\"ICC\") +\n  ylab(\"Power\") +\n  ggtitle(\"N = 20 (per cluster), d = 0.3\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#icc-in-psychology",
    "href": "materials/glmer/glmer.html#icc-in-psychology",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "ICC in Psychology1",
    "text": "ICC in Psychology1\nIn Psychology it is common to collect clustered data and the data collection is usually time expensive. In addition, sample sizes are usually lower than the optimal level according to power calculation. Rao and Scott (1992) defined the concept of effective sample size for the reduction in the sample size (and thus power) according to the ICC in clustered data.\n\\[\nN_{\\text{eff}} = \\frac{N}{1 + (\\bar k - 1) \\rho}\n\\] Where \\(\\bar k\\) is the average number of observations per cluster.\n\nneff &lt;- function(N, khat, icc){\n  N / (1 + (khat - 1) * icc)\n}"
  },
  {
    "objectID": "materials/glmer/glmer.html#icc-in-psychology-1",
    "href": "materials/glmer/glmer.html#icc-in-psychology-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "ICC in Psychology",
    "text": "ICC in Psychology\n\nN &lt;- 100\nkhat &lt;- 10\nicc &lt;- seq(0, 1, 0.01)\n\nqplot(icc, neff(N, khat, icc), type = \"l\", lwd = 1)"
  },
  {
    "objectID": "materials/glmer/glmer.html#adding-the-fixed-effect",
    "href": "materials/glmer/glmer.html#adding-the-fixed-effect",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Adding the fixed effect",
    "text": "Adding the fixed effect\nThen we can add the fixed effect of Days. The variable is numeric starting with 0 up to 5 days. We can just add the variable as it is.\n\n\nfit1 &lt;- lmer(Reaction ~ Days + (1|Subject), data = dat)\n# equivalent to\n# fit1 &lt;- update(fit0, . ~ . + Days)\n\nsummary(fit1)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Reaction ~ Days + (1 | Subject)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: 1786.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.2257 -0.5529  0.0109  0.5188  4.2506 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  Subject  (Intercept) 1378.2   37.12   \n#&gt;  Residual              960.5   30.99   \n#&gt; Number of obs: 180, groups:  Subject, 18\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept) 251.4051     9.7467   25.79\n#&gt; Days         10.4673     0.8042   13.02\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; Days -0.371"
  },
  {
    "objectID": "materials/glmer/glmer.html#adding-the-fixed-effect-1",
    "href": "materials/glmer/glmer.html#adding-the-fixed-effect-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Adding the fixed effect",
    "text": "Adding the fixed effect\nThis means that for each day we have an expected increase in reaction times of 10.47 milliseconds (or 0.01 seconds).\nWe have only the random intercept for subjects, thus we are assuming that each subject has the same sleep deprivation effect but can have different baseline reaction times.\n\nhead(coef(fit1)$Subject)\n\n#&gt;     (Intercept)     Days\n#&gt; 308    292.1888 10.46729\n#&gt; 309    173.5556 10.46729\n#&gt; 310    188.2965 10.46729\n#&gt; 330    255.8115 10.46729\n#&gt; 331    261.6213 10.46729\n#&gt; 332    259.6263 10.46729\n\n# equivalent to fixef(fit1)[\"(Intercept)\"] + ranef(fit1)$Subject for the random intercept"
  },
  {
    "objectID": "materials/glmer/glmer.html#adding-the-fixed-effect-2",
    "href": "materials/glmer/glmer.html#adding-the-fixed-effect-2",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Adding the fixed effect",
    "text": "Adding the fixed effect\n\ncoef(fit1)$Subject |&gt; \n  mutate(Subject = 1:n()) |&gt; \n  mutate(b0 = fixef(fit1)[1],\n         b1 = fixef(fit1)[2]) |&gt; \n  rename(\"b0i\" = `(Intercept)`,\n         \"b1i\" = `Days`) |&gt; \n  expand_grid(Days = unique(dat$Days)) |&gt; \n  mutate(pi = b0i + b1i * Days,\n         p = b0 + b1 * Days) |&gt; \n  ggplot(aes(x = Days, y = pi)) +\n  geom_line(aes(group = Subject),\n            alpha = 0.5) +\n  geom_line(aes(x = Days, y = p),\n            lwd = 1.5,\n            col = \"firebrick\") +\n  ylab(\"Reaction\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#adding-the-fixed-effect-3",
    "href": "materials/glmer/glmer.html#adding-the-fixed-effect-3",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Adding the fixed effect",
    "text": "Adding the fixed effect\n\ncoef(fit1)$Subject |&gt; \n  mutate(Subject = 1:n()) |&gt; \n  mutate(b0 = fixef(fit1)[1],\n         b1 = fixef(fit1)[2]) |&gt; \n  rename(\"b0i\" = `(Intercept)`,\n         \"b1i\" = `Days`) |&gt; \n  expand_grid(Days = unique(dat$Days)) |&gt; \n  mutate(pi = b0i + b1i * Days,\n         p = b0 + b1 * Days) |&gt; \n  ggplot(aes(x = Days, y = pi)) +\n  geom_line(aes(group = Subject),\n            alpha = 0.5) +\n  geom_line(aes(x = Days, y = p),\n            lwd = 1.5,\n            col = \"firebrick\") +\n  ylab(\"Reaction\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#adding-the-fixed-effect-4",
    "href": "materials/glmer/glmer.html#adding-the-fixed-effect-4",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Adding the fixed effect",
    "text": "Adding the fixed effect\nThe same can be achieved using:\n\nDD &lt;- expand_grid(\n  Subject = unique(dat$Subject),\n  Days = unique(dat$Days)\n)\n\nDD$pi &lt;- predict(fit1, newdata = DD)\n\nhead(DD)\n\n#&gt; # A tibble: 6 × 3\n#&gt;   Subject  Days    pi\n#&gt;   &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 308         0  292.\n#&gt; 2 308         1  303.\n#&gt; 3 308         2  313.\n#&gt; 4 308         3  324.\n#&gt; 5 308         4  334.\n#&gt; 6 308         5  345."
  },
  {
    "objectID": "materials/glmer/glmer.html#is-the-fixed-effect-enough",
    "href": "materials/glmer/glmer.html#is-the-fixed-effect-enough",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Is the fixed effect enough?",
    "text": "Is the fixed effect enough?\nA big problem with mixed models is that effects can be included both as fixed and random and the choice is not always easy. From the plots at the beginning there is a clear variability in slopes that the model is ignoring.\n\nfit2 &lt;- lmer(Reaction ~ Days + (Days|Subject), data = dat)\nsummary(fit2)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: Reaction ~ Days + (Days | Subject)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: 1743.6\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.9536 -0.4634  0.0231  0.4634  5.1793 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr\n#&gt;  Subject  (Intercept) 612.10   24.741       \n#&gt;           Days         35.07    5.922   0.07\n#&gt;  Residual             654.94   25.592       \n#&gt; Number of obs: 180, groups:  Subject, 18\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)  251.405      6.825  36.838\n#&gt; Days          10.467      1.546   6.771\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; Days -0.138"
  },
  {
    "objectID": "materials/glmer/glmer.html#is-the-fixed-effect-enough-1",
    "href": "materials/glmer/glmer.html#is-the-fixed-effect-enough-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Is the fixed effect enough?",
    "text": "Is the fixed effect enough?\nThe first important part is the estimation of the random part. Clearly the random slopes variance is not zero.\n\nfilter_output(summary(fit2), c(\"^Random effects|^Number of obs\"))\n\n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr\n#&gt;  Subject  (Intercept) 612.10   24.741       \n#&gt;           Days         35.07    5.922   0.07\n#&gt;  Residual             654.94   25.592       \n#&gt; Number of obs: 180, groups:  Subject, 18"
  },
  {
    "objectID": "materials/glmer/glmer.html#is-the-fixed-effect-enough-2",
    "href": "materials/glmer/glmer.html#is-the-fixed-effect-enough-2",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Is the fixed effect enough?",
    "text": "Is the fixed effect enough?\nOne of the most important part is that the standard error of the fixed coefficients is affected by the inclusion of the random slopes. Omitting the slopes was underestimating the standard error.\nqualcosa su barr, keep it maximal, etc.\n\ncar::compareCoefs(fit1, fit2)\n\n#&gt; Calls:\n#&gt; 1: lmer(formula = Reaction ~ Days + (1 | Subject), data = dat)\n#&gt; 2: lmer(formula = Reaction ~ Days + (Days | Subject), data = dat)\n#&gt; \n#&gt;             Model 1 Model 2\n#&gt; (Intercept)  251.41  251.41\n#&gt; SE             9.75    6.82\n#&gt;                            \n#&gt; Days         10.467  10.467\n#&gt; SE            0.804   1.546\n#&gt;"
  },
  {
    "objectID": "materials/glmer/glmer.html#is-the-fixed-effect-enough-3",
    "href": "materials/glmer/glmer.html#is-the-fixed-effect-enough-3",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Is the fixed effect enough?",
    "text": "Is the fixed effect enough?\nWe can formally compare the models using a Likelihood Ratio Test (LRT)2:\n\nanova(fit1, fit2)\n\n#&gt; Data: dat\n#&gt; Models:\n#&gt; fit1: Reaction ~ Days + (1 | Subject)\n#&gt; fit2: Reaction ~ Days + (Days | Subject)\n#&gt;      npar    AIC    BIC  logLik -2*log(L)  Chisq Df Pr(&gt;Chisq)    \n#&gt; fit1    4 1802.1 1814.8 -897.04    1794.1                         \n#&gt; fit2    6 1763.9 1783.1 -875.97    1751.9 42.139  2  7.072e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# or ranova(refitML(fit2))"
  },
  {
    "objectID": "materials/glmer/glmer.html#plotting-the-random-slopes",
    "href": "materials/glmer/glmer.html#plotting-the-random-slopes",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Plotting the random slopes",
    "text": "Plotting the random slopes\n\nDD &lt;- expand_grid(\n  Subject = unique(dat$Subject),\n  Days = unique(dat$Days)\n)\n\nDD$pi &lt;- predict(fit2, newdata = DD)\n\nDD |&gt; \n  ggplot(aes(x = Days, y = pi, group = Subject)) +\n  geom_line() +\n  xlab(\"Days\") +\n  ylab(\"Reaction\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#shrinkage",
    "href": "materials/glmer/glmer.html#shrinkage",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Shrinkage!",
    "text": "Shrinkage!\nWe can compare the fit of the multilevel model with linear models for each cluster. We can use the fit_by_cluster() function tha takes a formula, a grouping factor and fit a model for each cluster.\n\nfitl &lt;- fit_by_cluster(Reaction ~ Days | Subject,\n                       dat,\n                       model = lm)"
  },
  {
    "objectID": "materials/glmer/glmer.html#shrinkage-1",
    "href": "materials/glmer/glmer.html#shrinkage-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Shrinkage!",
    "text": "Shrinkage!\n\nfitl &lt;- fit_by_cluster(Reaction ~ Days | Subject,\n                       dat,\n                       model = lm)\n\nDD &lt;- expand_grid(\n  Subject = unique(dat$Subject),\n  Days = unique(dat$Days)\n)\n\nDD$lmer &lt;- predict(fit2, DD)\nDD$Subject &lt;- as.numeric(as.character(DD$Subject))\n\nsubjs &lt;- unique(DD$Subject)\nDD$lm &lt;- NA\n\nfor(i in 1:length(fitl)){\n  pp &lt;- predict(fitl[[i]], DD[DD$Subject == subjs[i], ])\n  DD$lm[DD$Subject == subjs[i]] &lt;- pp\n}\n\nDD |&gt; \n  pivot_longer(c(lmer, lm)) |&gt; \n  ggplot(aes(x = Days, y = value, color = name)) +\n  geom_line(lwd = 1) +\n  facet_wrap(~Subject) +\n  ylab(\"Reaction\") +\n  labs(color = \"Method\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model",
    "href": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s try to simulate the previous model",
    "text": "Let’s try to simulate the previous model\n\n\nN &lt;- 10\nDAYS &lt;- 10 # max number of days\nb00 &lt;- 300 # grand-mean of reaction times at time 0\nb1 &lt;- 20  # increase in reaction time for each day\nsb0 &lt;- 30 # standard deviation intercepts\nsb1 &lt;- 10 # standard deviaton slopes\ns &lt;- 100 # residual standard deviation\n\n# we are simulating an ICC of\nsb0^2 / (sb0^2 + s^2)\n#&gt; [1] 0.08256881\n\nsim &lt;- expand_grid(\n  id = 1:N,\n  days = 0:(DAYS - 1)\n)\n\n# random intercepts and slopes, rho = 0\n\nR &lt;- 0 + diag(1 - 0, 2)\nVCOV &lt;- diag(c(sb0, sb1)) %*% R %*% diag(c(sb0, sb1))\n\nRE &lt;- MASS::mvrnorm(N, c(0, 0), VCOV)\n\nb0i &lt;- RE[, 1]\nb1i &lt;- RE[, 2]\n\n# linear predictor\nsim$lp &lt;- with(sim, b00 + b0i[id] + (b1 + b1i[id]) * days)\nsim$rt &lt;- rnorm(nrow(sim), sim$lp, s)"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-1",
    "href": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s try to simulate the previous model",
    "text": "Let’s try to simulate the previous model\n\nsim |&gt; \n  ggplot(aes(x = rt)) +\n  geom_histogram(color = \"black\",\n                 fill = \"dodgerblue\") +\n  xlab(\"Reaction Times\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-2",
    "href": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-2",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s try to simulate the previous model",
    "text": "Let’s try to simulate the previous model\n\nsim |&gt; \n  ggplot(aes(x = days, y = rt)) +\n  geom_point() +\n  scale_x_continuous(breaks = 0:DAYS) +\n  xlab(\"Days\") +\n  ylab(\"Reaction Times\") +\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              aes(group = id))"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-3",
    "href": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-3",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s try to simulate the previous model",
    "text": "Let’s try to simulate the previous model\n\nsim |&gt; \n  ggplot(aes(x = days, y = rt)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = 0:DAYS) +\n  xlab(\"Days\") +\n  ylab(\"Reaction Times\") +\n  facet_wrap(~id, ncol = 4) +\n  geom_smooth(method = \"lm\",\n              se = FALSE)"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-4",
    "href": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-4",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s try to simulate the previous model",
    "text": "Let’s try to simulate the previous model\nA more realistic scenario could be to have an heterogeneous number of observations for each cluster.\n\n\n# minimum 3 observations\nndays_per_subject &lt;- sample(3:(DAYS - 1), size = N, replace = TRUE)\nsiml &lt;- split(sim, sim$id)\n\nfor(i in 1:length(siml)){\n  siml[[i]] &lt;- siml[[i]][1:ndays_per_subject[i], ]\n}\n\nsim_missing &lt;- do.call(rbind, siml)\n\n# number of observations\ntapply(sim_missing$rt, sim_missing$id, length)\n#&gt;  1  2  3  4  5  6  7  8  9 10 \n#&gt;  8  3  3  6  9  5  4  5  7  4"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-5",
    "href": "materials/glmer/glmer.html#lets-try-to-simulate-the-previous-model-5",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s try to simulate the previous model",
    "text": "Let’s try to simulate the previous model\n\nsim_missing |&gt; \n  ggplot(aes(x = days, y = rt)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = 0:DAYS) +\n  xlab(\"Days\") +\n  ylab(\"Reaction Times\") +\n  facet_wrap(~id, ncol = 4) +\n  geom_smooth(method = \"lm\",\n              se = FALSE)"
  },
  {
    "objectID": "materials/glmer/glmer.html#lets-fit-the-model",
    "href": "materials/glmer/glmer.html#lets-fit-the-model",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Let’s fit the model",
    "text": "Let’s fit the model\nHere the random-intercepts and slopes model:\n\n\nfit &lt;- lmer(rt ~ days + (days|id), data = sim_missing)\nsummary(fit)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: rt ~ days + (days | id)\n#&gt;    Data: sim_missing\n#&gt; \n#&gt; REML criterion at convergence: 650\n#&gt; \n#&gt; Scaled residuals: \n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.10251 -0.66077  0.00732  0.63516  2.01985 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  id       (Intercept)  3543.5   59.53        \n#&gt;           days          451.5   21.25   -0.77\n#&gt;  Residual             10994.3  104.85        \n#&gt; Number of obs: 54, groups:  id, 10\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept)   313.18      30.20  10.369\n#&gt; days           12.14      11.03   1.101\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;      (Intr)\n#&gt; days -0.761"
  },
  {
    "objectID": "materials/glmer/glmer.html#what-do-you-see-in-this-plot",
    "href": "materials/glmer/glmer.html#what-do-you-see-in-this-plot",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "What do you see in this plot?",
    "text": "What do you see in this plot?\n\nk &lt;- 10 # number of clusters/units\nn &lt;- 100 # number of participants within each unit\nN &lt;- n * k # total sample size\nunit &lt;- rep(1:k, each = n)\n\nage &lt;- rnorm(N, 60 - 3 * (unit - 1), 5) # age equation\ny &lt;- 0 + rnorm(k, 0, 0.1)[unit] + 0.01 * age + 0.1 * (unit-1) + rnorm(N, 0, 0.1) # response equation\ndat &lt;- data.frame(unit, age, y)\n\n\ndat |&gt; \n  ggplot(aes(x = age, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n. . .\nThere is a clear negative relationship between age and the response variable y!"
  },
  {
    "objectID": "materials/glmer/glmer.html#what-do-you-see-in-this-plot-1",
    "href": "materials/glmer/glmer.html#what-do-you-see-in-this-plot-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "What do you see in this plot?",
    "text": "What do you see in this plot?\nLet’s add the cluster information. What about now?\n\ndat |&gt; \n  ggplot(aes(x = age, y = y)) +\n  geom_point(aes(color = factor(unit))) +\n  labs(color = \"Cluster\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox",
    "href": "materials/glmer/glmer.html#simpsons-paradox",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\n\nWe have clustered data, and the relationship y ~ age seems to be different within and between clusters.\nThis phenomenon is called Simpson’s paradox and can be a serious problem in multilevel models.\nClearly this is a problem only for variables at the observation level (not at the cluster level).\nFor example, if clusters are schools and the observations are children. age is a variable at the children level (or aggregated at the school level). On the other side, the prestige of the school is a variable at the school level (the same for each child)"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-1",
    "href": "materials/glmer/glmer.html#simpsons-paradox-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox",
    "text": "Simpson’s paradox\n\ndat |&gt; \n  ggplot(aes(x = age, y = y)) +\n  geom_point(aes(color = factor(unit))) +\n  labs(color = \"Cluster\") + \n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              col = \"black\") +\n  geom_smooth(method = \"lm\",\n              aes(group = unit,\n                  color = factor(unit)),\n              se = FALSE)"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-what-to-do",
    "href": "materials/glmer/glmer.html#simpsons-paradox-what-to-do",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, what to do?",
    "text": "Simpson’s paradox, what to do?\nThe main strategy to deal with the Simpson’s paradox is centering the variables. Enders and Tofighi (2007) provide a clear overview of the strategy."
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-what-to-do-1",
    "href": "materials/glmer/glmer.html#simpsons-paradox-what-to-do-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, what to do?",
    "text": "Simpson’s paradox, what to do?\nWe can define some centering functions and see how we can model the multilevel structure.\n\nfilor::print_fun(c(funs$cm, funs$cmc, funs$gmc))\ncm &lt;- function(x, cluster){\n  cm &lt;- tapply(x, cluster, mean)\n  cm[cluster]\n}\ncmc &lt;- function(x, cluster){\n  x - cm(x, cluster)\n}\ngmc &lt;- function(x){\n  x - mean(x)\n}"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-between-clusters-effect",
    "href": "materials/glmer/glmer.html#simpsons-paradox-between-clusters-effect",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, between-clusters effect",
    "text": "Simpson’s paradox, between-clusters effect\nFirsly we can calculate the clusters mean. This remove the within-effect and a linear model will capture only the between-effect.\n\ndat |&gt; \n  mutate(age_cm = cm(age, unit),\n         y_cm = cm(y, unit)) |&gt; \n  ggplot(aes(x = age, y = y)) +\n  geom_point(alpha = 0.2,\n             aes(color = factor(unit))) +\n  geom_point(aes(x = age_cm, y = y_cm,\n                 color = factor(unit)),\n             alpha = 1,\n             size = 4) +\n  labs(color = \"Unit\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-between-clusters-effect-1",
    "href": "materials/glmer/glmer.html#simpsons-paradox-between-clusters-effect-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, between-clusters effect",
    "text": "Simpson’s paradox, between-clusters effect\nWe have a negative age effect between clusters, as expected.\n\ndat_cm &lt;- dat |&gt; \n  group_by(unit) |&gt; \n  summarise(y_cm = mean(y),\n            age_cm = mean(age))\n\nlm(y_cm ~ age_cm, data = dat_cm)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y_cm ~ age_cm, data = dat_cm)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)       age_cm  \n#&gt;     1.92527     -0.02175"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-within-clusters-effect",
    "href": "materials/glmer/glmer.html#simpsons-paradox-within-clusters-effect",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, within-clusters effect",
    "text": "Simpson’s paradox, within-clusters effect\nWe can substract (i.e., centering) from each observation, the cluster mean.\n\ndat |&gt; \n  mutate(age_cm = cm(age, unit),\n         age_cmc = cmc(age, unit),\n         y_cm = cm(y, unit)) |&gt; \n  ggplot(aes(x = age_cmc, y = y)) +\n  geom_point(alpha = 0.2,\n             aes(color = factor(unit))) +\n  xlab(latex2exp::TeX(\"$age - \\\\; \\\\bar{age_k}$\")) +\n  geom_point(aes(x = 0, y = y_cm,\n                 color = factor(unit))) +\n  geom_smooth(method = \"lm\",\n              aes(group = unit,\n                  color = factor(unit)),\n              se = FALSE) +\n  labs(color = \"Unit\")"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-within-clusters-effect-1",
    "href": "materials/glmer/glmer.html#simpsons-paradox-within-clusters-effect-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, within-clusters effect",
    "text": "Simpson’s paradox, within-clusters effect\n\ndat$age_cmc &lt;- cmc(dat$age, dat$unit)\n\nfitl_cmc &lt;- fit_by_cluster(\n  y ~ age_cmc | unit,\n  data = dat,\n  model = lm\n)"
  },
  {
    "objectID": "materials/glmer/glmer.html#simpsons-paradox-within-clusters-effect-2",
    "href": "materials/glmer/glmer.html#simpsons-paradox-within-clusters-effect-2",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Simpson’s paradox, within-clusters effect",
    "text": "Simpson’s paradox, within-clusters effect\nAll slopes are similar but positive (compared to the between-effect). Thus estimating only the between (or within) effect is completely misleading.\n\nfitl_cmc |&gt; \n  lapply(broom::tidy, conf.int = TRUE) |&gt; \n  bind_rows(.id = \"unit\") |&gt; \n  mutate(unit = as.numeric(unit)) |&gt; \n  filter(term == \"age_cmc\") |&gt; \n  ggplot(aes(x = estimate, y = unit)) +\n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) +\n  geom_vline(xintercept = 0,\n             lty = \"dashed\",\n             col = \"firebrick\") +\n  xlab(latex2exp::TeX(\"$\\\\beta_{age}$\"))"
  },
  {
    "objectID": "materials/glmer/glmer.html#what-about-the-multilevel-model",
    "href": "materials/glmer/glmer.html#what-about-the-multilevel-model",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "What about the multilevel model?",
    "text": "What about the multilevel model?\nWe can fit a multilevel model on the full dataset. What is the age slope? within or between?\n\n\nfit &lt;- lmer(y ~ age + (1|unit), data = dat)\nsummary(fit)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ age + (1 | unit)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: -1710.7\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.7439 -0.6848 -0.0165  0.7191  3.0376 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  unit     (Intercept) 0.091429 0.30237 \n#&gt;  Residual             0.009747 0.09872 \n#&gt; Number of obs: 1000, groups:  unit, 10\n#&gt; \n#&gt; Fixed effects:\n#&gt;              Estimate Std. Error t value\n#&gt; (Intercept) 0.4471843  0.0997411   4.483\n#&gt; age         0.0100761  0.0006074  16.590\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; age -0.283"
  },
  {
    "objectID": "materials/glmer/glmer.html#what-about-the-multilevel-model-1",
    "href": "materials/glmer/glmer.html#what-about-the-multilevel-model-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "What about the multilevel model?",
    "text": "What about the multilevel model?\nThe estimated effect is a sort of weighted average of the within and between effect. This is usually not interesting, especially when the two effects are different. We want to isolate the between and within effects.\nWe need to include two version of the age variable, one centered on the clusters and the other representing the clusters means.\n\ndat$age_cmc &lt;- cmc(dat$age, dat$unit)\ndat$age_cm &lt;- cm(dat$age, dat$unit)\n\nfit_bw &lt;- lmer(y ~ age_cmc + age_cm + (1|unit), data = dat)"
  },
  {
    "objectID": "materials/glmer/glmer.html#what-about-the-multilevel-model-2",
    "href": "materials/glmer/glmer.html#what-about-the-multilevel-model-2",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "What about the multilevel model?",
    "text": "What about the multilevel model?\n\nsummary(fit_bw)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ age_cmc + age_cm + (1 | unit)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: -1724.4\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.7518 -0.6848 -0.0136  0.7126  3.0452 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev.\n#&gt;  unit     (Intercept) 0.007530 0.08678 \n#&gt;  Residual             0.009746 0.09872 \n#&gt; Number of obs: 1000, groups:  unit, 10\n#&gt; \n#&gt; Fixed effects:\n#&gt;               Estimate Std. Error t value\n#&gt; (Intercept)  1.9252710  0.1503998  12.801\n#&gt; age_cmc      0.0101730  0.0006083  16.724\n#&gt; age_cm      -0.0217498  0.0031833  -6.832\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;         (Intr) ag_cmc\n#&gt; age_cmc  0.000       \n#&gt; age_cm  -0.983  0.000"
  },
  {
    "objectID": "materials/glmer/glmer.html#what-about-the-multilevel-model-3",
    "href": "materials/glmer/glmer.html#what-about-the-multilevel-model-3",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "What about the multilevel model?",
    "text": "What about the multilevel model?\nThe within-clusters effect can be also included as random slope3. Basically we allows not only the within effect to be different compared to the between effect but also that each cluster has a different sloope.\n\nfit_bw2 &lt;- lmer(y ~ age_cmc + age_cm + (age_cmc|unit), data = dat)\nsummary(fit_bw2)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ age_cmc + age_cm + (age_cmc | unit)\n#&gt;    Data: dat\n#&gt; \n#&gt; REML criterion at convergence: -1724.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.7516 -0.6911 -0.0114  0.7116  3.0458 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance  Std.Dev.  Corr\n#&gt;  unit     (Intercept) 7.528e-03 0.0867634     \n#&gt;           age_cmc     2.053e-08 0.0001433 1.00\n#&gt;  Residual             9.746e-03 0.0987213     \n#&gt; Number of obs: 1000, groups:  unit, 10\n#&gt; \n#&gt; Fixed effects:\n#&gt;              Estimate Std. Error t value\n#&gt; (Intercept)  1.933188   0.149989  12.889\n#&gt; age_cmc      0.010176   0.000610  16.683\n#&gt; age_cm      -0.021920   0.003174  -6.905\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;         (Intr) ag_cmc\n#&gt; age_cmc  0.020       \n#&gt; age_cm  -0.983 -0.006\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')"
  },
  {
    "objectID": "materials/glmer/glmer.html#more-on-the-simpsons-paradox",
    "href": "materials/glmer/glmer.html#more-on-the-simpsons-paradox",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "More on the Simpson’s Paradox",
    "text": "More on the Simpson’s Paradox\nKievit et al. (2013) describe the SP problem in Psychology with methods to detect it.\n\nWhat do you think?"
  },
  {
    "objectID": "materials/glmer/glmer.html#practical-session",
    "href": "materials/glmer/glmer.html#practical-session",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Practical session",
    "text": "Practical session\n\nsimulate clustered data with some predictors\nsimulate the same dataset but with a some between-within differences"
  },
  {
    "objectID": "materials/glmer/glmer.html#the-performance-package",
    "href": "materials/glmer/glmer.html#the-performance-package",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "The performance package",
    "text": "The performance package\nThe performance package has a series of nice functions to visualize and assess the models fit.\nLet’s go back to our reaction times:\n\nfit &lt;- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)\n\nperformance::check_model(fit)"
  },
  {
    "objectID": "materials/glmer/glmer.html#the-performance-package-1",
    "href": "materials/glmer/glmer.html#the-performance-package-1",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "The performance package",
    "text": "The performance package\n\nfit &lt;- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)\n\nperformance::check_model(fit)"
  },
  {
    "objectID": "materials/glmer/glmer.html#influence-measures",
    "href": "materials/glmer/glmer.html#influence-measures",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Influence measures",
    "text": "Influence measures\nNieuwenhuis et al. (2012) describe the Influence.ME package that computes the standard influence measures (Cook’s distance, DFbeta, etc.) for lme4 models.\nAlso the lme4:::influence.merMod() compute all the measures. You can provide the groups = argument to specify at which level performing the leave-one-out procedure."
  },
  {
    "objectID": "materials/glmer/glmer.html#influence-measures-small-exercise",
    "href": "materials/glmer/glmer.html#influence-measures-small-exercise",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Influence measures, small exercise",
    "text": "Influence measures, small exercise\nBoth lme4:::influence.merMod() and Influence.ME do not provide (good enough) plotting tools. Write a set of functions that takes a lme4 model in input, calculate the influence measures, organize everything in a data.frame and plot the influence measures results with ggplot2."
  },
  {
    "objectID": "materials/glmer/glmer.html#r2-for-multilevel-models",
    "href": "materials/glmer/glmer.html#r2-for-multilevel-models",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "\\(R^2\\) for multilevel models",
    "text": "\\(R^2\\) for multilevel models\nThe \\(R^2\\) for multilevel models is not computed as for standard regression models. Nakagawa, Johnson, and Schielzeth (2017) describe how to calculate the \\(R^2\\). They described the marginal (only fixed-effects) and the conditional (fixed and random-effects).\n\n# or performance::r2()\nperformance::r2_nakagawa(fit)\n\n#&gt; # R2 for Mixed Models\n#&gt; \n#&gt;   Conditional R2: 0.799\n#&gt;      Marginal R2: 0.279\n\n\nClearly the conditional is always greater or equal to the marginal one."
  },
  {
    "objectID": "materials/glmer/glmer.html#footnotes",
    "href": "materials/glmer/glmer.html#footnotes",
    "title": "Generalized Linear Mixed-Effects Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is just an approximation to estimate the impact of the ICC↩︎\nNote that the anova() function is refitting models using Maximum Likelihood (and not REML). This is required to compare models using LRT↩︎\nOf course, including the clusters means as random-slopes is not possible. Note that data are simulated without random slopes, thus the model estimate parameters at the boundaries↩︎"
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html",
    "href": "materials/baseR-vs-tidyverse.html",
    "title": "Base R vs Tidyverse",
    "section": "",
    "text": "In this exercise, we will use two datasets:\n\nThe iris dataset for complex operations on grouped data.\nThe mtcars dataset for reshaping between long and wide formats.\n\nThis will allow us to compare different data manipulation tasks using base R and the tidyverse."
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html#base-r-solution",
    "href": "materials/baseR-vs-tidyverse.html#base-r-solution",
    "title": "Base R vs Tidyverse",
    "section": "Base R Solution",
    "text": "Base R Solution\n\n# Load the iris dataset\ndata(iris)\n\n# Base R approach using tapply and aggregate\nmean_sd_base &lt;- aggregate(cbind(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) ~ Species, data = iris, \n                          FUN = function(x) c(mean = mean(x), sd = sd(x)))\n\n# Flatten the results\nmean_sd_base &lt;- do.call(data.frame, mean_sd_base)\n\n# Display the result\nmean_sd_base\n\n     Species Sepal.Length.mean Sepal.Length.sd Sepal.Width.mean Sepal.Width.sd\n1     setosa             5.006       0.3524897            3.428      0.3790644\n2 versicolor             5.936       0.5161711            2.770      0.3137983\n3  virginica             6.588       0.6358796            2.974      0.3224966\n  Petal.Length.mean Petal.Length.sd Petal.Width.mean Petal.Width.sd\n1             1.462       0.1736640            0.246      0.1053856\n2             4.260       0.4699110            1.326      0.1977527\n3             5.552       0.5518947            2.026      0.2746501"
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html#tidyverse-solution",
    "href": "materials/baseR-vs-tidyverse.html#tidyverse-solution",
    "title": "Base R vs Tidyverse",
    "section": "Tidyverse Solution",
    "text": "Tidyverse Solution\n\n# Load the tidyverse package\nlibrary(tidyverse)\n\n# Tidyverse approach using dplyr\nmean_sd_tidy &lt;- iris %&gt;%\n  group_by(Species) %&gt;%\n  summarize(across(starts_with(\"Sepal\") | starts_with(\"Petal\"), \n                   list(mean = ~mean(.), sd = ~sd(.)), \n                   .names = \"{col}_{fn}\"))\n\n# Display the result\nmean_sd_tidy\n\n# A tibble: 3 × 9\n  Species    Sepal.Length_mean Sepal.Length_sd Sepal.Width_mean Sepal.Width_sd\n  &lt;fct&gt;                  &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 setosa                  5.01           0.352             3.43          0.379\n2 versicolor              5.94           0.516             2.77          0.314\n3 virginica               6.59           0.636             2.97          0.322\n# ℹ 4 more variables: Petal.Length_mean &lt;dbl&gt;, Petal.Length_sd &lt;dbl&gt;,\n#   Petal.Width_mean &lt;dbl&gt;, Petal.Width_sd &lt;dbl&gt;"
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html#base-r-solution-1",
    "href": "materials/baseR-vs-tidyverse.html#base-r-solution-1",
    "title": "Base R vs Tidyverse",
    "section": "Base R Solution",
    "text": "Base R Solution\n\n# Load the mtcars dataset\ndata(mtcars)\n\n# Add car names as a column instead of row names\nmtcars$car &lt;- rownames(mtcars)\n\n# Base R approach to long format\nmtcars_long_base &lt;- reshape(mtcars, idvar = \"car\", varying = names(mtcars)[1:11], \n                            v.names = \"value\", timevar = \"variable\", \n                            times = names(mtcars)[1:11], direction = \"long\")\n\n# Back to wide format\nmtcars_wide_base &lt;- reshape(mtcars_long_base, idvar = \"car\", timevar = \"variable\", \n                            direction = \"wide\")\n\n# Display results\nhead(mtcars_long_base)\n\n                                    car variable value\nMazda RX4.mpg                 Mazda RX4      mpg  21.0\nMazda RX4 Wag.mpg         Mazda RX4 Wag      mpg  21.0\nDatsun 710.mpg               Datsun 710      mpg  22.8\nHornet 4 Drive.mpg       Hornet 4 Drive      mpg  21.4\nHornet Sportabout.mpg Hornet Sportabout      mpg  18.7\nValiant.mpg                     Valiant      mpg  18.1\n\nhead(mtcars_wide_base)\n\n                                    car value.mpg value.cyl value.disp value.hp\nMazda RX4.mpg                 Mazda RX4      21.0         6        160      110\nMazda RX4 Wag.mpg         Mazda RX4 Wag      21.0         6        160      110\nDatsun 710.mpg               Datsun 710      22.8         4        108       93\nHornet 4 Drive.mpg       Hornet 4 Drive      21.4         6        258      110\nHornet Sportabout.mpg Hornet Sportabout      18.7         8        360      175\nValiant.mpg                     Valiant      18.1         6        225      105\n                      value.drat value.wt value.qsec value.vs value.am\nMazda RX4.mpg               3.90    2.620      16.46        0        1\nMazda RX4 Wag.mpg           3.90    2.875      17.02        0        1\nDatsun 710.mpg              3.85    2.320      18.61        1        1\nHornet 4 Drive.mpg          3.08    3.215      19.44        1        0\nHornet Sportabout.mpg       3.15    3.440      17.02        0        0\nValiant.mpg                 2.76    3.460      20.22        1        0\n                      value.gear value.carb\nMazda RX4.mpg                  4          4\nMazda RX4 Wag.mpg              4          4\nDatsun 710.mpg                 4          1\nHornet 4 Drive.mpg             3          1\nHornet Sportabout.mpg          3          2\nValiant.mpg                    3          1"
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html#tidyverse-solution-1",
    "href": "materials/baseR-vs-tidyverse.html#tidyverse-solution-1",
    "title": "Base R vs Tidyverse",
    "section": "Tidyverse Solution",
    "text": "Tidyverse Solution\n\n# Tidyverse approach to long format\nmtcars_long_tidy &lt;- mtcars %&gt;% \n  pivot_longer(cols = -car, names_to = \"variable\", values_to = \"value\")\n\n# Back to wide format\nmtcars_wide_tidy &lt;- mtcars_long_tidy %&gt;% \n  pivot_wider(names_from = variable, values_from = value)\n\n# Display results\nhead(mtcars_long_tidy)\n\n# A tibble: 6 × 3\n  car       variable  value\n  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n1 Mazda RX4 mpg       21   \n2 Mazda RX4 cyl        6   \n3 Mazda RX4 disp     160   \n4 Mazda RX4 hp       110   \n5 Mazda RX4 drat       3.9 \n6 Mazda RX4 wt         2.62\n\nhead(mtcars_wide_tidy)\n\n# A tibble: 6 × 12\n  car            mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mazda RX4     21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2 Mazda RX4 W…  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3 Datsun 710    22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4 Hornet 4 Dr…  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1\n5 Hornet Spor…  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n6 Valiant       18.1     6   225   105  2.76  3.46  20.2     1     0     3     1"
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html#pros-and-cons-of-base-r",
    "href": "materials/baseR-vs-tidyverse.html#pros-and-cons-of-base-r",
    "title": "Base R vs Tidyverse",
    "section": "Pros and Cons of Base R",
    "text": "Pros and Cons of Base R\n\nPros:\n\nFlexibility: Base R allows detailed control over transformations.\nNo external dependencies: No need to install additional packages.\nSuitable for simple tasks: If transformations are minimal, base R can be effective.\n\n\n\nCons:\n\nVerbose: Base R code for reshaping data is long and requires multiple parameters.\nLess intuitive: The syntax for reshape() can be confusing.\nMore manual work: Intermediate steps often need to be managed explicitly."
  },
  {
    "objectID": "materials/baseR-vs-tidyverse.html#pros-and-cons-of-tidyverse",
    "href": "materials/baseR-vs-tidyverse.html#pros-and-cons-of-tidyverse",
    "title": "Base R vs Tidyverse",
    "section": "Pros and Cons of Tidyverse",
    "text": "Pros and Cons of Tidyverse\n\nPros:\n\nConcise and readable: Functions like pivot_longer() and pivot_wider() are intuitive.\nStreamlined workflow: Tidyverse simplifies common operations like grouping and reshaping.\nBetter suited for modern data analysis: Works well with pipes and declarative transformations.\n\n\n\nCons:\n\nRequires package installation: Tidyverse needs additional dependencies.\nLearning curve: Users new to functional programming might need time to adapt.\nMay not cover every niche use case: Highly specific transformations might need workarounds."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting started",
    "section": "",
    "text": "Shared Notepad: online notepad to share the R code during the class.\nShared Drive: folder to share files and script if necessary\n\n\nQRcode always redirecting here:"
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "Getting started",
    "section": "Quarto",
    "text": "Quarto\nQuarto is an an open-source scientific and technical publishing system. It is very easy to install and you can find instructions here https://quarto.org/docs/get-started/.\nTo check if Quarto is installed, you can open a terminal (e.g., Powershell or CMD in Windows) and type:\nquarto --version\nThis should return the version of Quarto without errors or strange messages."
  },
  {
    "objectID": "index.html#gitgithub",
    "href": "index.html#gitgithub",
    "title": "Getting started",
    "section": "Git/Github",
    "text": "Git/Github\nGit is a version-control system that you can easily install from here https://git-scm.com/. You can use Git from the command line depending on your operating system or you can use the Github Desktop software https://desktop.github.com/download/ to work with a GUI.\nGithub is the online version of Git and works as an online repository to share and store the code. In order to work with Git and Github you need to:\n\ncreate an account https://github.com/\nconfigure your local machine with an SSH key (with this you do not need to write the password every time). Configuring an SSH key is not so easy thus I suggest you to use the Github CLI tool https://cli.github.com/ where you can configure your account using SSH very easily. The instructions can be found here https://cli.github.com/manual/gh_auth_login and we need to use the gh auth login command.\n\nAlso here you can check the Git installation typing this command in the terminal:\ngit --version"
  },
  {
    "objectID": "index.html#cloning-the-repository",
    "href": "index.html#cloning-the-repository",
    "title": "Getting started",
    "section": "Cloning the repository",
    "text": "Cloning the repository\nNow that we have all the tools we can clone the repository of the course. You can navigate into the folder that you want in your machine and type:\ngit clone git@github.com:stat-teaching/psychometrics4neuroscience.git\nOr manually (but there will not be the Git-Github link) downloading the zip folder from https://github.com/stat-teaching/psychometrics4neuroscience.\nIf you cloned the repository you can navigate into the folder and type:\ngit status\nThis should return some info or messages not errors or messages related to non being in a Git repository.\nNow you have the repository of the course. I will update this repository during the course with new slides and materials.\nDo not modify the files and everytime you start working or using this repository run:\ngit pull\nAnd your local repository will be updated."
  },
  {
    "objectID": "index.html#creating-your-repository",
    "href": "index.html#creating-your-repository",
    "title": "Getting started",
    "section": "Creating your repository",
    "text": "Creating your repository\nFor the course exercises, notes and everything else, I suggest you to create a local folder to track with Git and Github. Follow these steps:\n\ncreate an R Project\ncreate an R/ folder\ninit the git repository with the command git init\nadd all files with git add .\ncommit the changes with git commit -m \"message\"\n\nThen you need to create and link the online repository. Go to Github and create a new empty repository. Copy the SSH address and run git remote add origin &lt;ssh link&gt;. Then run git push. In this way your local and online Git repositories will be linked.\nCheck these other resources to learn Git:\n\nhttps://rogerdudler.github.io/git-guide/\nhttps://www.freecodecamp.org/news/learn-the-basics-of-git-in-under-10-minutes-da548267cc91/"
  },
  {
    "objectID": "index.html#renv",
    "href": "index.html#renv",
    "title": "Getting started",
    "section": "renv",
    "text": "renv\nrenv is the equivalent of venv in Python. Basically allows to create a by-project library of R packages with a specific version. Sometimes packages change defaults, functions, etc. thus fixing them improve the reproducibility and remove unexpected results.\nFor a detailed guide about renv you can read the official documentation https://rstudio.github.io/renv/articles/renv.html.\nWhen opening the R project of the repository, renv should prompt you to install renv itself (if missing) and then to install the packages included into the renv.lock file.\nTo create new project with renv you can type:\nrenv::init()\nand following the instructions. renv will create all the required files and folders and switch to the local library."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Psychometrics4Neuroscience",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nscript\n\n\n\n\n\n\nBase R vs Tidyverse\n\n\n \n\n\n\n\nFunctional programming examples\n\n\n \n\n\n\n\nGeneralized Linear Mixed-Effects Models\n\n\n \n\n\n\n\nmeta-analysis-examples\n\n\n \n\n\n\n\nmultivariate-meta-analysis\n\n\n \n\n\n\n\nSignal Detection Theory\n\n\n \n\n\n\n\nThree-level meta-analysis\n\n\n \n\n\n\n\nUseful GLMER tools\n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/functional-programming-examples.html",
    "href": "materials/functional-programming-examples.html",
    "title": "Functional programming examples",
    "section": "",
    "text": "library(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(purrr)\n\ndat &lt;- iris\n\n# functions\n\nremove_rownames &lt;- function(x){\n    rownames(x) &lt;- NULL\n    x\n}\n\nsum_lm &lt;- function(x, conf.level = 0.95){\n    xs &lt;- data.frame(summary(x)$coefficients)\n    xs$param &lt;- rownames(xs)\n    rownames(xs) &lt;- NULL\n    names(xs) &lt;- c(\"b\", \"se\", \"t\", \"pval\", \"param\")\n    cc &lt;- data.frame(confint(x, level = conf.level))\n    names(cc) &lt;- c(\"ci.lb\", \"ci.ub\")\n    rownames(cc) &lt;- NULL\n    cbind(\n        xs[, c(\"param\", \"b\", \"se\", \"t\", \"pval\")],\n        cc\n    )\n}\n\n# fit a linear model for each Species\n\ndatl &lt;- split(dat, dat$Species)\nfitl &lt;- lapply(datl, function(d) lm(Sepal.Length ~ Petal.Width + Petal.Length, data = d))\nresl &lt;- lapply(fitl, sum_lm)\n\nres_by_species &lt;- do.call(rbind, resl)\nres_by_species &lt;- remove_rownames(res_by_species)\nres_by_species$species &lt;- rep(names(resl), sapply(resl, nrow))\n\nggplot(res_by_species, aes(x = param, \n                           y = b, \n                           ymin = ci.lb, \n                           ymax = ci.ub,\n                           color = species)) +\n    geom_pointrange(position = position_dodge(width = 0.5))\n\n\n\n\n\n\n\n# alternative version using other packages\n\nresl &lt;- lapply(fitl, broom::tidy, conf.int = TRUE)\nres_by_species &lt;- dplyr::bind_rows(resl, .id = \"species\")\n\nres_by_species\n\n# A tibble: 9 × 8\n  species    term       estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 setosa     (Intercep…  4.25       0.411    10.3    1.13e-13   3.42       5.08 \n2 setosa     Petal.Wid…  0.712      0.487     1.46   1.51e- 1  -0.268      1.69 \n3 setosa     Petal.Len…  0.399      0.296     1.35   1.84e- 1  -0.196      0.994\n4 versicolor (Intercep…  2.38       0.449     5.30   3.04e- 6   1.48       3.28 \n5 versicolor Petal.Wid… -0.320      0.402    -0.795  4.30e- 1  -1.13       0.489\n6 versicolor Petal.Len…  0.934      0.169     5.52   1.44e- 6   0.594      1.27 \n7 virginica  (Intercep…  1.05       0.514     2.05   4.63e- 2   0.0179     2.09 \n8 virginica  Petal.Wid…  0.00706    0.179     0.0394 9.69e- 1  -0.354      0.368\n9 virginica  Petal.Len…  0.995      0.0893   11.1    8.87e-15   0.815      1.17 \n\n# bootstrapping\n\nboot &lt;- function(data, B = 100){\n    res &lt;- vector(mode = \"list\", length = B)\n    n &lt;- nrow(data)\n    for(i in 1:B){\n        idx &lt;- sample(x = 1:n, size = n, replace = TRUE)\n        dataB &lt;- data[idx, ]\n        rownames(dataB) &lt;- NULL\n        res[[i]] &lt;- dataB\n    }\n    return(res)\n}\n\nfit_lm &lt;- function(data){\n    lm(Sepal.Length ~ Petal.Width + Petal.Length, data = data)\n}\n\nbootl &lt;- lapply(datl, boot, B = 100)\nfit_bootl &lt;- lapply(bootl, function(x) lapply(x, fit_lm))\nres_bootl &lt;- lapply(fit_bootl, function(x) lapply(x, sum_lm))\nres_bootl &lt;- lapply(res_bootl, function(x) do.call(rbind, x))\nres_boot_by_species &lt;- do.call(rbind, res_bootl)\nres_boot_by_species &lt;- remove_rownames(res_boot_by_species)\nres_boot_by_species$species &lt;- rep(names(res_bootl), sapply(res_bootl, nrow))\n\nggplot(res_boot_by_species, aes(x = param, y = b, fill = species)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n# using nested tibbles\n\ndat |&gt; \n    group_by(Species) |&gt; \n    nest() |&gt; \n    mutate(boot = map(data, boot)) |&gt; \n    select(-data) |&gt; \n    unnest(boot) |&gt; \n    mutate(fit = map(boot, fit_lm)) |&gt; \n    mutate(res = map(fit, sum_lm)) |&gt; \n    select(-boot, -fit) |&gt; \n    unnest(res)\n\n# A tibble: 900 × 8\n# Groups:   Species [3]\n   Species param            b    se      t     pval  ci.lb ci.ub\n   &lt;fct&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 setosa  (Intercept)  4.27  0.369 11.6   2.20e-15  3.53  5.01 \n 2 setosa  Petal.Width  1.57  0.596  2.64  1.12e- 2  0.376 2.77 \n 3 setosa  Petal.Length 0.280 0.265  1.06  2.96e- 1 -0.253 0.813\n 4 setosa  (Intercept)  3.62  0.460  7.87  4.02e-10  2.70  4.55 \n 5 setosa  Petal.Width  0.457 0.575  0.796 4.30e- 1 -0.699 1.61 \n 6 setosa  Petal.Length 0.847 0.353  2.40  2.05e- 2  0.136 1.56 \n 7 setosa  (Intercept)  4.17  0.473  8.81  1.62e-11  3.22  5.12 \n 8 setosa  Petal.Width  0.297 0.469  0.632 5.30e- 1 -0.648 1.24 \n 9 setosa  Petal.Length 0.591 0.348  1.70  9.63e- 2 -0.110 1.29 \n10 setosa  (Intercept)  4.22  0.431  9.78  6.55e-13  3.35  5.08 \n# ℹ 890 more rows"
  },
  {
    "objectID": "materials/signal-detection-theory.html",
    "href": "materials/signal-detection-theory.html",
    "title": "Signal Detection Theory",
    "section": "",
    "text": "devtools::load_all()\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(here)\n\nmtheme &lt;- function(){\n    theme_minimal(20)\n}\n\ntheme_set(mtheme())\n\nfuns &lt;- filor::get_funs(here(\"R\", \"utils-glm_phd.R\"))"
  },
  {
    "objectID": "materials/signal-detection-theory.html#probit-link-1",
    "href": "materials/signal-detection-theory.html#probit-link-1",
    "title": "Signal Detection Theory",
    "section": "Probit link",
    "text": "Probit link\n\nThe mostly used link function when using a binomial GLM is the logit link. The probit link is another link function that can be used. The overall approach is the same between logit and probit models. The only difference is the parameter interpretation (i.e., no odds ratios) and the specific link function (and the inverse) to use.\nThe probit model use the cumulative normal distribution but the actual difference with a logit functions is neglegible."
  },
  {
    "objectID": "materials/signal-detection-theory.html#probit-link-2",
    "href": "materials/signal-detection-theory.html#probit-link-2",
    "title": "Signal Detection Theory",
    "section": "Probit link",
    "text": "Probit link"
  },
  {
    "objectID": "materials/signal-detection-theory.html#probit-link-3",
    "href": "materials/signal-detection-theory.html#probit-link-3",
    "title": "Signal Detection Theory",
    "section": "Probit link",
    "text": "Probit link\nWhen using the probit link the parameters are interpreted as difference in z-scores associated with a unit increase in the predictors. In fact probabilities are mapped into z-scores using the cumulative normal distribution.\n\np1 &lt;- 0.7\np2 &lt;- 0.5\n\nqlogis(c(p1, p2)) # log(odds(p1)), logit link\n\n[1] 0.8472979 0.0000000\n\nqnorm(c(p1, p2)) # probit link\n\n[1] 0.5244005 0.0000000\n\nlog(odds_ratio(p1, p2)) # ~ beta1, logit link\n\n[1] 0.8472979\n\npnorm(p1) - pnorm(p2) # ~beta1, probit link\n\n[1] 0.06657389"
  },
  {
    "objectID": "materials/signal-detection-theory.html#probit-link-4",
    "href": "materials/signal-detection-theory.html#probit-link-4",
    "title": "Signal Detection Theory",
    "section": "Probit link",
    "text": "Probit link"
  },
  {
    "objectID": "materials/signal-detection-theory.html#signal-detection-theory",
    "href": "materials/signal-detection-theory.html#signal-detection-theory",
    "title": "Signal Detection Theory",
    "section": "Signal Detection Theory",
    "text": "Signal Detection Theory\nIl modello probit è utilizzato per stimare i parametri della signal detection theory.\nBrevemente l’idea è quella di modellare decisioni binarie (o anche come rating) rispetto a come uno stimolo viene percepito ed elaborato internamente.\nLa teoria (nella sua versione di base) assume che uno stimolo (segnale) venga elaborato e l’informazione contenuta sostenga un qualche tipo di decisione su questo stimolo.\nAd esempio, immaginiamo di voler valutare la capacità di un radiologo di rilevare la presenza di un’anomalia in una radiografia. Possiamo immaginare di prendere 100 radiografie. 50 di queste contengono un’anomalia (signal trials) mentre 50 non la contengono (catch trials).\nPer ogni radiografia, chiediamo ai radiologi di valutare se rilevano un’anomalia oppure no.\nIncrociando lo stimolo (signal o catch) e la risposta (presente o assente) otteniamo una tipica tabella di contingenza 2x2, simile a quello che si ottiene nei test diagnostici.\n\n\n\n\nSegnale: Si\nSegnale: No\n\n\n\n\nRisposta: Si\nHit (H)\nFalse Alarm (FA)\n\n\nRisposta: No\nMiss (M)\nCorrect Rejection (CR)\n\n\n\nIn questo tipo di classificazione solitamente è ottimale massimizzare gli Hit (o True Positive) e minimizzare i False Alarm (False Positive).\nLa teoria formalizza che le distribuzioni del segnale e del rumore sono delle Gaussiane standard. La distribuzione del rumore ha \\(\\mu = 0\\) mentre la distribuzione del segnale ha \\(\\mu = d'\\). In questo modo il parametro \\(d'\\) (pronunciato d-prime) rappresenta il grado di separazione tra segnale e rumore.\nUna radiografia che contiene un segno chiaramente visibile avrà molta separazione tra le due distribuzioni mentre una radiografia con un segnale molto debole avrà più sovrapposizione.\n\n\n\n\n\n\n\n\n\nOra, questa rappresentazione interna del segnale e del rumore che dipende dal tipo di stimolo e dall’abilità del soggetto. Tuttavia noi non osserviamo direttamente questa variabile latente ma la riposta si/no del soggetto.\nIl soggetto quindi, in base ad un qualche tipo di regola interna, decide di rispondere. La SDT formalizza questa regola interna come una soglia (criterio) che viene decisa internamente dal soggetto. Se in quel trial (radiografia) il segnale supera la soglia, il soggetto risponde Si, se non supera la soglia il soggetto risponde no.\nQuindi con la stessa intensità del segnale \\(d'\\) soggetti diversi o lo stesso soggetto in condizioni diverse può avere un pattern di risposte diverse.\nCi sono alcuni punti importanti:\n\nqualcunque criterio si scelga (in condizioni plausibili) non è mai possibile annullare i falsi allarmi e massimizzare gli hit\nquando il criterio è nel mezzo tra le due distribuzioni (\\(d'/2\\)) viene definito unbiased\nquando il soggetto (a prescindere dal segnale) tende a dare più risposte si viene definito un criterio liberale\nquando il soggetto (a prescindere dal segnale) tende a dare più risposte no viene definito un criterio conservatore\n\n\n\n\n\n\n\n\n\n\nQuindi, per ogni possibile criterio (assumendo di poterlo variare sperimentalmente) abbiamo una diversa tabella di contingenza. Se lo facciamo tante volte, otteniamo una curva:\n\n\nCode\nd &lt;- 1\ndat &lt;- sim_sdt(1e3, d = d, 0.5)\nmid &lt;- d/2\ncr &lt;- c(-Inf, seq(mid - 4, mid + 4, 0.001), Inf)\nres &lt;- sdt(is_signal = dat$is_signal, x = dat$x, c = cr)\n\ndata.frame(res) |&gt; \n    ggplot(aes(x = pfa, y = phit)) +\n    geom_line() +\n    ylim(c(0, 1)) +\n    scale_x_reverse(limits = c(1, 0)) +\n    geom_abline(slope = -1, col = alpha(\"black\", 0.5)) +\n    xlab(\"P (FA)\") +\n    ylab(\"P (Hit)\") +\n    ggtitle(\"d' = 1\")\n\n\n\n\n\n\n\n\n\nQuesta in altri contesti (come quello dei test diagnostici) viene chiamata curva di ROC. Infatti l’area under the curve (AUC) assumendo la normalità delle due distribuzioni è:\n\\[\n\\mbox{AUC} = \\Phi(\\frac{d'}{\\sqrt{2}})\n\\] Quindi:\n\nd &lt;- 1 # dalla simulazione precedente\npnorm(1 / sqrt(2))\n\n[1] 0.7602499\n\n\n\ndata.frame(res) |&gt; \n    pivot_longer(c(phit, pfa, pmiss, pcr)) |&gt; \n    ggplot(aes(x = c, y = value, color = name)) +\n    geom_line() +\n    theme(legend.title = element_blank()) +\n    xlab(\"Criterio\") +\n    ylab(\"Probabilità\")\n\n\n\n\n\n\n\n\nTornando all’esperimento delle radiografie, quello che osserviamo empiricamente è qualcosa di questo tipo (dati simulati usando sim_sdt()):\n\ndat &lt;- sim_sdt(100, 1, c = 0.5) |&gt; \n    select(-x)\nhead(dat)\n\n  say_signal is_signal\n1          0         0\n2          1         1\n3          0         0\n4          1         1\n5          0         0\n6          0         1\n\n\nDove is_signal indica se la radiografia contiene il segnale o no e say_signal indica la risposta del soggetto.\nIn questo caso il \\(d'\\) è la distanza tra la distribuzione latente di segnale e rumore e \\(c\\) è il criterio di risposta.\n\ncl &lt;- sdt(is_signal = dat$is_signal, dat$say_signal)\ncl\n\n$hit\n[1] 12\n\n$miss\n[1] 13\n\n$fa\n[1] 4\n\n$cr\n[1] 21\n\n$phit\n[1] 0.48\n\n$pfa\n[1] 0.16\n\n$pmiss\n[1] 0.52\n\n$pcr\n[1] 0.84\n\n$c\n[1] NA\n\n\nPossiamo semplicemente calcolare la distanza tra le due distribuzioni, assumendo che siano gaussiane a varianza 1:\n\n# dprime\nqnorm(cl$phit) - qnorm(cl$pfa)\n\n[1] 0.9443043\n\n# criterio\n-(qnorm(cl$phit) + qnorm(cl$pfa)) / 2 # - perchè per convenzione c negativo = liberale, c positivo = conservatore\n\n[1] 0.5223057\n\n\nGli stessi parametri possono essere stimati con un glm binomiale con link function probit. Infatti il criterio è il punto di mezzo tra signal e noise mentre il \\(d'\\) non è altro che la distanza tra le due distribuzioni (di segnale e rumore).\nSe facciamo un modello predicendo le risposte (binarie) con il tipo di trial (binario) otteniamo esattamente questi parametri.\n\ndat$say_signal01 &lt;- as.integer(as.character(dat$say_signal))\n\nfit &lt;- glm(say_signal01 ~ is_signal, data = dat, family = binomial(link = \"probit\"))\n\nsummary(fit)\n\n\nCall:\nglm(formula = say_signal01 ~ is_signal, family = binomial(link = \"probit\"), \n    data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -0.05015    0.25078  -0.200    0.841  \nis_signal0  -0.94430    0.39204  -2.409    0.016 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.687  on 49  degrees of freedom\nResidual deviance: 56.601  on 48  degrees of freedom\nAIC: 60.601\n\nNumber of Fisher Scoring iterations: 3\n\n\nL’intercetta è la probabilità (in \\(z\\) scores) di rispondere Si quando il segnale è 0 (catch). Quindi è la probabilità di fare falsi allarmi.\nLa slope è la distanza (in \\(z\\) scores) tra i trial con il segnale e con il rumore che è esattamente il concetto di \\(d'\\). Cambia solo il segno rispetto a quello calcolato manualmente.\nPer calcolare anche il criterio nel modo convenzionale è sufficiente centrare il predittore is_signal:\n\nfit &lt;- glm(say_signal01 ~ is_signal, \n           data = dat,\n           contrasts = list(is_signal = contr.sum(2)/2), # -0.5, 0.5\n           family = binomial(link = \"probit\"))\n\nsummary(fit)\n\n\nCall:\nglm(formula = say_signal01 ~ is_signal, family = binomial(link = \"probit\"), \n    data = dat, contrasts = list(is_signal = contr.sum(2)/2))\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  -0.5223     0.1960  -2.665  0.00771 **\nis_signal1    0.9443     0.3920   2.409  0.01601 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.687  on 49  degrees of freedom\nResidual deviance: 56.601  on 48  degrees of freedom\nAIC: 60.601\n\nNumber of Fisher Scoring iterations: 3\n\n\nAttenzione che per come è parametrizzato, il criterio ha il segno opposto rispetto a quello convenzionale.\nIl vantaggio è che possiamo inserire dei predittori sia per il criterio che per il \\(d'\\). Ad esempio, immaginiamo che ci siano 100 radiografie che indagano un’ipotetica condizione a bassa mortalità vs una condizione ad alta mortalità. Potremmo immaginare che in funzione dell’incentivo decisionale lo stile di risposta possa cambiare (da più a meno conservativo/liberale).\n\n\n  say_signal is_signal          x cond\n1          0         0 -1.0198272  low\n2          1         1  1.3471905  low\n3          1         0  0.6164624  low\n4          1         1  0.4093837  low\n5          0         0 -1.1217480  low\n6          1         1  0.3081716  low\n\n\n\nfit_low &lt;- glm(say_signal ~ is_signal,\n               subset = cond == \"low\",\n               contrasts = list(is_signal = -contr.sum(2)/2),\n               data = dat, \n               family = binomial(link = \"probit\"))\n\nfit_high &lt;- glm(say_signal ~ is_signal,\n               subset = cond == \"high\",\n               contrasts = list(is_signal = -contr.sum(2)/2),\n               data = dat, \n               family = binomial(link = \"probit\"))\n\n\nfit &lt;- glm(say_signal ~ is_signal * cond, \n           contrasts = list(is_signal = -contr.sum(2)/2),\n           data = dat, \n           family = binomial(link = \"probit\"))\n\n\ncar::compareCoefs(fit_low, fit_high, fit)\n\nCalls:\n1: glm(formula = say_signal ~ is_signal, family = binomial(link = \"probit\"),\n   data = dat, subset = cond == \"low\", contrasts = list(is_signal = \n  -contr.sum(2)/2))\n2: glm(formula = say_signal ~ is_signal, family = binomial(link = \"probit\"),\n   data = dat, subset = cond == \"high\", contrasts = list(is_signal = \n  -contr.sum(2)/2))\n3: glm(formula = say_signal ~ is_signal * cond, family = binomial(link = \n  \"probit\"), data = dat, contrasts = list(is_signal = -contr.sum(2)/2))\n\n                   Model 1 Model 2 Model 3\n(Intercept)        -0.5246  0.4992  0.4992\nSE                  0.0197  0.0197  0.0197\n                                          \nis_signal1          1.0031  1.0405  1.0405\nSE                  0.0395  0.0394  0.0394\n                                          \ncondlow                            -1.0238\nSE                                  0.0279\n                                          \nis_signal1:condlow                 -0.0374\nSE                                  0.0558\n                                          \n\nlibrary(multcomp)\n\nglht(fit, \n     linfct = c(\n         \"-(Intercept) == 0\",\n         # criterion low\n         \"-(Intercept) + condlow == 0\",\n         # dprime condition high\n         \"is_signal1 == 0\",\n         # dprime condition low\n         \"is_signal1 + is_signal1:condlow == 0\",\n         # difference between criterion\n         \"condlow == 0\",\n         # difference between dprime\n         \"is_signal1:condlow == 0\"\n     )\n) |&gt; summary()\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nFit: glm(formula = say_signal ~ is_signal * cond, family = binomial(link = \"probit\"), \n    data = dat, contrasts = list(is_signal = -contr.sum(2)/2))\n\nLinear Hypotheses:\n                                     Estimate Std. Error z value Pr(&gt;|z|)    \n-(Intercept) == 0                    -0.49919    0.01971 -25.325   &lt;1e-05 ***\n-(Intercept) + condlow == 0          -1.52300    0.04409 -34.544   &lt;1e-05 ***\nis_signal1 == 0                       1.04048    0.03942  26.394   &lt;1e-05 ***\nis_signal1 + is_signal1:condlow == 0  1.00313    0.03948  25.406   &lt;1e-05 ***\ncondlow == 0                         -1.02381    0.02790 -36.699   &lt;1e-05 ***\nis_signal1:condlow == 0              -0.03735    0.05579  -0.669    0.928    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nInfine, un aspetto interessante è che in qualunque caso, il criterio unbiased è quello che massimizza l’accuratezza intesa come HIT + CR.\n\ndat &lt;- sim_sdt(1e4, 1, 0)\ncr &lt;- seq(-3, 3, 0.1)\nres &lt;- sdt(dat$is_signal, x = dat$x, c = cr)\nres &lt;- data.frame(res)\n\nres |&gt; \n    mutate(acc = 0.5 * (phit + pcr)) |&gt; \n    ggplot(aes(x = c, y = acc)) +\n    geom_line() +\n    xlab(\"Criterio\") +\n    ylab(\"pCR + pHIT\")\n\n\n\n\n\n\n\n\nPer tutti gli esempi ho simulato i dati usando due funzioni custom:\nsim_sdt &lt;- function(nt, d, c = 0, ps = 0.5, sr = 1){\n  ns &lt;- floor(ps * nt)\n  nn &lt;- nt - ns\n  is_signal &lt;- rep(c(0, 1), nn, ns)\n  x &lt;- ifelse(is_signal == 1, rnorm(ns, d/2, sr), rnorm(nn, -d/2, 1))\n  say_signal &lt;- ifelse(x &gt; c, 1, 0)\n  is_signal &lt;- factor(is_signal, levels = c(1,0))\n  say_signal &lt;- factor(say_signal, levels = c(1,0))\n  data.frame(say_signal, is_signal, x)\n}\nsdt &lt;- function(is_signal, say_signal = NULL, x = NULL, c = NULL){\n\n  if(is.null(say_signal)){\n    say_signal &lt;- lapply(c, function(ci) ifelse(x &gt; ci, 1, 0))\n  }else{\n    say_signal &lt;- list(say_signal)\n    c &lt;- NA\n  }\n\n  hit &lt;- miss &lt;- fa &lt;- cr &lt;- rep(0, length(c))\n\n  for(i in 1:length(c)){\n    hit[i] &lt;- sum(is_signal == 1 & say_signal[[i]] == 1)\n    miss[i] &lt;- sum(is_signal == 1 & say_signal[[i]] == 0)\n    fa[i] &lt;- sum(is_signal == 0 & say_signal[[i]] == 1)\n    cr[i] &lt;- sum(is_signal == 0 & say_signal[[i]] == 0)\n  }\n\n  list(hit = hit,\n       miss = miss,\n       fa = fa,\n       cr = cr,\n       phit = hit / (hit + miss),\n       pfa = fa / (fa + cr),\n       pmiss = miss / (miss + hit),\n       pcr = cr / (cr + fa),\n       c = c)\n}"
  },
  {
    "objectID": "materials/signal-detection-theory.html#esempio-con-dati-veri",
    "href": "materials/signal-detection-theory.html#esempio-con-dati-veri",
    "title": "Signal Detection Theory",
    "section": "Esempio con dati veri",
    "text": "Esempio con dati veri\nPartendo da questo tutorial https://vuorre.com/posts/sdt-regression/index.html usiamo il dataset data/sdt-example.rds.\n\ndat &lt;- readRDS(here(\"data\", \"sdt-example.rds\"))\nhead(dat)\n\n# A tibble: 6 × 4\n  pid   trial stimulus response\n  &lt;fct&gt; &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;   \n1 1         1 Old      New     \n2 1         2 Old      New     \n3 1         3 Old      New     \n4 1         4 Old      New     \n5 1         5 Old      New     \n6 1         6 Old      New     \n\n\n\nper ogni soggetto calcoliamo i parametri di SDT (Hit, FA, etc.)\ncalcoliamo manualmente \\(d'\\) e criterio con il pacchetto psycho::dprime()\nfittiamo un modello probit multilivello per stimare i parametri e confrontiamoli"
  },
  {
    "objectID": "materials/useful-glmer-tools.html",
    "href": "materials/useful-glmer-tools.html",
    "title": "Useful GLMER tools",
    "section": "",
    "text": "library(lme4)\nlibrary(equatiomatic)\n\n\nfit_lme4 &lt;- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)\nequatiomatic::extract_eq(fit_lme4)\n\n\\[\n\\begin{aligned}\n  \\operatorname{Reaction}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{Days}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n,\n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} \\\\\n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}}\n  \\end{array}\n\\right)\n\\right)\n    \\text{, for Subject j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "materials/useful-glmer-tools.html#equations-from-models",
    "href": "materials/useful-glmer-tools.html#equations-from-models",
    "title": "Useful GLMER tools",
    "section": "",
    "text": "library(lme4)\nlibrary(equatiomatic)\n\n\nfit_lme4 &lt;- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)\nequatiomatic::extract_eq(fit_lme4)\n\n\\[\n\\begin{aligned}\n  \\operatorname{Reaction}_{i}  &\\sim N \\left(\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{Days}), \\sigma^2 \\right) \\\\    \n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n,\n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} \\\\\n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}}\n  \\end{array}\n\\right)\n\\right)\n    \\text{, for Subject j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "materials/useful-glmer-tools.html#plotting-effects",
    "href": "materials/useful-glmer-tools.html#plotting-effects",
    "title": "Useful GLMER tools",
    "section": "Plotting effects",
    "text": "Plotting effects\n\nlibrary(effects)\nplot(allEffects(fit_lme4))\n\n\n\n\n\n\n\n\n\nlibrary(ggeffects)\nlibrary(ggplot2)\n\nplot(ggeffect(fit_lme4)) +\n    ggtitle(\"Amazing Title\")"
  },
  {
    "objectID": "materials/useful-glmer-tools.html#marginal-effects",
    "href": "materials/useful-glmer-tools.html#marginal-effects",
    "title": "Useful GLMER tools",
    "section": "Marginal effects",
    "text": "Marginal effects\n\nlibrary(emmeans)\n\nfit &lt;- lm(Sepal.Length ~ Petal.Width * Species, data = iris)\nemmeans(fit, ~ Species)\n\n Species    emmean     SE  df lower.CL upper.CL\n setosa       5.89 0.6225 144     4.66     7.12\n versicolor   5.76 0.0807 144     5.60     5.91\n virginica    6.05 0.2168 144     5.62     6.48\n\nConfidence level used: 0.95 \n\n# comparisons\nemmeans(fit, pairwise ~ Species)\n\n$emmeans\n Species    emmean     SE  df lower.CL upper.CL\n setosa       5.89 0.6225 144     4.66     7.12\n versicolor   5.76 0.0807 144     5.60     5.91\n virginica    6.05 0.2168 144     5.62     6.48\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast               estimate    SE  df t.ratio p.value\n setosa - versicolor       0.137 0.628 144   0.219  0.9739\n setosa - virginica       -0.157 0.659 144  -0.238  0.9691\n versicolor - virginica   -0.295 0.231 144  -1.274  0.4121\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n# comparison fixing Petal.Width\nemmeans(fit, pairwise ~ Species, at = list(Petal.Width = 1))\n\n$emmeans\n Species    emmean    SE  df lower.CL upper.CL\n setosa       5.71 0.494 144     4.73     6.68\n versicolor   5.47 0.132 144     5.21     5.73\n virginica    5.92 0.264 144     5.40     6.44\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast               estimate    SE  df t.ratio p.value\n setosa - versicolor       0.236 0.511 144   0.462  0.8890\n setosa - virginica       -0.213 0.560 144  -0.380  0.9236\n versicolor - virginica   -0.449 0.295 144  -1.521  0.2840\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n# comparison of slopes\n\nemtrends(fit, ~ Species, var = \"Petal.Width\")\n\n Species    Petal.Width.trend    SE  df lower.CL upper.CL\n setosa                 0.930 0.649 144   -0.353     2.21\n versicolor             1.426 0.346 144    0.743     2.11\n virginica              0.651 0.249 144    0.159     1.14\n\nConfidence level used: 0.95 \n\nemtrends(fit, pairwise ~ Species, var = \"Petal.Width\")\n\n$emtrends\n Species    Petal.Width.trend    SE  df lower.CL upper.CL\n setosa                 0.930 0.649 144   -0.353     2.21\n versicolor             1.426 0.346 144    0.743     2.11\n virginica              0.651 0.249 144    0.159     1.14\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast               estimate    SE  df t.ratio p.value\n setosa - versicolor      -0.496 0.736 144  -0.675  0.7786\n setosa - virginica        0.279 0.695 144   0.402  0.9149\n versicolor - virginica    0.776 0.426 144   1.819  0.1669\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n# factorial designs\nwarp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)\nemmeans (warp.lm,  pairwise ~ wool | tension)\n\n$emmeans\ntension = L:\n wool emmean   SE df lower.CL upper.CL\n A      44.6 3.65 48     37.2     51.9\n B      28.2 3.65 48     20.9     35.6\n\ntension = M:\n wool emmean   SE df lower.CL upper.CL\n A      24.0 3.65 48     16.7     31.3\n B      28.8 3.65 48     21.4     36.1\n\ntension = H:\n wool emmean   SE df lower.CL upper.CL\n A      24.6 3.65 48     17.2     31.9\n B      18.8 3.65 48     11.4     26.1\n\nConfidence level used: 0.95 \n\n$contrasts\ntension = L:\n contrast estimate   SE df t.ratio p.value\n A - B       16.33 5.16 48   3.167  0.0027\n\ntension = M:\n contrast estimate   SE df t.ratio p.value\n A - B       -4.78 5.16 48  -0.926  0.3589\n\ntension = H:\n contrast estimate   SE df t.ratio p.value\n A - B        5.78 5.16 48   1.120  0.2682\n\n\nAlso the marginaleffects package is amazing."
  },
  {
    "objectID": "materials/useful-glmer-tools.html#tables",
    "href": "materials/useful-glmer-tools.html#tables",
    "title": "Useful GLMER tools",
    "section": "Tables",
    "text": "Tables\n\nlibrary(sjPlot)\n\ntab_model(fit)\n\n\n\n\n\n\n\n\n\n\n \nSepal.Length\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n4.78\n4.43 – 5.12\n&lt;0.001\n\n\nPetal Width\n0.93\n-0.35 – 2.21\n0.154\n\n\nSpecies [versicolor]\n-0.73\n-1.71 – 0.25\n0.141\n\n\nSpecies [virginica]\n0.49\n-0.57 – 1.56\n0.362\n\n\nPetal Width × Species\n[versicolor]\n0.50\n-0.96 – 1.95\n0.501\n\n\nPetal Width × Species\n[virginica]\n-0.28\n-1.65 – 1.09\n0.688\n\n\nObservations\n150\n\n\nR2 / R2 adjusted\n0.677 / 0.666\n\n\n\n\n\n\ntab_model(fit_lme4)\n\n\n\n \nReaction\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n251.41\n237.94 – 264.87\n&lt;0.001\n\n\nDays\n10.47\n7.42 – 13.52\n&lt;0.001\n\n\nRandom Effects\n\n\n\nσ2\n654.94\n\n\n\nτ00 Subject\n612.10\n\n\nτ11 Subject.Days\n35.07\n\n\nρ01 Subject\n0.07\n\n\nICC\n0.72\n\n\nN Subject\n18\n\nObservations\n180\n\n\nMarginal R2 / Conditional R2\n0.279 / 0.799\n\n\n\n\n\n\n\nlibrary(gtsummary)\n\ngtsummary::tbl_regression(fit_lme4)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\n\n\n\n\nDays\n10\n7.4, 13\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\nSee also http://cran.r-project.org/web/packages/jtools/vignettes/summ.html"
  },
  {
    "objectID": "scripts-lectures/2025-03-28.html",
    "href": "scripts-lectures/2025-03-28.html",
    "title": "2025-03-28",
    "section": "",
    "text": "@Shimizu2024-xl analyzed the impact of the type and intensity of the facial expression on the detection accuracy.\n\nThis study examined the relationship between the intensity of emotional expressions in facial stimuli and receivers’ decoding accuracy for six basic emotions: anger, disgust, fear, happiness, sadness, and surprise. A laboratory experiment was conducted using the forced‐choice method, in which the intensity of each stimulus was manipulated at every 10% interval using the morphing technique. To explore whether a linear relationship would be observed when the intensity was finely manipulated at 10% intervals, a hierarchical multiple regression analysis was performed. The mean percentage of correct responses for each stimulus was the dependent variable, and the linear, quadratic, and cubic terms of the stimulus intensity were the independent variables. The results showed that the linear model was not adopted as the final model for all facial expressions; that is, the effect of the squared term of intensity was significant for anger, disgust, fear, and sadness, while the effect of the cubic term of intensity was significant for happiness and surprise. Our findings indicate that a higher intensity of emotional expression does not yield higher decoding accuracy.\n\nData are available on OSF\nScript di pre-processing:\n\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(here)\n\n# https://osf.io/zhtbj/?view_only=\n# download.file(\"https://osf.io/download/tph5f/\", \"data-raw/emoint.csv\")\n\ndat &lt;- read.csv(here(\"data-raw/emoint.csv\"))\n\n# conversion for responses\n# 1 = neutral\n# 2 = anger\n# 3 = disgust\n# 4 = fear\n# 5 = happiness\n# 6 = sadness\n# 7 = surprise\n\nresp_code &lt;- c(\n  \"1\" = \"neutral\",\n  \"2\" = \"anger\",\n  \"3\" = \"disgust\",\n  \"4\" = \"fear\",\n  \"5\" = \"happiness\",\n  \"6\" = \"sadness\",\n  \"7\" = \"suprise\"\n)\n\nemotion_code &lt;- c(\n  \"fear\" = \"fear\",\n  \"disop\" = \"disgust\",\n  \"discl\" = \"disgust\",\n  \"hap\" = \"happiness\",\n  \"sad\" = \"sadness\",\n  \"sur\" = \"suprise\",\n  \"angcl\" = \"anger\",\n  \"neutral\" = \"neutral\"\n)\n\ndat_clean &lt;- dat |&gt; \n  pivot_longer(4:ncol(dat), values_to = \"response\") |&gt; \n  separate(name, into = c(\"face\", \"emotion\", \"intensity\"), sep = \"_\")  |&gt;\n  # intensity as number\n  mutate(intensity = as.numeric(intensity)) |&gt; \n  # neutral as maximal intensity, avoid NA\n  mutate(intensity = ifelse(emotion == \"neutral\", 100, intensity))\n\nnames(dat_clean)[1:3] &lt;- c(\"id\", \"gender\", \"age\")\n\n# recoding response with labels\n# see https://adv-r.hadley.nz/subsetting.html?q=look#lookup-tables\n\ndat_clean$response_lbl &lt;- resp_code[dat_clean$response]\n\n# recoding the displayed emotion as the response\n\ndat_clean$emotion_lbl &lt;- emotion_code[dat_clean$emotion]\n\n# binary accuracy if emotion_lbl == response_lbl\n\ndat_clean$acc &lt;- as.integer(dat_clean$response_lbl == dat_clean$emotion_lbl)\n\nhead(dat_clean)\n\n# A tibble: 6 × 10\n     id gender age   face  emotion intensity response response_lbl emotion_lbl\n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;      \n1     1 f      32    f1    fear           60        4 fear         fear       \n2     1 f      32    m3    disop          60        3 disgust      disgust    \n3     1 f      32    m3    hap            70        5 happiness    happiness  \n4     1 f      32    m1    hap           100        5 happiness    happiness  \n5     1 f      32    m4    disop          60        6 sadness      disgust    \n6     1 f      32    m1    fear           20        1 neutral      fear       \n# ℹ 1 more variable: acc &lt;int&gt;\n\nsaveRDS(dat_clean, here(\"data/emoint.rds\"))"
  },
  {
    "objectID": "scripts-lectures/2025-03-28.html#face-processing",
    "href": "scripts-lectures/2025-03-28.html#face-processing",
    "title": "2025-03-28",
    "section": "",
    "text": "@Shimizu2024-xl analyzed the impact of the type and intensity of the facial expression on the detection accuracy.\n\nThis study examined the relationship between the intensity of emotional expressions in facial stimuli and receivers’ decoding accuracy for six basic emotions: anger, disgust, fear, happiness, sadness, and surprise. A laboratory experiment was conducted using the forced‐choice method, in which the intensity of each stimulus was manipulated at every 10% interval using the morphing technique. To explore whether a linear relationship would be observed when the intensity was finely manipulated at 10% intervals, a hierarchical multiple regression analysis was performed. The mean percentage of correct responses for each stimulus was the dependent variable, and the linear, quadratic, and cubic terms of the stimulus intensity were the independent variables. The results showed that the linear model was not adopted as the final model for all facial expressions; that is, the effect of the squared term of intensity was significant for anger, disgust, fear, and sadness, while the effect of the cubic term of intensity was significant for happiness and surprise. Our findings indicate that a higher intensity of emotional expression does not yield higher decoding accuracy.\n\nData are available on OSF\nScript di pre-processing:\n\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(here)\n\n# https://osf.io/zhtbj/?view_only=\n# download.file(\"https://osf.io/download/tph5f/\", \"data-raw/emoint.csv\")\n\ndat &lt;- read.csv(here(\"data-raw/emoint.csv\"))\n\n# conversion for responses\n# 1 = neutral\n# 2 = anger\n# 3 = disgust\n# 4 = fear\n# 5 = happiness\n# 6 = sadness\n# 7 = surprise\n\nresp_code &lt;- c(\n  \"1\" = \"neutral\",\n  \"2\" = \"anger\",\n  \"3\" = \"disgust\",\n  \"4\" = \"fear\",\n  \"5\" = \"happiness\",\n  \"6\" = \"sadness\",\n  \"7\" = \"suprise\"\n)\n\nemotion_code &lt;- c(\n  \"fear\" = \"fear\",\n  \"disop\" = \"disgust\",\n  \"discl\" = \"disgust\",\n  \"hap\" = \"happiness\",\n  \"sad\" = \"sadness\",\n  \"sur\" = \"suprise\",\n  \"angcl\" = \"anger\",\n  \"neutral\" = \"neutral\"\n)\n\ndat_clean &lt;- dat |&gt; \n  pivot_longer(4:ncol(dat), values_to = \"response\") |&gt; \n  separate(name, into = c(\"face\", \"emotion\", \"intensity\"), sep = \"_\")  |&gt;\n  # intensity as number\n  mutate(intensity = as.numeric(intensity)) |&gt; \n  # neutral as maximal intensity, avoid NA\n  mutate(intensity = ifelse(emotion == \"neutral\", 100, intensity))\n\nnames(dat_clean)[1:3] &lt;- c(\"id\", \"gender\", \"age\")\n\n# recoding response with labels\n# see https://adv-r.hadley.nz/subsetting.html?q=look#lookup-tables\n\ndat_clean$response_lbl &lt;- resp_code[dat_clean$response]\n\n# recoding the displayed emotion as the response\n\ndat_clean$emotion_lbl &lt;- emotion_code[dat_clean$emotion]\n\n# binary accuracy if emotion_lbl == response_lbl\n\ndat_clean$acc &lt;- as.integer(dat_clean$response_lbl == dat_clean$emotion_lbl)\n\nhead(dat_clean)\n\n# A tibble: 6 × 10\n     id gender age   face  emotion intensity response response_lbl emotion_lbl\n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;      \n1     1 f      32    f1    fear           60        4 fear         fear       \n2     1 f      32    m3    disop          60        3 disgust      disgust    \n3     1 f      32    m3    hap            70        5 happiness    happiness  \n4     1 f      32    m1    hap           100        5 happiness    happiness  \n5     1 f      32    m4    disop          60        6 sadness      disgust    \n6     1 f      32    m1    fear           20        1 neutral      fear       \n# ℹ 1 more variable: acc &lt;int&gt;\n\nsaveRDS(dat_clean, here(\"data/emoint.rds\"))"
  },
  {
    "objectID": "scripts-lectures/2025-04-01.html",
    "href": "scripts-lectures/2025-04-01.html",
    "title": "2025-04-01",
    "section": "",
    "text": "library(here)\nlibrary(lme4)\nlibrary(tidyverse)\nlibrary(effects)\nlibrary(ggeffects)\nlibrary(sjPlot)\nlibrary(lattice)\n\n\n# loading data\ndat &lt;- readRDS(here(\"data/emoint.rds\"))\ndat &lt;- filter(dat, emotion_lbl != \"neutral\")\n\nSingle-subject model:\n\nfit &lt;- glm(acc ~ intensity * emotion_lbl, \n           data = dat, \n           subset = id == 1,\n           family = binomial(link = \"logit\"))\n\n# model without the interaction\nfit0 &lt;- glm(acc ~ intensity + emotion_lbl, \n           data = dat, \n           subset = id == 1,\n           family = binomial(link = \"logit\"))\n\nsummary(fit)\n\n\nCall:\nglm(formula = acc ~ intensity * emotion_lbl, family = binomial(link = \"logit\"), \n    data = dat, subset = id == 1)\n\nCoefficients:\n                                Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)                    -2.598651   1.347156  -1.929   0.0537 .\nintensity                       0.095568   0.038859   2.459   0.0139 *\nemotion_lbldisgust             -0.618369   1.514043  -0.408   0.6830  \nemotion_lblfear                 0.429429   1.603165   0.268   0.7888  \nemotion_lblhappiness           -0.275018   1.600348  -0.172   0.8636  \nemotion_lblsadness             -0.556507   1.737147  -0.320   0.7487  \nemotion_lblsuprise              2.267763   1.513293   1.499   0.1340  \nintensity:emotion_lbldisgust   -0.024760   0.041089  -0.603   0.5468  \nintensity:emotion_lblfear      -0.048318   0.041881  -1.154   0.2486  \nintensity:emotion_lblhappiness -0.007585   0.044519  -0.170   0.8647  \nintensity:emotion_lblsadness    0.018227   0.051148   0.356   0.7216  \nintensity:emotion_lblsuprise   -0.044934   0.042913  -1.047   0.2951  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 448.60  on 369  degrees of freedom\nResidual deviance: 265.38  on 358  degrees of freedom\nAIC: 289.38\n\nNumber of Fisher Scoring iterations: 7\n\nsummary(fit0)\n\n\nCall:\nglm(formula = acc ~ intensity + emotion_lbl, family = binomial(link = \"logit\"), \n    data = dat, subset = id == 1)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          -1.824e+00  6.024e-01  -3.028  0.00246 ** \nintensity             7.148e-02  7.860e-03   9.094  &lt; 2e-16 ***\nemotion_lbldisgust   -1.425e+00  6.182e-01  -2.304  0.02121 *  \nemotion_lblfear      -1.539e+00  7.060e-01  -2.180  0.02926 *  \nemotion_lblhappiness -4.451e-01  6.421e-01  -0.693  0.48818    \nemotion_lblsadness   -2.137e-15  6.637e-01   0.000  1.00000    \nemotion_lblsuprise    8.825e-01  6.746e-01   1.308  0.19082    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 448.60  on 369  degrees of freedom\nResidual deviance: 271.84  on 363  degrees of freedom\nAIC: 285.84\n\nNumber of Fisher Scoring iterations: 6\n\n# evaluating the single effects\ncar::Anova(fit)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: acc\n                      LR Chisq Df Pr(&gt;Chisq)    \nintensity              157.042  1  &lt; 2.2e-16 ***\nemotion_lbl             31.677  5  6.884e-06 ***\nintensity:emotion_lbl    6.462  5     0.2638    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(fit, fit0) # same as car::Anova()\n\nAnalysis of Deviance Table\n\nModel 1: acc ~ intensity * emotion_lbl\nModel 2: acc ~ intensity + emotion_lbl\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       358     265.38                     \n2       363     271.84 -5  -6.4619   0.2638\n\n# plotting the effects\nplot(allEffects(fit))\n\n\n\n\n\n\n\nplot(ggeffect(fit, terms = c(\"intensity\", \"emotion_lbl\")))\n\n\n\n\n\n\n\n# manually\neff &lt;- ggeffect(fit, terms = c(\"intensity\", \"emotion_lbl\"))\ndata.frame(eff)\n\n     x  predicted std.error   conf.low conf.high     group\n1   10 0.16206109 1.0134548 0.02584869 0.5850072     anger\n2   10 0.07523375 0.5710367 0.02587777 0.1994509   disgust\n3   10 0.15489361 0.7318202 0.04184388 0.4347781      fear\n4   10 0.11985130 0.6739778 0.03506656 0.3378552 happiness\n5   10 0.11740792 0.8052717 0.02671343 0.3920019   sadness\n6   10 0.54375108 0.5457759 0.29023397 0.7764599   suprise\n7   20 0.33463559 0.7357683 0.10627463 0.6802208     anger\n8   20 0.14174613 0.4586222 0.06298839 0.2886439   disgust\n9   20 0.22719363 0.6038331 0.08258613 0.4898177      fear\n10  20 0.24712418 0.5065491 0.10843502 0.4697392 happiness\n11  20 0.29333114 0.5615043 0.12134142 0.5550924   sadness\n12  20 0.66413889 0.4322265 0.45875524 0.8218514   suprise\n13  30 0.56669672 0.5980157 0.28829016 0.8085283     anger\n14  30 0.25109449 0.3609010 0.14183446 0.4048178   disgust\n15  30 0.32044495 0.4924107 0.15227929 0.5531434      fear\n16  30 0.44172120 0.3915644 0.26862075 0.6302460 happiness\n17  30 0.56431390 0.4509125 0.34862614 0.7581312   sadness\n18  30 0.76640719 0.3769221 0.61049188 0.8729046   suprise\n19  40 0.77277821 0.6898508 0.46803932 0.9293107     anger\n20  40 0.40499269 0.2929652 0.27709731 0.5472329   disgust\n21  40 0.43064266 0.4112451 0.25251283 0.6287355      fear\n22  40 0.65602957 0.3800502 0.47521173 0.8006776 happiness\n23  40 0.80164974 0.5590775 0.57465410 0.9236080   sadness\n24  40 0.84481172 0.4045034 0.71129104 0.9232458   suprise\n25  50 0.89841576 0.9466620 0.58037697 0.9826245     anger\n26  50 0.58014633 0.2776176 0.44503643 0.7042241   disgust\n27  50 0.54816730 0.3802329 0.36540650 0.7187988      fear\n28  50 0.82134401 0.4795189 0.64236416 0.9216746 happiness\n29  50 0.92653114 0.8018876 0.72370511 0.9837975   sadness\n30  50 0.90032269 0.5014756 0.77170101 0.9602158   suprise\n31  60 0.95833052 1.2721821 0.65520373 0.9964202     anger\n32  60 0.73719748 0.3224567 0.59855539 0.8407014   disgust\n33  60 0.66055460 0.4108916 0.46516502 0.8132244      fear\n34  60 0.91723130 0.6401745 0.75961878 0.9749137 happiness\n35  60 0.97521779 1.0930188 0.82204393 0.9970258   sadness\n36  60 0.93744757 0.6368946 0.81135906 0.9812097   suprise\n37  70 0.98355420 1.6256474 0.71195388 0.9993094     anger\n38  70 0.85062758 0.4081041 0.71903147 0.9268582   disgust\n39  70 0.75736091 0.4918202 0.54346873 0.8911182      fear\n40  70 0.96391547 0.8270993 0.84078153 0.9926540 happiness\n41  70 0.99192187 1.4027000 0.88707864 0.9994793   sadness\n42  70 0.96133902 0.7912609 0.84059387 0.9915436   suprise\n43  80 0.99361109 1.9922386 0.75805874 0.9998705     anger\n44  80 0.92038654 0.5145711 0.80831055 0.9694141   disgust\n45  80 0.83351729 0.6031108 0.60556023 0.9422876      fear\n46  80 0.98470730 1.0260350 0.89603987 0.9979255 happiness\n47  80 0.99739686 1.7209459 0.92926412 0.9999105   sadness\n48  80 0.97633565 0.9554345 0.86380034 0.9962880   suprise\n49  90 0.99753344 2.3658621 0.79664507 0.9999760     anger\n50  90 0.95913231 0.6314125 0.87193127 0.9877902   disgust\n51  90 0.88926557 0.7310256 0.65711799 0.9711409      fear\n52  90 0.99359849 1.2311731 0.93287683 0.9994234 happiness\n53  90 0.99916428 2.0437594 0.95608899 0.9999848   sadness\n54  90 0.98560220 1.1251304 0.88298049 0.9983924   suprise\n55 100 0.99905004 2.7436465 0.82930246 0.9999956     anger\n56 100 0.97944271 0.7538196 0.91577731 0.9952328   disgust\n57 100 0.92795947 0.8682480 0.70141067 0.9860399      fear\n58 100 0.99733432 1.4398651 0.95699760 0.9998410 happiness\n59 100 0.99973202 2.3692744 0.97289708 0.9999974   sadness\n60 100 0.99127256 1.2981848 0.89917783 0.9993092   suprise\n\ndd &lt;- expand.grid(\n    emotion_lbl = unique(dat$emotion_lbl),\n    intensity = unique(dat$intensity)\n)\n\n#predict(fit, newdata = dd, type = \"response\", se.fit = TRUE)\n\n# creating table\ntab_model(fit)\n\n\n\n\n\n\n\n\n\n\n \nacc\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n0.07\n0.00 – 0.72\n0.054\n\n\nintensity\n1.10\n1.04 – 1.22\n0.014\n\n\nemotion lbl [disgust]\n0.54\n0.04 – 17.70\n0.683\n\n\nemotion lbl [fear]\n1.54\n0.08 – 56.59\n0.789\n\n\nemotion lbl [happiness]\n0.76\n0.04 – 27.73\n0.864\n\n\nemotion lbl [sadness]\n0.57\n0.02 – 24.64\n0.749\n\n\nemotion lbl [suprise]\n9.66\n0.66 – 320.51\n0.134\n\n\nintensity × emotion lbl\n[disgust]\n0.98\n0.88 – 1.04\n0.547\n\n\nintensity × emotion lbl\n[fear]\n0.95\n0.86 – 1.02\n0.249\n\n\nintensity × emotion lbl\n[happiness]\n0.99\n0.89 – 1.07\n0.865\n\n\nintensity × emotion lbl\n[sadness]\n1.02\n0.91 – 1.13\n0.722\n\n\nintensity × emotion lbl\n[suprise]\n0.96\n0.86 – 1.03\n0.295\n\n\nObservations\n370\n\n\nR2 Tjur\n0.465\n\n\n\n\n\n\n\nFit a model for each subject and plot the coefficients.\n\nfit_res &lt;- function(fit){\n    cc &lt;- summary(fit)$coefficients\n    cc &lt;- data.frame(cc)\n    ci &lt;- data.frame(confint(fit))\n    names(ci) &lt;- c(\"lower\", \"upper\")\n    names(cc) &lt;- c(\"b\", \"se\", \"z\", \"p\")\n    out &lt;- cbind(cc, ci)\n    out$param &lt;- rownames(out)\n    rownames(out) &lt;- NULL\n    return(out)\n}\n\nfit_fun &lt;- function(data){\n    glm(acc ~ intensity, family = binomial(link = \"logit\"), data = data)\n}\n\nfit_glm_res &lt;- function(data){\n    fit &lt;- fit_fun(data)\n    fit_res(fit)\n}\n\ndat |&gt; \n    group_by(id) |&gt; \n    nest() |&gt; \n    mutate(res = lapply(data, fit_glm_res)) |&gt; \n    unnest(res) |&gt; \n    ggplot(aes(x = id, y = b, ymin = lower, ymax = upper)) +\n    geom_pointrange() +\n    facet_wrap(~param, scales = \"free\")\n\n\n\n\n\n\n\n\n\n# centering on the minimum and rescaling to 0-10\ndat$intensity0 &lt;- (dat$intensity/10) - 1\n\nfit0 &lt;- glmer(acc ~ intensity0 + (1|id), data = dat, family = binomial(link = \"logit\"))\nfit &lt;- glmer(acc ~ intensity0 + (intensity0|id), data = dat, family = binomial(link = \"logit\"))\n\ncar::compareCoefs(fit0, fit, zvals = TRUE)\n\nCalls:\n1: glmer(formula = acc ~ intensity0 + (1 | id), data = dat, family = \n  binomial(link = \"logit\"))\n2: glmer(formula = acc ~ intensity0 + (intensity0 | id), data = dat, family \n  = binomial(link = \"logit\"))\n\n            Model 1 Model 2\n(Intercept) -1.0760 -1.0935\nSE           0.0457  0.0406\nz             -23.6   -26.9\n                           \nintensity0  0.32508 0.33490\nSE          0.00524 0.01148\nz              62.0    29.2\n                           \n\ndotplot(ranef(fit))\n\n$id\n\n\n\n\n\n\n\n\n# histograms of acc when intensity is 0\nhist(plogis(fixef(fit)[1] + ranef(fit)$id[[1]]))\n\n\n\n\n\n\n\nsummary(fit)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: acc ~ intensity0 + (intensity0 | id)\n   Data: dat\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  30742.3   30783.2  -15366.2   30732.3     26265 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.2930 -0.7394  0.3993  0.7623  2.1703 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n id     (Intercept) 0.069921 0.26443       \n        intensity0  0.007283 0.08534  -0.43\nNumber of obs: 26270, groups:  id, 71\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.09350    0.04058  -26.95   &lt;2e-16 ***\nintensity0   0.33490    0.01148   29.17   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr)\nintensity0 -0.545\n\n# independent slopes and intercepts\nfit2 &lt;- glmer(acc ~ intensity0 + (intensity0|id), data = dat, family = binomial(link = \"logit\"))\n\nsummary(fit2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: acc ~ intensity0 + (intensity0 | id)\n   Data: dat\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  30742.3   30783.2  -15366.2   30732.3     26265 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.2930 -0.7394  0.3993  0.7623  2.1703 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n id     (Intercept) 0.069921 0.26443       \n        intensity0  0.007283 0.08534  -0.43\nNumber of obs: 26270, groups:  id, 71\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.09350    0.04058  -26.95   &lt;2e-16 ***\nintensity0   0.33490    0.01148   29.17   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr)\nintensity0 -0.545"
  },
  {
    "objectID": "scripts-lectures/2025-04-04_extra/2025-04-04_esempio-simpson-paradox.html",
    "href": "scripts-lectures/2025-04-04_extra/2025-04-04_esempio-simpson-paradox.html",
    "title": "2025-04-04",
    "section": "",
    "text": "In psicologia e neuroscienze alcuni esperimenti includono delle variabili che possono variare tra soggetti, nonostante siano manipolate sperimentalmente.\nAd esempio, in psicofisica gli stimoli vengono spesso adattati ai soggetti e quindi non tutti i soggetti sono sottoposti allo stesso tipo di stimolazione.\nIpotizziamo che siamo interessati a capire la sensibilità al contrasto (visibilità rispetto allo sfondo) di un gruppo di soggetti. A livello individuale possiamo ipotizzare che la relazione vera di due soggetti sia ad esempio:\n\n\n\n\n\n\n\n\n\nSolitamente siamo interessati a stimare la soglia percettiva ed eventualmente la slope. La soglia percettiva è il livello di \\(x\\) (contrasto) necessario a ad avere una certa percentuale di visibilità (e.g., 50%).\nGli esperimenti possono essere tarati per adattare lo stimolo (contrasto) alle risposte permettendo di focalizzare i trial sulla parte della curva di interesse. Se proviamo a simulare due ipotetici esperimenti:\n\n\n\n\n\n\n\n\n\nOra carichiamo un dataset con un esperimento di questo tipo.\n\n\n  id trial       x01 visibility\n1  1     1 0.2069943          0\n2  2     1 0.6339033          1\n3  3     1 0.7137630          0\n4  4     1 0.6853990          0\n5  5     1 0.2117152          0\n6  6     1 0.2450111          0\n\n\nPossiamo anche vedere i pattern individuali:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFittiamo i nostri modelli per soggetto e vediamo il pattern di parametri:\n\n\n\n\n\n\n\n\n\nPerfetto, ora fittiamo il nostro modello:\n\nlibrary(lme4)\nlibrary(lmerTest)\n\nfit &lt;- glmer(visibility ~ x01 + (x01||id), data = dat, family = binomial(link = \"logit\"))\nsummary(fit)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: visibility ~ x01 + (x01 || id)\n   Data: dat\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   7387.3    7416.2   -3689.7    7379.3      9996 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.2114 -0.4091 -0.3261 -0.2499  8.6903 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 2.217    1.489   \n id.1   x01         1.896    1.377   \nNumber of obs: 10000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -6.342      1.013  -6.258 3.91e-10 ***\nx01            8.738      2.017   4.333 1.47e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n    (Intr)\nx01 -0.984\n\n\n\nlibrary(ggeffects)\nplot(ggeffect(fit))\n\n\n\n\n\n\n\n\nL’effetto fisso stimato dal modello è 8.74. Al netto dello shrinkage, questo è decisamente inferiore rispetto alla media delle slope stimate sui singoli soggetti. Quale potrebbe essere il motivo?\nIl problema principale è che abbiamo un effetto del cluster (soggetti) sulla nostra variabile \\(x\\) (vi dice qualcosa il Simpson’s paradox?). Ogni soggetto ha il suo esperimento con un incremento chiaro (e consistente) della visibilità in funzione del contrasto MA i livelli di contrasto di ogni soggetto sono diversi uno dall’altro.\n\n\n\n\n\n\n\n\n\nQuindi in realtà non stiamo stimando esattamente quello che vorremmo, ovvero l’effetto medio (e la sua variabilità) del contrasto in ogni soggetto. Idealmente dovremmo calcolarlo su ogni soggetto e poi fare la media.\nPer fare questo è necessario trasformare la \\(x\\), centrando i valori di contrasto sulla media di ogni soggetto.\ncmc &lt;- function(x, cluster){\n  x - cm(x, cluster)\n}\ncm &lt;- function(x, cluster){\n    cmm &lt;- tapply(x, cluster, mean)\n    cmn &lt;- tapply(x, cluster, length) \n    cmm[as.character(cluster)]\n}\n\n\n\n\n\n\n\n\n\n\ndat_ex$x01_cmc &lt;- cmc(dat_ex$x01, dat_ex$id)\nfit_cmc &lt;- glmer(visibility ~ x01_cmc + (x01_cmc||id), data = dat_ex, family = binomial(link = \"logit\"))\nsummary(fit_cmc)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: visibility ~ x01_cmc + (x01_cmc || id)\n   Data: dat_ex\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   7081.7    7110.5   -3536.8    7073.7      9996 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5490 -0.4042 -0.3101 -0.2293  6.2565 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.2294   0.4789  \n id.1   x01_cmc     7.6120   2.7590  \nNumber of obs: 10000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.15515    0.05998  -35.93   &lt;2e-16 ***\nx01_cmc     18.17924    1.03817   17.51   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\nx01_cmc -0.224\n\n\nSe erroneamente (qualche volta viene fatto), decidiamo di aggregare i dati a livello del soggetto. Possiamo nel migliore dei casi attenuare o distorcere la stima oppure stimare un pattern anche opposto.\n\ndat_agg &lt;- dat_ex |&gt; \n    group_by(id) |&gt; \n    summarise(p = mean(visibility),\n              n = n(),\n              x01 = mean(x01))\nhead(dat_agg)\n\n# A tibble: 6 × 4\n     id     p     n   x01\n  &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1     1  0.11   100 0.171\n2     2  0.08   100 0.623\n3     3  0.12   100 0.680\n4     4  0.21   100 0.679\n5     5  0.02   100 0.180\n6     6  0.17   100 0.264\n\nfit_agg &lt;- glmer(p ~ x01 + (1|id), data = dat_agg, weights = n, family = binomial(link = \"logit\"))\nsummary(fit_agg)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: p ~ x01 + (1 | id)\n   Data: dat_agg\nWeights: n\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    633.0     640.8    -313.5     627.0        97 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.62242 -0.44308  0.02905  0.35862  1.33912 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.2064   0.4543  \nNumber of obs: 100, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.9989     0.1605 -12.455   &lt;2e-16 ***\nx01          -0.0477     0.3052  -0.156    0.876    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n    (Intr)\nx01 -0.938"
  },
  {
    "objectID": "scripts-lectures/2025-04-07_extra/2025-04-07_simulazione.html",
    "href": "scripts-lectures/2025-04-07_extra/2025-04-07_simulazione.html",
    "title": "2025-04-04",
    "section": "",
    "text": "Simulazione\nProviamo a simulare un mixed-model per un esperimento. L’obiettivo è simulare un dataset realistico dove \\(k\\) soggetti fanno massimo \\(n = 240\\) trials. Il numero di trials non è lo stesso per soggetto. Il modo di campionare i trial potete deciderlo.\nL’esperimento si basa sulla seguente teoria:\n\nStimoli rilevanti evoluzionisticamente sono elaborati in modo più efficiente rispetto a stimoli meno rilevanti.\n\nUn’ipotesi legata a questo è che ci siano delle categorie (ad esempio i volti) che rispetto ad altre hanno una maggiore rilevanza evoluzionistica. A sua volta, dentro questa categoria, ci sono stimoli con più o meno rilevanza.\nIn questo caso si stanno testando i tempi di reazione in laboratorio in risposta a 3 categorie di stimoli:\n\nvolti di persone adulte\nvolti di bambini\nforme geometriche\n\nL’ipotesi è che i tempi di reazione siano sistematicamente inferiori per i volti rispetto alle forme geometriche e per i volti di bambini rispetto a quelli adulti.\n\n\n\n\n\n\n\n\n\nPer la simulazione è necessario impostare tutti i parametri del modello. Il numero di trials totale è 80 per condizione ma in modo casuale alcuni trial vengono eliminati perchè considerati non validi. La percentuale di dati rimossi da ogni soggetto è sempre inferiore al 30% ma varia da soggetto a soggetto.\nLe medie per ogni condizione sono indicate nel grafico. Il grado di skewness nei dati è di 0.5. Per quanto riguarda gli effetti random, scegliete la struttura random che preferite. Al minimo, mettete le intercette random con un valore che vi sembra plausibile.\nAi ricercatori però interessano due contrasti in particolare:\n\nforme geometriche vs media di volti adulti e bambini\nadulti vs bambini\n\nImpostate una simulazione per generare un dataset realistico che rispetta le regole generali introdotte prima e anche il tipo di variabile. I tempi sono positivi e generalmente asimmetrici.\n\n\n\n\n\n\n\n\n\nFate un piccolo report in Quarto o R Markdown dove definite i parametri, codice e qualche grafico di come vengono i dati.\nQualche consiglio:\n\npartite dal modello che fareste in questo caso\nbisogna trasformare i parametri della distribuzione in qualche modo per fissare queste medie di tempi\nla deviazione standard non è un parametro fisso, partite dalla skewness\nattenzione a lme4, non sempre funziona benissimo :)"
  },
  {
    "objectID": "scripts-lectures/2025-04-15.html",
    "href": "scripts-lectures/2025-04-15.html",
    "title": "2025-04-15",
    "section": "",
    "text": "Vediamo qualche dataset per applicare i modelli metanalitici.\n\nil pacchetto metadat contiene diversi dataset già predisposti per poter fare una metanalisi.\nil progetto metapsy raccoglie tutti i randomized-controlled trials riguardo l’efficacia di psicoterapie per diversi tipo di condizioni. contiene molte variabili oltre agli effect sizes quindi si presta bene per le meta-regressions."
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#about-me",
    "href": "slides/00-course-intro/00-course-intro.html#about-me",
    "title": "Introduzione al corso",
    "section": "About me",
    "text": "About me\n\nSono uno Psicologo Clinico e assegnista di ricerca in Psicometria al Dipartimento di Psicologia dello Sviluppo e della Socializzazione\nMi occupo di analisi dei dati in Psicologia, in particolare: meta-analysis, simulazioni monte carlo per la power analysis, replicabilità e multiverse analysis"
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#ricevimento",
    "href": "slides/00-course-intro/00-course-intro.html#ricevimento",
    "title": "Introduzione al corso",
    "section": "Ricevimento",
    "text": "Ricevimento\n\nLavoro al Dipartimento di Psicologia dello Sviluppo e della Socializzazione, Via Venezia 16, 35131 (edificio CLA). Il mio ufficio è 05-025 (5° piano).\nIl mio orario di ricevimento è Venerdì dalle 10:00 alle 12:00. Possiamo vederci sia in presenza che su Zoom. Potete prenotarvi qui https://calendar.app.google/Go7B6GBKBeRPCpU27.\nPer ogni cosa potete scrivermi a filippo.gambarota@unipd.it"
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#argomenti",
    "href": "slides/00-course-intro/00-course-intro.html#argomenti",
    "title": "Introduzione al corso",
    "section": "Argomenti",
    "text": "Argomenti\n\nOpen science tools: R, Quarto, Git e Github\nReplicabilità e riproducibilità nelle neuroscienze cognitive\nMeta-analysis\nGeneralized Linear Mixed-Effects models\nSimulazioni Monte Carlo"
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#organizzazione-delle-lezioni",
    "href": "slides/00-course-intro/00-course-intro.html#organizzazione-delle-lezioni",
    "title": "Introduzione al corso",
    "section": "Organizzazione delle lezioni",
    "text": "Organizzazione delle lezioni\nCosa faremo?\n\nPresentazione dei concetti teorici principali\nEsempi con dati reali e simulati\nIntepretazione dei risultati in ottica applicativa\nTanto codice\n\nCosa non faremo?\n\ndimostrazioni\nmolto focus sulle formule"
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#materiale",
    "href": "slides/00-course-intro/00-course-intro.html#materiale",
    "title": "Introduzione al corso",
    "section": "Materiale",
    "text": "Materiale\nPer il materiale, trovate tutto su Github https://github.com/stat-teaching/psychometrics4neuroscience. Trovate i vari link anche su Moodle ma Github è molto più comodo per tenere e organizzare tutto (lo vedremo nel dettaglio).\nLa repository contiene il codice, le slide (sia in formato .qmd che compilate), i dataset e tutto il resto del materiale."
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#esami",
    "href": "slides/00-course-intro/00-course-intro.html#esami",
    "title": "Introduzione al corso",
    "section": "Esami",
    "text": "Esami\nFate sempre riferimento alla pagina ufficiale https://www.stat.unipd.it/studenti-iscritti/calendario-appelli-desame.\n\n16/06/2025 aula SC60 10:30-12:30\n07/07/2025 aula SC60 10:30-12:30\n01/09/2025 aula SC60 14:30-16:30"
  },
  {
    "objectID": "slides/00-course-intro/00-course-intro.html#lavori-di-gruppo",
    "href": "slides/00-course-intro/00-course-intro.html#lavori-di-gruppo",
    "title": "Introduzione al corso",
    "section": "Lavori di gruppo",
    "text": "Lavori di gruppo\nParleremo dei lavori di gruppo assieme al Prof. Maffei il 28/04/2025 (salvo modifiche) dove vi presenteremo i lavori nel dettaglio.\nIn breve, vi sarà richiesto partendo da un dataset e/o un problema di ricerca, analizzare e/o simulare dei dati, produrre un report in Quarto e fare una presentazione del lavoro fatto."
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#reproducibility-starter-pack-1",
    "href": "slides/03-modern-r/03-modern-r.html#reproducibility-starter-pack-1",
    "title": "Modern R",
    "section": "Reproducibility starter pack 👷",
    "text": "Reproducibility starter pack 👷\n\nA general purpose (or flexible enough) programming language such as   or  \nA literate programming framework to integrate code and text\nA version control system to track projects\nAn online repository for future-proof sharing"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#disclaimers",
    "href": "slides/03-modern-r/03-modern-r.html#disclaimers",
    "title": "Modern R",
    "section": "Disclaimers",
    "text": "Disclaimers\n\nThe best tool is the tool that does the job.\n\n\nBut there are some features that makes a tool better in terms of reproducibility, reducing the probability of errors and improve your coding skills.\nThere is nothing bad about using SPSS, Jasp or Jamovi. The real problem is that using a point-and-click software reduce the reproducibility. If you can use the scripting part, whatever the tool.\nA general suggestion is to invest some of your time learning/improving a programming language for data pre-processing, analysis and reporting (tables, figures, etc.)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#r",
    "href": "slides/03-modern-r/03-modern-r.html#r",
    "title": "Modern R",
    "section": "R",
    "text": "R\n\nR is a free software environment for statistical computing and graphics.\n\n\n(TBH) It is not a proper general purpose programming language (such as C++ or Python).\nR packages allow to do almost everything (file manager, image processing, webscraping, sending emails, coffee 😄, etc.)\nIt is free and open-source\nThe community is wide, active thus solving problems is very easy\nForce you to learn scripting but the are R-based GUI software (e.g., JAMOVI)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#r---cran",
    "href": "slides/03-modern-r/03-modern-r.html#r---cran",
    "title": "Modern R",
    "section": "R - CRAN",
    "text": "R - CRAN\nThe CRAN is the repository where package developers upload their packages and other users can install them.\n\n\n\n\n\n\n\n\nAs the saying goes: if something exist, there is an R package for doing it! 😄"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#r---pypl-index",
    "href": "slides/03-modern-r/03-modern-r.html#r---pypl-index",
    "title": "Modern R",
    "section": "R - PYPL Index",
    "text": "R - PYPL Index\n\nSource: https://pypl.github.io/PYPL.html"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#r---pypl-index-1",
    "href": "slides/03-modern-r/03-modern-r.html#r---pypl-index-1",
    "title": "Modern R",
    "section": "R - PYPL Index",
    "text": "R - PYPL Index\nThe popularity is on a different scale compared to Python but still increasing:\n\n\n\nSource: https://pypl.github.io/PYPL.html"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#r-or-python",
    "href": "slides/03-modern-r/03-modern-r.html#r-or-python",
    "title": "Modern R",
    "section": "R or Python?",
    "text": "R or Python?\n\nPython is a very general-purpose language more powerful for general tasks.\nI find python very useful for programming experiments, image processing, automatizing tasks and interacting with the operating system\nR is still a little bit superior in terms of data manipulation and visualization. Python is faster and more powerful for complex models (e.g., machine learning, etc.)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#positron",
    "href": "slides/03-modern-r/03-modern-r.html#positron",
    "title": "Modern R",
    "section": "Positron",
    "text": "Positron\nSometimes Python is not so easy to setup. In addition is not as interactive as R (i.e., line by line evaluation). Posit (ex. R Studio) recently created Positron that is a new IDE working with R and Python at the same way."
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#modern-r",
    "href": "slides/03-modern-r/03-modern-r.html#modern-r",
    "title": "Modern R",
    "section": "Modern R",
    "text": "Modern R\n\nFor purist programmers, R is weird: arrays starts with 1, object-oriented programming is hidden, a lot of built-in vectorized functions, etc. The The R Inferno book is really funny showing the strange R-stuff.\nDespite the weirdness, R is widely used because it is intuitive (for non-programmers) and made for statistics and data manipulation\nR is a language and as in spoken languages you can elegant, rude, ambiguous, funny, etc.\nThere are some tips to improve the readability and reproducibility of your code"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming",
    "title": "Modern R",
    "section": "Functional Programming",
    "text": "Functional Programming\n\nIn computer science, functional programming is a programming paradigm where programs are constructed by applying and composing functions.\n\n\nDespite R can be used both with an imperative and object-oriented approach, the functional side is quite powerful.\nThe basic idea is to decompose your code into small, testable and re-usable functions"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming-example",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming-example",
    "title": "Modern R",
    "section": "Functional Programming, example…",
    "text": "Functional Programming, example…\nWe have a dataset (mtcars) and we want to calculate the mean, median, standard deviation, minimum and maximum of each column and store the result in a table.\n\nhead(mtcars)\n\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nstr(mtcars)\n\n#&gt; 'data.frame':    32 obs. of  11 variables:\n#&gt;  $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n#&gt;  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n#&gt;  $ disp: num  160 160 108 258 360 ...\n#&gt;  $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n#&gt;  $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n#&gt;  $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n#&gt;  $ qsec: num  16.5 17 18.6 19.4 17 ...\n#&gt;  $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n#&gt;  $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n#&gt;  $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n#&gt;  $ carb: num  4 4 1 1 2 1 4 2 2 4 ..."
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming-1",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming-1",
    "title": "Modern R",
    "section": "Functional Programming",
    "text": "Functional Programming\nThe standard (~imperative) option is using a for loop, iterating through columns, calculate the values and store into another data structure.\n\nncols &lt;- ncol(mtcars)\nmeans &lt;- medians &lt;- mins &lt;- maxs &lt;- rep(0, ncols)\n\nfor(i in 1:ncols){\n  means[i] &lt;- mean(mtcars[[i]])\n  medians[i] &lt;- median(mtcars[[i]])\n  mins[i] &lt;- min(mtcars[[i]])\n  maxs[i] &lt;- max(mtcars[[i]])\n}\n\nresults &lt;- data.frame(means, medians, mins, maxs)\nresults$col &lt;- names(mtcars)\n\nresults\n\n#&gt;         means medians   mins    maxs  col\n#&gt; 1   20.090625  19.200 10.400  33.900  mpg\n#&gt; 2    6.187500   6.000  4.000   8.000  cyl\n#&gt; 3  230.721875 196.300 71.100 472.000 disp\n#&gt; 4  146.687500 123.000 52.000 335.000   hp\n#&gt; 5    3.596563   3.695  2.760   4.930 drat\n#&gt; 6    3.217250   3.325  1.513   5.424   wt\n#&gt; 7   17.848750  17.710 14.500  22.900 qsec\n#&gt; 8    0.437500   0.000  0.000   1.000   vs\n#&gt; 9    0.406250   0.000  0.000   1.000   am\n#&gt; 10   3.687500   4.000  3.000   5.000 gear\n#&gt; 11   2.812500   2.000  1.000   8.000 carb"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming-2",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming-2",
    "title": "Modern R",
    "section": "Functional Programming",
    "text": "Functional Programming\nThe main idea is to decompose the problem writing a function and loop over the columns of the dataframe:\n\nsumm &lt;- function(x){\n  data.frame(means = mean(x), \n             medians = median(x), \n             mins = min(x), \n             maxs = max(x))\n}\nncols &lt;- ncol(mtcars)\ndfs &lt;- vector(mode = \"list\", length = ncols)\n\nfor(i in 1:ncols){\n  dfs[[i]] &lt;- summ(mtcars[[i]])\n}"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming-3",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming-3",
    "title": "Modern R",
    "section": "Functional Programming",
    "text": "Functional Programming\n\nresults &lt;- do.call(rbind, dfs)\nresults\n\n#&gt;         means medians   mins    maxs\n#&gt; 1   20.090625  19.200 10.400  33.900\n#&gt; 2    6.187500   6.000  4.000   8.000\n#&gt; 3  230.721875 196.300 71.100 472.000\n#&gt; 4  146.687500 123.000 52.000 335.000\n#&gt; 5    3.596563   3.695  2.760   4.930\n#&gt; 6    3.217250   3.325  1.513   5.424\n#&gt; 7   17.848750  17.710 14.500  22.900\n#&gt; 8    0.437500   0.000  0.000   1.000\n#&gt; 9    0.406250   0.000  0.000   1.000\n#&gt; 10   3.687500   4.000  3.000   5.000\n#&gt; 11   2.812500   2.000  1.000   8.000"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming-4",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming-4",
    "title": "Modern R",
    "section": "Functional Programming",
    "text": "Functional Programming\nThe actual real functional way require using the built-in iteration tools *apply. In this way you avoid writing the verbose for loop.\n\nresults &lt;- lapply(mtcars, summ)\nresults &lt;- do.call(rbind, results)\nresults\n\n#&gt;           means medians   mins    maxs\n#&gt; mpg   20.090625  19.200 10.400  33.900\n#&gt; cyl    6.187500   6.000  4.000   8.000\n#&gt; disp 230.721875 196.300 71.100 472.000\n#&gt; hp   146.687500 123.000 52.000 335.000\n#&gt; drat   3.596563   3.695  2.760   4.930\n#&gt; wt     3.217250   3.325  1.513   5.424\n#&gt; qsec  17.848750  17.710 14.500  22.900\n#&gt; vs     0.437500   0.000  0.000   1.000\n#&gt; am     0.406250   0.000  0.000   1.000\n#&gt; gear   3.687500   4.000  3.000   5.000\n#&gt; carb   2.812500   2.000  1.000   8.000"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#functional-programming-apply",
    "href": "slides/03-modern-r/03-modern-r.html#functional-programming-apply",
    "title": "Modern R",
    "section": "Functional Programming, *apply",
    "text": "Functional Programming, *apply\n\nThe *apply family is one of the best tool in R. The idea is pretty simple: apply a function to each element of a list.\nThe powerful side is that in R everything can be considered as a list. A vector is a list of single elements, a dataframe is a list of columns etc.\nInternally, R is still using a for loop but the verbose part (preallocation, choosing the iterator, indexing) is encapsulated into the *apply function.\n\n\n\nmeans &lt;- rep(0, ncol(mtcars))\nfor(i in 1:length(means)){\n  means[i] &lt;- mean(mtcars[[i]])\n}\n\n# the same with sapply\nmeans &lt;- sapply(mtcars, mean)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#for-loops-are-bad",
    "href": "slides/03-modern-r/03-modern-r.html#for-loops-are-bad",
    "title": "Modern R",
    "section": "for loops are bad?",
    "text": "for loops are bad?\nfor loops are the core of each operation in R (and in every programming language). For complex operation thery are more readable and effective compared to *apply. In R we need extra care for writing efficent for loops.\nExtremely slow, no preallocation:\n\nres &lt;- c()\nfor(i in 1:1000){\n  # do something\n  res[i] &lt;- x\n}\n\nVery fast, no difference compared to *apply\n\nres &lt;- rep(0, 1000)\nfor(i in 1:length(res)){\n  # do something\n  res[i] &lt;- x\n}"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#for-loops-are-bad-1",
    "href": "slides/03-modern-r/03-modern-r.html#for-loops-are-bad-1",
    "title": "Modern R",
    "section": "for loops are bad?",
    "text": "for loops are bad?\nWe can formally compare the for loop approaches using the microbenchmark package:\n\nno_prealloc &lt;- function(n = 100){\n    res &lt;- c()\n    for(i in 1:n) res[i] &lt;- rnorm(1)\n}\n\nprealloc &lt;- function(n = 100){\n    res &lt;- vector(mode = \"numeric\", length = n)\n    for(i in 1:n) res[i] &lt;- rnorm(1)\n}\n\nmicrobenchmark::microbenchmark(\n    no_prealloc = no_prealloc(1000),\n    prealloc = prealloc(1000)\n)\n\n#&gt; Unit: microseconds\n#&gt;         expr     min       lq      mean   median       uq      max neval cld\n#&gt;  no_prealloc 848.225 872.0795 1010.1748 884.2175 918.5970 4462.520   100  a \n#&gt;     prealloc 648.589 663.1315  711.0051 668.4970 681.6215 2821.114   100   b"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#for-loops-are-bad-2",
    "href": "slides/03-modern-r/03-modern-r.html#for-loops-are-bad-2",
    "title": "Modern R",
    "section": "for loops are bad?",
    "text": "for loops are bad?\nIn fact, when the for loop is written appropriately, the performance are the same (or even better) compared to *apply:\n\nlibrary(purrr) # for map\niter &lt;- 500\n\nmicrobenchmark::microbenchmark(\n    for_no_prealloc = no_prealloc(iter),\n    for_prealloc = prealloc(iter),\n    sapply = sapply(1:iter, function(x) rnorm(1)),\n    map_dbl = map_dbl(1:iter, function(x) rnorm(1)),\n    vapply = vapply(1:iter, function(x) rnorm(1), FUN.VALUE = double(1)),\n    times = 500\n) |&gt; summary()\n\n#&gt;              expr     min       lq     mean   median       uq      max neval\n#&gt; 1 for_no_prealloc 427.404 444.7960 479.5039 452.2905 463.0960 4068.079   500\n#&gt; 2    for_prealloc 321.355 330.5470 347.4882 334.3735 339.7890 4380.626   500\n#&gt; 3          sapply 588.496 607.2065 652.3096 618.3775 633.7065 5153.349   500\n#&gt; 4         map_dbl 610.588 630.8610 697.8509 645.0725 679.1320 4740.082   500\n#&gt; 5          vapply 579.730 591.2970 635.9248 598.4200 607.1715 4754.439   500\n#&gt;    cld\n#&gt; 1 a   \n#&gt; 2  b  \n#&gt; 3   cd\n#&gt; 4   c \n#&gt; 5    d"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#with-apply-you-can-do-crazy-stuff",
    "href": "slides/03-modern-r/03-modern-r.html#with-apply-you-can-do-crazy-stuff",
    "title": "Modern R",
    "section": "With *apply you can do crazy stuff!",
    "text": "With *apply you can do crazy stuff!\n\nfuns &lt;- list(mean = mean, sd = sd, min = min, max = max, median = median)\nsapply(funs, function(f) lapply(mtcars, function(x) f(x)))\n\n#&gt;      mean     sd        min   max   median\n#&gt; mpg  20.09062 6.026948  10.4  33.9  19.2  \n#&gt; cyl  6.1875   1.785922  4     8     6     \n#&gt; disp 230.7219 123.9387  71.1  472   196.3 \n#&gt; hp   146.6875 68.56287  52    335   123   \n#&gt; drat 3.596563 0.5346787 2.76  4.93  3.695 \n#&gt; wt   3.21725  0.9784574 1.513 5.424 3.325 \n#&gt; qsec 17.84875 1.786943  14.5  22.9  17.71 \n#&gt; vs   0.4375   0.5040161 0     1     0     \n#&gt; am   0.40625  0.4989909 0     1     0     \n#&gt; gear 3.6875   0.7378041 3     5     4     \n#&gt; carb 2.8125   1.6152    1     8     2"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#why-functional-programming",
    "href": "slides/03-modern-r/03-modern-r.html#why-functional-programming",
    "title": "Modern R",
    "section": "Why functional programming?",
    "text": "Why functional programming?\n\nWe can write less and reusable code that can be shared and used in multiple projects\nThe scripts are more compact, easy to modify and less error prone (imagine that you want to improve the summ function, you only need to change it once instead of touching the for loop)\nFunctions can be easily and consistently documented (see roxygen documentation) improving the reproducibility and readability of your code"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#more-about-functional-programming-in-r",
    "href": "slides/03-modern-r/03-modern-r.html#more-about-functional-programming-in-r",
    "title": "Modern R",
    "section": "More about functional programming in R",
    "text": "More about functional programming in R\n\nAdvanced R by Hadley Wickham, section on Functional Programming (https://adv-r.hadley.nz/fp.html)\nHands-On Programming with R by Garrett Grolemund https://rstudio-education.github.io/hopr/\nHadley Wickham: The Joy of Functional Programming (for Data Science)\nBruno Rodrigues Youtube Channel"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#a-small-example-1",
    "href": "slides/03-modern-r/03-modern-r.html#a-small-example-1",
    "title": "Modern R",
    "section": "A small example",
    "text": "A small example\nTake the dataset iris and do the following operations in the most readable and efficient way that you can.\n\nfit a linear model (choose the y and x that you want) for each Species on the full dataset\nfit a linear model (choose the y and x that you want) for each Species but resampling with replacement (bootstrapping, choose the number of iterations that you want) the rows within each group\n(choose the y and x that you want) for each Species doing a leave-one-out analysis within each group\norganize the three steps into separated datasets in a nice and readable format (nice column names, not strange characters, spaces, etc.)\nshow the results with a plot of your choice"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#a-more-advanced-approach-r-packages",
    "href": "slides/03-modern-r/03-modern-r.html#a-more-advanced-approach-r-packages",
    "title": "Modern R",
    "section": "A more advanced approach, R packages",
    "text": "A more advanced approach, R packages\nR packages are not only on CRAN. You can (pretty) easily create a package and put it on Github. For example, if you keep using some functions in your project, write a general version and put them into a package.\n\ngithub.com/filippogambarota/filor"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#a-more-advanced-approach-r-packages-1",
    "href": "slides/03-modern-r/03-modern-r.html#a-more-advanced-approach-r-packages-1",
    "title": "Modern R",
    "section": "A more advanced approach, R packages",
    "text": "A more advanced approach, R packages\nIf your functions are project-specific you can define them into your scripts or write some R scripts only with functions and source() them into the global environment.\nproject/\n├─ R/\n│  ├─ utils.R\n├─ analysis.R\nAnd inside utils.R you have some functions:\n\nmyfun &lt;- function(x) {\n  # something\n}\n\nThen you can load the function using source(\"R/utils.R) at the beginning of analysis.R:\n\nsource(\"R/utils.R\")"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#analysis-project-as-r-package",
    "href": "slides/03-modern-r/03-modern-r.html#analysis-project-as-r-package",
    "title": "Modern R",
    "section": "Analysis project as R package",
    "text": "Analysis project as R package\nThe R project structure is really interesting to organize a data analysis pipeline. In fact, you can use the project structure. Vuorre and Crump (2021) and Marwick, Boettiger, and Mullen (2018) describe in details the idea.\nThe general approach is:\n\nCreate an R Studio project .Rproj file\nCreate your directories, put scripts, data, etc.\nCreate an R/ folder and put your scripts with functions\nCreate a DESCRIPTION file using usethis::use_description(check_name = FALSE)\nThen you can load your functions without source and with devtools::load_all() (same as library())"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#the-tidy-approach",
    "href": "slides/03-modern-r/03-modern-r.html#the-tidy-approach",
    "title": "Modern R",
    "section": "The Tidy approach",
    "text": "The Tidy approach\nThe tidyverse is a series of high-quality R packages to do modern data science:\n\n\ndata manipulation (dplyr, tidyr)\nplotting (ggplot2)\nreporting (rmarkdown)\nstring manipulation (stringr)\nfunctionals (purrr)\n…"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#the-tidy-approach---pipes",
    "href": "slides/03-modern-r/03-modern-r.html#the-tidy-approach---pipes",
    "title": "Modern R",
    "section": "The Tidy approach - Pipes",
    "text": "The Tidy approach - Pipes\nOne of the great improvement from the tidyverse is the usage of the pipe %&gt;% now introduced in base R as |&gt;. You will se these symbols a lot when looking at modern R code.\n\nThe idea is very simple, the standard pattern to apply a function is function(argument). The pipe can reverse the pattern as argument |&gt; function(). Normally when we apply multiple functions progressively the pattern is this:\n\n\n\nx &lt;- rnorm(100)\nx &lt;- round(x, 3)\nx &lt;- abs(x)\nx &lt;- as.character(x)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#the-tidy-approach---pipes-1",
    "href": "slides/03-modern-r/03-modern-r.html#the-tidy-approach---pipes-1",
    "title": "Modern R",
    "section": "The Tidy approach - Pipes",
    "text": "The Tidy approach - Pipes\nWhen using the pipe, we remove the redundand assignment &lt;- pattern:\n\nx &lt;- rnorm(100)\nx |&gt;\n  round(3) |&gt;\n  abs() |&gt;\n  as.character()\n\nThe pipe can be read as “from x apply round, then abs, etc.”. The first argument of the piped function is assumed to be the result of the previus call."
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#more-about-the-tidy-approach",
    "href": "slides/03-modern-r/03-modern-r.html#more-about-the-tidy-approach",
    "title": "Modern R",
    "section": "More about the Tidy approach",
    "text": "More about the Tidy approach\nThe tidy approach contains tons of functions and packages. The overall philosophy can be deepen in the R for Data Science book.\n\nhttps://r4ds.hadley.nz/"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#ggplot2",
    "href": "slides/03-modern-r/03-modern-r.html#ggplot2",
    "title": "Modern R",
    "section": "ggplot2",
    "text": "ggplot2\nOnly an quick mention to ggplot2 https://ggplot2-book.org/ (part of the tidyverse) that is an amazing package for data visualization following the piping and tidy approach. Is the implementation of the grammar of graphics idea.\n\nlibrary(tidyverse)\n\niris |&gt;\n  mutate(wi = runif(n())) |&gt;\n  ggplot(aes(x = Sepal.Length, y = Petal.Width, color = Species)) +\n  geom_point(aes(size = wi)) +\n  geom_smooth(method = \"lm\", se = FALSE)\n  guides(size = \"none\") +\n  theme_minimal(15)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#ggplot2-1",
    "href": "slides/03-modern-r/03-modern-r.html#ggplot2-1",
    "title": "Modern R",
    "section": "ggplot2",
    "text": "ggplot2"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#base-r-version",
    "href": "slides/03-modern-r/03-modern-r.html#base-r-version",
    "title": "Modern R",
    "section": "Base R version",
    "text": "Base R version\nMore verbose, more hard coding, more steps and intermediate objects.\n\niris_l &lt;- split(iris, iris$Species)\nlms &lt;- lapply(iris_l, function(x) lm(Petal.Width ~ Sepal.Length, data = x))\n\nplot(iris$Sepal.Length, \n     iris$Petal.Width, \n     col = as.numeric(iris$Species), pch = 19)\n\nabline(lms[[1]], col = 1, lwd = 2)\nabline(lms[[2]], col = 2, lwd = 2)\nabline(lms[[3]], col = 3, lwd = 2)\n\nlegend(\"topleft\", legend = levels(iris$Species), fill = 1:3)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#base-r-version-1",
    "href": "slides/03-modern-r/03-modern-r.html#base-r-version-1",
    "title": "Modern R",
    "section": "Base R version",
    "text": "Base R version"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#more-on-ggplot2",
    "href": "slides/03-modern-r/03-modern-r.html#more-on-ggplot2",
    "title": "Modern R",
    "section": "More on ggplot2",
    "text": "More on ggplot2\nThe ggplot2 book https://ggplot2-book.org/ is a great resource to produce high-quality, publication ready plots. Clearly, the advantage of producing the figures entirely writing code are immense in terms of reusability and reproducibility."
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse",
    "href": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse",
    "title": "Modern R",
    "section": "Something crazy in the tidyverse",
    "text": "Something crazy in the tidyverse\nWithout going into details, I want to show you a very interesting approach that you can do with the tidyverse functions.\nLet’s assume you want to do a leave-one-out analysis thus fitting the same models on a dataset, removing one observation at time.\nYou can do it in base R with a loop or other methods, but the see so-called many-models approach. See https://r4ds.had.co.nz/many-models.html and https://www.youtube.com/watch?v=rz3_FDVt9eg."
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-1",
    "href": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-1",
    "title": "Modern R",
    "section": "Something crazy in the tidyverse",
    "text": "Something crazy in the tidyverse\nLet’s define some functions:\n\nleave1out &lt;- function(data){\n  idx &lt;- 1:nrow(data)\n  ll &lt;- lapply(idx, function(i) data[-i, ])\n  names(ll) &lt;- paste0(\"no\", idx)\n  c(no0 = list(data), ll)\n}\n\nfit_model &lt;- function(data){\n  lm(Sepal.Length ~ Petal.Width, data = data)\n}"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-2",
    "href": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-2",
    "title": "Modern R",
    "section": "Something crazy in the tidyverse",
    "text": "Something crazy in the tidyverse\n\ndat &lt;- tibble(data = leave1out(iris[1:20, ]))\ndat |&gt; \n  mutate(removed = names(data)) |&gt; \n  head()\n\n#&gt; # A tibble: 6 × 2\n#&gt;   data          removed\n#&gt;   &lt;named list&gt;  &lt;chr&gt;  \n#&gt; 1 &lt;df [20 × 5]&gt; no0    \n#&gt; 2 &lt;df [19 × 5]&gt; no1    \n#&gt; 3 &lt;df [19 × 5]&gt; no2    \n#&gt; 4 &lt;df [19 × 5]&gt; no3    \n#&gt; 5 &lt;df [19 × 5]&gt; no4    \n#&gt; 6 &lt;df [19 × 5]&gt; no5"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-3",
    "href": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-3",
    "title": "Modern R",
    "section": "Something crazy in the tidyverse",
    "text": "Something crazy in the tidyverse\n\n\n#&gt; # A tibble: 6 × 4\n#&gt;   data          removed fit          results         \n#&gt;   &lt;named list&gt;  &lt;chr&gt;   &lt;named list&gt; &lt;named list&gt;    \n#&gt; 1 &lt;df [20 × 5]&gt; no0     &lt;lm&gt;         &lt;tibble [2 × 5]&gt;\n#&gt; 2 &lt;df [19 × 5]&gt; no1     &lt;lm&gt;         &lt;tibble [2 × 5]&gt;\n#&gt; 3 &lt;df [19 × 5]&gt; no2     &lt;lm&gt;         &lt;tibble [2 × 5]&gt;\n#&gt; 4 &lt;df [19 × 5]&gt; no3     &lt;lm&gt;         &lt;tibble [2 × 5]&gt;\n#&gt; 5 &lt;df [19 × 5]&gt; no4     &lt;lm&gt;         &lt;tibble [2 × 5]&gt;\n#&gt; 6 &lt;df [19 × 5]&gt; no5     &lt;lm&gt;         &lt;tibble [2 × 5]&gt;"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-4",
    "href": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-4",
    "title": "Modern R",
    "section": "Something crazy in the tidyverse",
    "text": "Something crazy in the tidyverse\n\ndat |&gt; \n  mutate(removed = names(data)) |&gt; \n  mutate(fit = map(data, fit_model),\n         results = map(fit, broom::tidy)) |&gt; \n  unnest(results) |&gt; \n  ggplot(aes(x = removed, y = estimate)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~term, scales = \"free\")"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-5",
    "href": "slides/03-modern-r/03-modern-r.html#something-crazy-in-the-tidyverse-5",
    "title": "Modern R",
    "section": "Something crazy in the tidyverse",
    "text": "Something crazy in the tidyverse"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#quick-tables",
    "href": "slides/03-modern-r/03-modern-r.html#quick-tables",
    "title": "Modern R",
    "section": "Quick tables",
    "text": "Quick tables\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1501\n\n\n\n\nSepal.Length\n5.80 (5.10, 6.40)\n\n\nSepal.Width\n3.00 (2.80, 3.30)\n\n\nPetal.Length\n4.35 (1.60, 5.10)\n\n\nPetal.Width\n1.30 (0.30, 1.80)\n\n\nSpecies\n\n\n\n\n    setosa\n50 (33%)\n\n\n    versicolor\n50 (33%)\n\n\n    virginica\n50 (33%)\n\n\n\n1 Median (IQR); n (%)"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#quick-tables-from-models",
    "href": "slides/03-modern-r/03-modern-r.html#quick-tables-from-models",
    "title": "Modern R",
    "section": "Quick tables from models",
    "text": "Quick tables from models\n\nfit &lt;- lm(Sepal.Length ~ Petal.Width, data = iris)\nsjPlot::tab_model(fit)\n\n\n\n\n \nSepal.Length\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n4.78\n4.63 – 4.92\n&lt;0.001\n\n\nPetal Width\n0.89\n0.79 – 0.99\n&lt;0.001\n\n\nObservations\n150\n\n\nR2 / R2 adjusted\n0.669 / 0.667"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#quick-tables-from-models-1",
    "href": "slides/03-modern-r/03-modern-r.html#quick-tables-from-models-1",
    "title": "Modern R",
    "section": "Quick tables from models",
    "text": "Quick tables from models\n\ngtsummary::tbl_regression(fit)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\nPetal.Width\n0.89\n0.79, 0.99\n&lt;0.001\n\n\n\n1 CI = Confidence Interval"
  },
  {
    "objectID": "slides/03-modern-r/03-modern-r.html#references",
    "href": "slides/03-modern-r/03-modern-r.html#references",
    "title": "Modern R",
    "section": "References",
    "text": "References\n\n\n\n\nMarwick, Ben, Carl Boettiger, and Lincoln Mullen. 2018. “Packaging Data Analytical Work Reproducibly Using r (and Friends).” The American Statistician 72 (January): 80–88. https://doi.org/10.1080/00031305.2017.1375986.\n\n\nVuorre, Matti, and Matthew J C Crump. 2021. “Sharing and Organizing Research Products as r Packages.” Behavior Research Methods 53 (April): 792–802. https://doi.org/10.3758/s13428-020-01436-x."
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#git-and-github-1",
    "href": "slides/05-git-github/05-git-github.html#git-and-github-1",
    "title": "Git and Github",
    "section": "Git and Github",
    "text": "Git and Github\n\nThe basic idea is to track changes within a folder, assign a message and eventually a tag to a specific version obtaining a version hystory. The version history is completely navigable, you can go back to a previous version of the code.\nThe are advanced features like branches for creating an independent version of the project to test new features and then merge into the main streamline.\nThe entire (local) Git project can be hosted on Github to improve collaboration. Other people or collaborators can clone the repository and push their changes to the project."
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#veeeery-basic-git-workflow-1",
    "href": "slides/05-git-github/05-git-github.html#veeeery-basic-git-workflow-1",
    "title": "Git and Github",
    "section": "Veeeery basic Git workflow",
    "text": "Veeeery basic Git workflow\nAfter installing Git, you can start a new repository opening a terminal on a folder and typing git init. The folder is now a git project you can notice by the hidden .git folder.\ncd ~/some/folder\ngit init\nThen you can add files to the staging area. Basically these files are ready to be committed i.e. “written” in the Git history.\ngit add file1.txt\n# git add . # add everyting\nFinally you can commit the modified version of the file using git commit -m message\ngit commit -m \"my first amazing commit\"\nyou can see the Git hystory with all your commits:\ngit log"
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#github",
    "href": "slides/05-git-github/05-git-github.html#github",
    "title": "Git and Github",
    "section": "Github",
    "text": "Github\nImagine to put everyting into a server with nice viewing options and advanced features. Github is just an hosting service for your git folder.\nYou can create an empty repository on Github named git-test. Now my repo has the path git@github.com:filippogambarota/git-test.git.\ngit remote add origin git@github.com:filippogambarota/git-test.git\ngit push\nNow our local repository is linked with the remote repository. Every time we do git push our local commits will be uploaded.\nIf you worked on the repository from another machine or a colleague add some changes, you can do git pull and your local machine will be updated.\n\nThe repository git-test is online and can be seen here filippogambarota/git-test."
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#github-1",
    "href": "slides/05-git-github/05-git-github.html#github-1",
    "title": "Git and Github",
    "section": "Github",
    "text": "Github\nAn now let’s see on Github the result:"
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#more-about-git-and-github",
    "href": "slides/05-git-github/05-git-github.html#more-about-git-and-github",
    "title": "Git and Github",
    "section": "More about Git and Github",
    "text": "More about Git and Github\nThere are a lot of resources online:\n\nThe Open Science Manual - Zandonella and Massidda - Git and Github chapters.\nhttps://agripongit.vincenttunru.com/\nhttps://git-scm.com/docs/gittutorial"
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#open-science-framework-1",
    "href": "slides/05-git-github/05-git-github.html#open-science-framework-1",
    "title": "Git and Github",
    "section": "Open Science Framework",
    "text": "Open Science Framework\n\nOSF is a free, open platform to support your research and enable collaboration.\n\nIs a great tool to upload and share materials with others and collaborate on a project. Similarly to Github you can track the changes made to a project.\nThe great addition is having a DOI thus the project is persistently online and can be cited.\nIt is now common practice to create a OSF project supporting a research paper and put the link within the paper containing supplementary materials, raw data, scripts etc."
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#open-science-framework-2",
    "href": "slides/05-git-github/05-git-github.html#open-science-framework-2",
    "title": "Git and Github",
    "section": "Open Science Framework",
    "text": "Open Science Framework\nIt’s very easy to create a new project, then you simply need to add files and share it.\n\nThe project can be accessed here (depending on the visibility) https://osf.io/yf9tg/."
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#open-science-framework-3",
    "href": "slides/05-git-github/05-git-github.html#open-science-framework-3",
    "title": "Git and Github",
    "section": "Open Science Framework",
    "text": "Open Science Framework\nOSF and Github\nAn interesting feature is linking a Github repository to OSF. Now all changes made on Github (easier to manage) are mirrored into OSF. You can easily work in Github for the coding part and use OSF to upload other data or information and to assign a DOI to the project.\nPreprints\nOSF is also linked to a popular service for preprints called PsyArXiv https://psyarxiv.com/ thus you can link a preprint to an OSF project."
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#more-on-osf",
    "href": "slides/05-git-github/05-git-github.html#more-on-osf",
    "title": "Git and Github",
    "section": "More on OSF",
    "text": "More on OSF\n\nhttps://help.osf.io/article/342-getting-started-on-the-osf\nhttps://arca-dpss.github.io/manual-open-science/osf-chapter.html"
  },
  {
    "objectID": "slides/05-git-github/05-git-github.html#more-on-reproducibility",
    "href": "slides/05-git-github/05-git-github.html#more-on-reproducibility",
    "title": "Git and Github",
    "section": "More on reproducibility",
    "text": "More on reproducibility\nIn general, I highly suggest the online book The Open Science Manual https://arca-dpss.github.io/manual-open-science/ written by my friend Claudio Zandonella and Davide Massidda where these and other topics are explained in details:"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#notation",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#notation",
    "title": "Meta-analysis Models",
    "section": "Notation",
    "text": "Notation\nMeta-analysis notation is a little bit inconsistent in textbooks and papers. We define here some rules to simplify the work.\n\n\\(k\\) is the number of studies\n\\(n_j\\) is the sample size of the group \\(j\\) within a study\n\\(y_i\\) are the observed effect size included in the meta-analysis\n\\(\\sigma_i^2\\) are the observed sampling variance of studies and \\(\\epsilon_i\\) are the sampling errors\n\\(\\theta\\) is the equal-effects parameter (see Equation 1)\n\\(\\delta_i\\) is the random-effect (see Equation 4)\n\\(\\mu_\\theta\\) is the average effect of a random-effects model (see Equation 3)\n\\(w_i\\) are the meta-analysis weights\n\\(\\tau^2\\) is the heterogeneity (see Equation 4)\n\\(\\Delta\\) is the (generic) population effect size\n\\(s_j^2\\) is the variance of the group \\(j\\) within a study"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup-1",
    "title": "Meta-analysis Models",
    "section": "Simulation setup",
    "text": "Simulation setup\nGiven the introduction to effect sizes, from now we will simulate data using UMD and the individual-level data.\nBasically we are simulating an effect size \\(D\\) coming from the comparison of two independent groups \\(G_1\\) and \\(G_2\\).\nEach group is composed by \\(n\\) participants measured on a numerical outcome (e.g., reaction times)"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup-2",
    "title": "Meta-analysis Models",
    "section": "Simulation setup",
    "text": "Simulation setup\nA more general, clear and realistic approach to simulate data is by generating \\(k\\) studies with same/different sample sizes and (later) true effect sizes.\n\nk &lt;- 10 # number of studies\nn1 &lt;- n2 &lt;- 10 + rpois(k, 30 - 10) # sample size from poisson distribution with lambda 40 and minimum 10\nD &lt;- 0.5 # effect size\n\nyi &lt;- rep(NA, k)\nvi &lt;- rep(NA, k)\n  \nfor(i in 1:k){\n  g1 &lt;- rnorm(n1[i], 0, 1)\n  g2 &lt;- rnorm(n2[i], D, 1)\n  yi[i] &lt;- mean(g2) - mean(g1)\n  vi[i] &lt;- var(g1)/n1[i] + var(g2)/n2[i]\n}\n  \nsim &lt;- data.frame(id = 1:k, yi, vi)\n\nhead(sim)\n\n#&gt;   id        yi         vi\n#&gt; 1  1 0.7562511 0.04969240\n#&gt; 2  2 0.2291634 0.05342456\n#&gt; 3  3 0.2014451 0.08230128\n#&gt; 4  4 0.6322707 0.07142231\n#&gt; 5  5 0.7198368 0.08825071\n#&gt; 6  6 0.3234732 0.06334575"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup-3",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup-3",
    "title": "Meta-analysis Models",
    "section": "Simulation setup",
    "text": "Simulation setup\nWe can again put everything within a function:\n\nsim_studies &lt;- function(k, es, n1, n2 = NULL){\n  if(length(n1) == 1) n1 &lt;- rep(n1, k)\n  if(is.null(n2)) n2 &lt;- n1\n  if(length(es) == 1) es &lt;- rep(es, k)\n  \n  yi &lt;- rep(NA, k)\n  vi &lt;- rep(NA, k)\n  \n  for(i in 1:k){\n    g1 &lt;- rnorm(n1[i], 0, 1)\n    g2 &lt;- rnorm(n2[i], es[i], 1)\n    yi[i] &lt;- mean(g2) - mean(g1)\n    vi[i] &lt;- var(g1)/n1[i] + var(g2)/n2[i]\n  }\n  \n  sim &lt;- data.frame(id = 1:k, yi, vi, n1 = n1, n2 = n2)\n  \n  # convert to escalc for using metafor methods\n  sim &lt;- metafor::escalc(yi = yi, vi = vi, data = sim)\n  \n  return(sim)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup---disclaimer",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup---disclaimer",
    "title": "Meta-analysis Models",
    "section": "Simulation setup - Disclaimer",
    "text": "Simulation setup - Disclaimer\nThe proposed simulation approach using a for loop and separated vectors. For the purpose of the workshop this is the best option. In real-world meta-analysis simulations you can choose a more functional approach starting from a simulation grid as data.frame and mapping the simulation functions.\nFor some examples see:\n\nGambarota and Altoè (2024)\nwww.jepusto.com/simulating-correlated-smds"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup---disclaimer-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulation-setup---disclaimer-1",
    "title": "Meta-analysis Models",
    "section": "Simulation setup - Disclaimer",
    "text": "Simulation setup - Disclaimer\nFor a more extended overview of the simulation setup we have an entire paper. Supplementary materials (github.com/shared-research/simulating-meta-analysis) contains also more examples for complex (multilevel and multivariate models.)"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#combining-studies-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#combining-studies-1",
    "title": "Meta-analysis Models",
    "section": "Combining studies",
    "text": "Combining studies\nLet’s imagine to have \\(k = 10\\) studies, a \\(D = 0.5\\) and heterogeneous sample sizes in each study.\n\nk &lt;- 10\nD &lt;- 0.5\nn &lt;- 10 + rpois(k, lambda = 20) \ndat &lt;- sim_studies(k = k, es = D, n1 = n)\nhead(dat)\n\n#&gt; \n#&gt;   id     yi     vi n1 n2 \n#&gt; 1  1 0.3170 0.0789 29 29 \n#&gt; 2  2 0.7179 0.0724 26 26 \n#&gt; 3  3 0.3074 0.0677 31 31 \n#&gt; 4  4 0.3630 0.0579 34 34 \n#&gt; 5  5 0.7039 0.0900 28 28 \n#&gt; 6  6 0.5369 0.0686 30 30\n\n\n\nWhat is the best way to combine the studies?"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#combining-studies-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#combining-studies-2",
    "title": "Meta-analysis Models",
    "section": "Combining studies",
    "text": "Combining studies\nWe can take the average effect size and considering it as a huge study. This can be considered the best way to combine the effects.\n\\[\n\\hat{D} = \\frac{\\sum^{k}_{i = 1} D_i}{k}\n\\]\n\nmean(dat$yi)\n#&gt; [1] 0.5604501\n\n\nIt is appropriate? What do you think? Are we missing something?"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#weighting-studies",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#weighting-studies",
    "title": "Meta-analysis Models",
    "section": "Weighting studies",
    "text": "Weighting studies\nWe are not considering that some studies, despite providing a similar effect size could give more information. An higher sample size (or lower sampling variance) produce a more reliable estimation.\n\nWould you trust more a study with \\(n = 100\\) and \\(D = 0.5\\) or a study with \\(n = 10\\) and \\(D = 0.5\\)? The “meta-analysis” that we did before is completely ignoring this information."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#weighting-studies-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#weighting-studies-1",
    "title": "Meta-analysis Models",
    "section": "Weighting studies",
    "text": "Weighting studies\nWe need to find a value (called weight \\(w_i\\)) that allows assigning more trust to a study because it provide more information.\n\nThe simplest weights are just the sample size, but in practice we use the so-called inverse-variance weighting. We use the (inverse) of the sampling variance of the effect size to weight each study.\n\n\nThe basic version of a meta-analysis is just a weighted average:\n\\[\n\\overline D_w = \\frac{\\sum^k_{i = 1}{w_iD_i}}{\\sum^k_{i = 1}{w_i}}\n\\]\n\n\n\nwi &lt;- 1/dat$vi\nsum(dat$yi * wi) / sum(wi)\n\n#&gt; [1] 0.5746279\n\n# weighted.mean(dat$yi, wi)"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#weighting-studies-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#weighting-studies-2",
    "title": "Meta-analysis Models",
    "section": "Weighting studies",
    "text": "Weighting studies\nGraphically, the two models can be represented in this way:\n\n\nCode\ndw &lt;- weighted.mean(dat$yi, 1/dat$vi)\ndunw &lt;- mean(dat$yi)\n\nunw_plot &lt;- ggplot(dat, aes(x = yi, y = factor(id))) +\n  geom_point(size = 3) +\n  xlim(c(-0.5, 1.5)) +\n  geom_vline(xintercept = dunw) +\n  xlab(latex2exp::TeX(\"$y_i$\")) +\n  ylab(\"Study\") +\n  theme_minimal(15) +\n  annotate(\"label\", x = 0.5, y = k + 0.4, label = latex2exp::TeX(sprintf(\"$\\\\bar{D} = %.2f$\", dunw))) +\n  geom_label(aes(x = 1, y = id, label = paste0(\"n = \", n1)))\n\nw_plot &lt;- ggplot(dat, aes(x = yi, y = factor(id))) +\n  geom_point(aes(size = 1/vi),\n             show.legend = FALSE) +\n  xlim(c(-0.5, 1.5)) +\n  geom_vline(xintercept = dw) +\n  xlab(latex2exp::TeX(\"$y_i$\")) +\n  ylab(\"Study\") +\n  theme_minimal(15) +\n  annotate(\"label\", x = 0.5, y = k + 0.4, label = latex2exp::TeX(sprintf(\"$\\\\bar{D}_w = %.2f$\", dw))) +\n  geom_label(aes(x = 1, y = id, label = paste0(\"n = \", n1)))\n\nunw_plot + w_plot"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-meta-analysis",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-meta-analysis",
    "title": "Meta-analysis Models",
    "section": "EE meta-analysis",
    "text": "EE meta-analysis\nWhat we did in the last example (the weighted mean) is the exactly a meta-analysis model called equal-effects (or less precisely fixed-effect). The assumptions are very simple:\n\nthere is a unique, true effect size to estimate \\(\\theta\\)\neach study is a more or less precise estimate of \\(\\theta\\)\nthere is no TRUE variability among studies. The observed variability is due to studies that are imprecise (i.e., sampling error)\nassuming that each study has a very large sample size, the observed variability is close to zero."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-meta-analysis-formally",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-meta-analysis-formally",
    "title": "Meta-analysis Models",
    "section": "EE meta-analysis, formally",
    "text": "EE meta-analysis, formally\n\\[\ny_i = \\theta + \\epsilon_i\n\\tag{1}\\]\n\\[\n\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)\n\\tag{2}\\]\nWhere \\(\\sigma^2_i\\) is the vector of sampling variabilities of \\(k\\) studies. This is a standard linear model but with heterogeneous sampling variances."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-meta-analysis-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-meta-analysis-1",
    "title": "Meta-analysis Models",
    "section": "EE meta-analysis",
    "text": "EE meta-analysis"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-an-ee-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-an-ee-model",
    "title": "Meta-analysis Models",
    "section": "Simulating an EE model",
    "text": "Simulating an EE model\nWhat we were doing with the sim_studies() function so far was simulating an EE model. In fact, there were a single \\(\\theta\\) parameter and the observed variability was a function of the rnorm() randomness.\nBased on previous assumptions and thinking a little bit, what could be the result of simulating studies with a very large \\(n\\)?\n\n\nns &lt;- c(10, 50, 100, 1000, 1e4)\nD &lt;- 0.5\ndats &lt;- lapply(ns, function(n) sim_studies(10, es = D, n1 = n))"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#sec-ee-impact-n",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#sec-ee-impact-n",
    "title": "Meta-analysis Models",
    "section": "Simulating an EE modelm",
    "text": "Simulating an EE modelm"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-an-ee-model-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-an-ee-model-1",
    "title": "Meta-analysis Models",
    "section": "Simulating an EE model",
    "text": "Simulating an EE model\nFormulating the model as a intercept-only regression (see Equations Equation 1 and Equation 2) we can generate data directly:\n\nD &lt;- 0.5\nn &lt;- 30\nk &lt;- 10\n\nyi &lt;- D + rnorm(k, 0, sqrt(1/n + 1/n))\n# or equivalently\n# yi &lt;- rnorm(k, D, sqrt(1/n + 1/n))\n\nAs we did for the aggregated data approach. Clearly we need to simulate also the vi vector from the appropriate distribution. Given that we simulated data starting from the participant-level the uncertainty of yi and vi is already included."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#fitting-an-ee-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#fitting-an-ee-model",
    "title": "Meta-analysis Models",
    "section": "Fitting an EE model",
    "text": "Fitting an EE model\nThe model can be fitted using the metafor::rma() function, with method = \"EE\"1.\n\ntheta &lt;- 0.5\nk &lt;- 15\nn &lt;- 10 + rpois(k, 30 - 10)\ndat &lt;- sim_studies(k = k, es = theta, n1 = n)\nfit &lt;- rma(yi, vi, data = dat, method = \"EE\")\nsummary(fit)\n#&gt; \n#&gt; Equal-Effects Model (k = 15)\n#&gt; \n#&gt;   logLik  deviance       AIC       BIC      AICc   \n#&gt;  -1.8959   16.4195    5.7918    6.4999    6.0995   \n#&gt; \n#&gt; I^2 (total heterogeneity / total variability):   14.74%\n#&gt; H^2 (total variability / sampling variability):  1.17\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 14) = 16.4195, p-val = 0.2884\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt;   0.5658  0.0660  8.5672  &lt;.0001  0.4364  0.6952  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThere is a confusion about the fixed-effects vs fixed-effect (no s) and equal-effects models. See https://wviechtb.github.io/metafor/reference/misc-models.html"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model",
    "title": "Meta-analysis Models",
    "section": "Interpreting an EE model",
    "text": "Interpreting an EE model\n\nThe first section (logLik, deviance, etc.) presents some general model statistics and information criteria\nThe \\(I^2\\) and \\(H^2\\) are statistics evaluating the observed heterogeneity (see next slides)\nThe Test of Heterogeneity section presents the test of the \\(Q\\) statistics for the observed heterogeneity (see next slides)\nThe Model Results section presents the estimation of the \\(\\theta\\) parameter along with the standard error and the Wald \\(z\\) test (\\(H_0: \\theta = 0\\))\n\nThe metafor package has a several well documented functions to calculate and plot model results, residuals analysis etc."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model-1",
    "title": "Meta-analysis Models",
    "section": "Interpreting an EE model",
    "text": "Interpreting an EE model\n\nplot(fit) # general plots"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model-2",
    "title": "Meta-analysis Models",
    "section": "Interpreting an EE Model",
    "text": "Interpreting an EE Model\nThe main function for plotting model results is the forest() function that produce the forest plot.\n\nforest(fit)"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model-3",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#interpreting-an-ee-model-3",
    "title": "Meta-analysis Models",
    "section": "Interpreting an EE Model",
    "text": "Interpreting an EE Model\nWe did not introduced the concept of heterogeneity, but the \\(I^2\\), \\(H^2\\) and \\(Q\\) statistics basically evaluate if the observed heterogeneity should be attributed to sampling variability (uncertainty in estimating \\(\\theta\\) because we have a limited \\(k\\) and \\(n\\)) or sampling variability plus other sources of heterogeneity."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-model-as-a-weighted-average",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#ee-model-as-a-weighted-average",
    "title": "Meta-analysis Models",
    "section": "EE model as a weighted Average",
    "text": "EE model as a weighted Average\nFormally \\(\\theta\\) is estimated as (see Borenstein et al. 2009, 66)\n\\[\n\\hat{\\theta} = \\frac{\\sum^k_{i = 1}{w_iy_i}}{\\sum^k_{i = 1}{w_i}}; \\;\\;\\; w_i = \\frac{1}{\\sigma^2_i}\n\\]\n\\[\nSE_{\\theta} = \\frac{1}{\\sum^k_{i = 1}{w_i}}\n\\]\n\nwi &lt;- 1/dat$vi\ntheta_hat &lt;- with(dat, sum(yi * wi)/sum(wi))\nse_theta_hat &lt;- sqrt(1/sum(wi))\nc(theta = theta_hat, se = se_theta_hat, z = theta_hat / se_theta_hat)\n#&gt;     theta        se         z \n#&gt; 0.5658010 0.0660428 8.5671866"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#are-the-ee-assumptions-realistic",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#are-the-ee-assumptions-realistic",
    "title": "Meta-analysis Models",
    "section": "Are the EE assumptions realistic?",
    "text": "Are the EE assumptions realistic?\nThe EE model is appropriate if our studies are somehow exact replications of the exact same effect. We are assuming that there is no real variability.\n\nHowever, meta-analysis rarely report the results of \\(k\\) exact replicates. It is more common to include studies answering the same research question but with different methods, participants, etc.\n\n\n\npeople with different ages or other participant-level differences\ndifferent methodology\n…"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#are-the-ee-assumptions-realistic-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#are-the-ee-assumptions-realistic-1",
    "title": "Meta-analysis Models",
    "section": "Are the EE assumptions realistic?",
    "text": "Are the EE assumptions realistic?\n\nIf we relax the previous assumption we are able to combine studies that are not exact replications.\n\n\nThus the real effect \\(\\theta\\) is no longer a single true value but can be larger or smaller in some conditions.\n\n\nIn other terms we are assuming that there could be some variability (i.e., heterogeneity) among studies that is independent from the sample size. Even with studies with \\(\\lim_{n\\to\\infty}\\) the observed variability is not zero."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#random-effects-model-re",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#random-effects-model-re",
    "title": "Meta-analysis Models",
    "section": "Random-effects model (RE)",
    "text": "Random-effects model (RE)\nWe can extend the EE model including another source of variability, \\(\\tau^2\\). \\(\\tau^2\\) is the true heterogeneity among studies caused by methdological differences or intrisic variability in the phenomenon.\nFormally we can extend Equation 1 as: \\[\ny_i = \\mu_{\\theta} + \\delta_i + \\epsilon_i\n\\tag{3}\\]\n\\[\n\\delta_i \\sim \\mathcal{N}(0, \\tau^2)\n\\tag{4}\\]\n\\[\n\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)\n\\]\nWhere \\(\\mu_{\\theta}\\) is the average effect size and \\(\\delta_i\\) is the study-specific deviation from the average effect (regulated by \\(\\tau^2\\)). Clearly each study specific effect is \\(\\theta_i = \\mu_{\\theta} + \\delta_i\\)."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-model",
    "title": "Meta-analysis Models",
    "section": "RE model",
    "text": "RE model"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-model-estimation",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-model-estimation",
    "title": "Meta-analysis Models",
    "section": "RE model estimation",
    "text": "RE model estimation\nGiven that we extended the EE model equation. Also the estimation of the average effect need to be extended. Basically the RE is still a weighted average but weights need to include also \\(\\tau^2\\).\n\\[\n\\overline y = \\frac{\\sum_{i = 1}^k y_iw^*_i}{\\sum_{i = 1}^k w^*_i}\n\\tag{5}\\]\n\\[\nw^*_i = \\frac{1}{\\sigma^2_i + \\tau^2}\n\\tag{6}\\]\nThe weights are different compared to the EE model. Extremely precise/imprecise studies will have less impact in the RE model."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-vs-ee-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-vs-ee-model",
    "title": "Meta-analysis Models",
    "section": "RE vs EE model",
    "text": "RE vs EE model\nThe crucial difference with the EE model is that even with large \\(n\\), only the \\(\\mu_{\\theta} + \\delta_i\\) are estimated (almost) without error. As long \\(\\tau^2 \\neq 0\\) there will be variability in the effect sizes."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model",
    "title": "Meta-analysis Models",
    "section": "Simulating a RE Model",
    "text": "Simulating a RE Model\nTo simulate the RE model we simply need to include \\(\\tau^2\\) in the EE model simulation.\n\nk &lt;- 15 # number of studies\nmu &lt;- 0.5 # average effect\ntau2 &lt;- 0.1 # heterogeneity\nn &lt;- 10 + rpois(k, 30 - 10) # sample size\ndeltai &lt;- rnorm(k, 0, sqrt(tau2)) # random-effects\nthetai &lt;- mu + deltai # true study effect\n\ndat &lt;- sim_studies(k = k, es = thetai, n1 = n)\n\nhead(dat)\n\n#&gt; \n#&gt;   id      yi     vi n1 n2 \n#&gt; 1  1  0.3991 0.0528 34 34 \n#&gt; 2  2  0.4081 0.0650 27 27 \n#&gt; 3  3  0.0646 0.0862 26 26 \n#&gt; 4  4 -0.2003 0.0391 38 38 \n#&gt; 5  5  0.8870 0.0605 31 31 \n#&gt; 6  6  1.0143 0.0581 31 31"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-1",
    "title": "Meta-analysis Models",
    "section": "Simulating a RE model",
    "text": "Simulating a RE model\nAgain, we can put everything within a function expanding the previous sim_studies() by including \\(\\tau^2\\):\nsim_studies &lt;- function(k, es, tau2 = 0, n1, n2 = NULL, add = NULL){\n  if(length(n1) == 1) n1 &lt;- rep(n1, k)\n  if(is.null(n2)) n2 &lt;- n1\n  if(length(es) == 1) es &lt;- rep(es, k)\n  \n  yi &lt;- rep(NA, k)\n  vi &lt;- rep(NA, k)\n  \n  # random effects\n  deltai &lt;- rnorm(k, 0, sqrt(tau2))\n  \n  for(i in 1:k){\n    g1 &lt;- rnorm(n1[i], 0, 1)\n    g2 &lt;- rnorm(n2[i], es[i] + deltai[i], 1)\n    yi[i] &lt;- mean(g2) - mean(g1)\n    vi[i] &lt;- var(g1)/n1[i] + var(g2)/n2[i]\n  }\n  \n  sim &lt;- data.frame(id = 1:k, yi, vi, n1 = n1, n2 = n2)\n  \n  if(!is.null(add)){\n    sim &lt;- cbind(sim, add)\n  }\n  \n  # convert to escalc for using metafor methods\n  sim &lt;- metafor::escalc(yi = yi, vi = vi, data = sim)\n  \n  return(sim)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-2",
    "title": "Meta-analysis Models",
    "section": "Simulating a RE model",
    "text": "Simulating a RE model\nThe data are similar to the EE simulation but we have an extra source of heterogeneity.\n\n\nCode\ndat |&gt;\n  summary() |&gt;\n  qforest()"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-3",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-3",
    "title": "Meta-analysis Models",
    "section": "Simulating a RE model",
    "text": "Simulating a RE model\nTo see the actual impact of \\(\\tau^2\\) we can follow the same approach of Section 3.5 thus using a large \\(n\\). The sampling variance vi of each study is basically 0.\n\n# ... other parameters as before\nn &lt;- 1e4\ndeltai &lt;- rnorm(k, 0, sqrt(tau2)) # random-effects\nthetai &lt;- mu + deltai # true study effect\ndat &lt;- sim_studies(k = k, es = thetai, n1 = n)\n# or equivalently \n# dat &lt;- sim_studies(k = k, es = mu, tau2 = tau2, n1 = n)\n\nhead(dat)\n\n#&gt; \n#&gt;   id      yi     vi    n1    n2 \n#&gt; 1  1  0.3495 0.0002 10000 10000 \n#&gt; 2  2  0.6788 0.0002 10000 10000 \n#&gt; 3  3  0.3411 0.0002 10000 10000 \n#&gt; 4  4 -0.0409 0.0002 10000 10000 \n#&gt; 5  5  0.6032 0.0002 10000 10000 \n#&gt; 6  6  0.7977 0.0002 10000 10000"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-4",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#simulating-a-re-model-4",
    "title": "Meta-analysis Models",
    "section": "Simulating a RE Model",
    "text": "Simulating a RE Model\nClearly, compared to Section 3.5, even with large \\(n\\) the variability is not reduced because \\(\\tau^2 \\neq 0\\). As \\(\\tau^2\\) approach zero the EE and RE models are similar.\n\n\nCode\ndat |&gt;\n  summary() |&gt;\n  qforest()"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-model-estimation-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#re-model-estimation-1",
    "title": "Meta-analysis Models",
    "section": "RE model estimation",
    "text": "RE model estimation\nGiven that we extended the EE model equation. Also the estimation of the average effect need to be extended. Basically the RE is still a weighted average but weights need to include also \\(\\tau^2\\).\n\\[\n\\overline y = \\frac{\\sum_{i = 1}^k y_iw^*_i}{\\sum_{i = 1}^k w^*_i}\n\\tag{7}\\]\n\\[\nw^*_i = \\frac{1}{\\sigma^2_i + \\tau^2}\n\\tag{8}\\]\nThe weights are different compared to the EE model. Extremely precise/imprecise studies will have less impact in the RE model."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#fitting-a-re-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#fitting-a-re-model",
    "title": "Meta-analysis Models",
    "section": "Fitting a RE model",
    "text": "Fitting a RE model\nIn R we can use the metafor::rma() function using the method = \"REML\".\n\nfit &lt;- rma(yi, vi, data = dat, method = \"REML\")\nsummary(fit)\n#&gt; \n#&gt; Random-Effects Model (k = 15; tau^2 estimator: REML)\n#&gt; \n#&gt;   logLik  deviance       AIC       BIC      AICc   \n#&gt;  -2.0872    4.1745    8.1745    9.4526    9.2654   \n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.0787 (SE = 0.0298)\n#&gt; tau (square root of estimated tau^2 value):      0.2805\n#&gt; I^2 (total heterogeneity / total variability):   99.75%\n#&gt; H^2 (total variability / sampling variability):  394.95\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 14) = 5542.1126, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt;   0.5241  0.0725  7.2267  &lt;.0001  0.3820  0.6662  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#intepreting-the-re-model",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#intepreting-the-re-model",
    "title": "Meta-analysis Models",
    "section": "Intepreting the RE model",
    "text": "Intepreting the RE model\nThe model output is quite similar to the EE model and also the intepretation is similar.\nThe only extra section is tau^2/tau that is the estimation of the between-study heterogeneity.\n\nsummary(fit)\n\n#&gt; \n#&gt; Random-Effects Model (k = 15; tau^2 estimator: REML)\n#&gt; \n#&gt;   logLik  deviance       AIC       BIC      AICc   \n#&gt;  -2.0872    4.1745    8.1745    9.4526    9.2654   \n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.0787 (SE = 0.0298)\n#&gt; tau (square root of estimated tau^2 value):      0.2805\n#&gt; I^2 (total heterogeneity / total variability):   99.75%\n#&gt; H^2 (total variability / sampling variability):  394.95\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 14) = 5542.1126, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt;   0.5241  0.0725  7.2267  &lt;.0001  0.3820  0.6662  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#estimating-tau2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#estimating-tau2",
    "title": "Meta-analysis Models",
    "section": "Estimating \\(\\tau^2\\)",
    "text": "Estimating \\(\\tau^2\\)"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#estimating-tau2-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#estimating-tau2-1",
    "title": "Meta-analysis Models",
    "section": "Estimating \\(\\tau^2\\)",
    "text": "Estimating \\(\\tau^2\\)\nThe Restricted Maximum Likelihood (REML) estimator is considered one of the best. We can compare the results using the all_rma() custom function that tests all the estimators1.\n\nfitl &lt;- all_rma(fit)\nround(filor::compare_rma(fitlist = fitl), 3)\n\n#&gt;           DL     HE     HS    HSk     SJ     ML   REML     EB     PM    PMM\n#&gt; b      0.524  0.524  0.524  0.524  0.524  0.524  0.524  0.524  0.524  0.524\n#&gt; se     0.073  0.073  0.070  0.073  0.073  0.070  0.073  0.073  0.073  0.074\n#&gt; zval   7.218  7.227  7.472  7.218  7.227  7.480  7.227  7.227  7.227  7.054\n#&gt; pval   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n#&gt; ci.lb  0.382  0.382  0.387  0.382  0.382  0.387  0.382  0.382  0.382  0.378\n#&gt; ci.ub  0.666  0.666  0.662  0.666  0.666  0.661  0.666  0.666  0.666  0.670\n#&gt; I2    99.747 99.747 99.729 99.747 99.747 99.729 99.747 99.747 99.747 99.759\n#&gt; tau2   0.079  0.079  0.074  0.079  0.079  0.073  0.079  0.079  0.079  0.083\n\n\nThe filor::compare_rma() function is similar to the car::compareCoefs() function"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#intepreting-heterogeneity-tau2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#intepreting-heterogeneity-tau2",
    "title": "Meta-analysis Models",
    "section": "Intepreting heterogeneity \\(\\tau^2\\)",
    "text": "Intepreting heterogeneity \\(\\tau^2\\)\nLooking at Equation 4, \\(\\tau^2\\) is essentially the variance of the random-effect. This means that we can intepret it as the variability (or the standard deviation) of the true effect size distribution.\n\n\nCode\ntau2s &lt;- c(0.01, 0.05, 0.1, 0.2)\ntau2s_t &lt;- latex2exp::TeX(sprintf(\"$\\\\tau^2 = %.2f$\", tau2s))\n\npar(mfrow = c(1, 3))\nhist(rnorm(1e4, 0, sqrt(tau2s[1])), xlim = c(-2, 2), xlab = latex2exp::TeX(\"$y_i$\"), main = tau2s_t[1], probability = TRUE, ylim = c(0, 4.5), col = \"dodgerblue\")\nhist(rnorm(1e4, 0, sqrt(tau2s[2])), xlim = c(-2, 2), xlab = latex2exp::TeX(\"$y_i$\"), main = tau2s_t[2], probability = TRUE, ylim = c(0, 4.5), col = \"dodgerblue\")\n#hist(rnorm(1e4, 0, sqrt(tau2s[3])), xlim = c(-2, 2), xlab = latex2exp::TeX(\"$y_i$\"), main = tau2s_t[3], probability = TRUE, ylim = c(0, 5))\nhist(rnorm(1e4, 0, sqrt(tau2s[4])), xlim = c(-2, 2), xlab = latex2exp::TeX(\"$y_i$\"), main = tau2s_t[4], probability = TRUE, ylim = c(0, 4.5), col = \"dodgerblue\")"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#intepreting-tau2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#intepreting-tau2",
    "title": "Meta-analysis Models",
    "section": "Intepreting \\(\\tau^2\\)",
    "text": "Intepreting \\(\\tau^2\\)\nAs in the previus plot we can assume \\(n = \\infty\\) and generate true effects from Equation 4. In this way we understand the impact of assuming (or estimating) a certain \\(\\tau^2\\).\nFor example, a \\(\\tau = 0.2\\) and a \\(\\mu_{\\theta} = 0.5\\), 50% of the true effects ranged between:\n\nD &lt;- 0.5\nyis &lt;- D + rnorm(1e5, 0, 0.2)\nquantile(yis, c(0.75, 0.25))\n\n#&gt;       75%       25% \n#&gt; 0.6356239 0.3640649"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics",
    "title": "Meta-analysis Models",
    "section": "The \\(Q\\) Statistics1",
    "text": "The \\(Q\\) Statistics1\nThe Q statistics is used to make inference on the heterogeneity. Can be considered as a weighted sum of squares:\n\\[\nQ = \\sum^k_{i = 1}w_i(y_i - \\hat \\mu)^2\n\\]\nWhere \\(\\hat \\mu\\) is EE estimation (regardless if \\(\\tau^2 \\neq 0\\)) and \\(w_i\\) are the inverse-variance weights. Note that in the case of \\(w_1 = w_2 ... = w_i\\), Q is just a standard sum of squares (or deviance).\nSee Harrer et al. (2021) (Chapter 5) and Hedges and Schauer (2019) for an overview about the Q statistics"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics-1",
    "title": "Meta-analysis Models",
    "section": "The \\(Q\\) Statistics",
    "text": "The \\(Q\\) Statistics\n\nGiven that we are summing up squared distances, they should be approximately \\(\\chi^2\\) with \\(df = k - 1\\). In case of no heterogeneity (\\(\\tau^2 = 0\\)) the observed variability is only caused by sampling error and the expectd value of the \\(\\chi^2\\) is just the degrees of freedom (\\(df = k - 1\\)).\nIn case of \\(\\tau^2 \\neq 0\\), the expected value is \\(k - 1 + \\lambda\\) where \\(\\lambda\\) is a non-centrality parameter.\nIn other terms, if the expected value of \\(Q\\) exceed the expected value assuming no heterogeneity, we have evidence that \\(\\tau^2 \\neq 0\\)."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics-2",
    "title": "Meta-analysis Models",
    "section": "The \\(Q\\) Statistics",
    "text": "The \\(Q\\) Statistics\nLet’s try a more practical approach. We simulate a lot of meta-analysis with and without heterogeneity and we check the Q statistics.\n\n\nCode\nget_Q &lt;- function(yi, vi){\n  wi &lt;- 1/vi\n  theta_ee &lt;- weighted.mean(yi, wi)\n  sum(wi*(yi - theta_ee)^2)\n}\n\nk &lt;- 30\nn &lt;- 30\ntau2 &lt;- 0.1\nnsim &lt;- 1e4\n\nQs_tau2_0 &lt;- rep(0, nsim)\nQs_tau2 &lt;- rep(0, nsim)\nres2_tau2_0 &lt;- vector(\"list\", nsim)\nres2_tau2 &lt;- vector(\"list\", nsim)\n\nfor(i in 1:nsim){\n  dat_tau2_0 &lt;- sim_studies(k = 30, es = 0.5, tau2 = 0, n1 = n)\n  dat_tau2 &lt;- sim_studies(k = 30, es = 0.5, tau2 = tau2, n1 = n)\n  \n  theta_ee_tau2_0 &lt;- weighted.mean(dat_tau2_0$yi, 1/dat_tau2_0$vi)\n  theta_ee &lt;- weighted.mean(dat_tau2$yi, 1/dat_tau2$vi)\n  \n  res2_tau2_0[[i]] &lt;- dat_tau2_0$yi - theta_ee_tau2_0\n  res2_tau2[[i]] &lt;- dat_tau2$yi - theta_ee\n  \n  Qs_tau2_0[i] &lt;- get_Q(dat_tau2_0$yi, dat_tau2_0$vi)\n  Qs_tau2[i] &lt;- get_Q(dat_tau2$yi, dat_tau2$vi)\n}"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics-3",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#the-q-statistics-3",
    "title": "Meta-analysis Models",
    "section": "The \\(Q\\) Statistics",
    "text": "The \\(Q\\) Statistics\nLet’s try a more practical approach. We simulate a lot of meta-analysis with and without heterogeneity and we check the Q statistics.\n\n\nclearly, in the presence of heterogeneity, the expected value of the Q statistics is higher (due to \\(\\lambda \\neq 0\\)) and also residuals are larger (the \\(\\chi^2\\) is just a sum of squared weighted residuals)\n\n\n\n\nwe can calculate a p-value for deviation from the \\(\\tau^2 = 0\\) case as evidence agaist the absence of heterogeneity"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#i2-higgins2002-fh",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#i2-higgins2002-fh",
    "title": "Meta-analysis Models",
    "section": "\\(I^2\\) (Higgins and Thompson 2002)",
    "text": "\\(I^2\\) (Higgins and Thompson 2002)\nWe have two sources of variability in a random-effects meta-analysis, the sampling variability \\(\\sigma_i^2\\) and true heterogeneity \\(\\tau^2\\). We can use the \\(I^2\\) to express the interplay between the two. \\[\nI^2 = 100\\% \\times \\frac{\\hat{\\tau}^2}{\\hat{\\tau}^2 + \\tilde{v}}\n\\tag{9}\\]\n\\[\n\\tilde{v} = \\frac{(k-1) \\sum w_i}{(\\sum w_i)^2 - \\sum w_i^2},\n\\]\nWhere \\(\\tilde{v}\\) is the typical sampling variability. \\(I^2\\) is intepreted as the proportion of total variability due to real heterogeneity (i.e., \\(\\tau^2\\))"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#i2-higgins2002-fh-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#i2-higgins2002-fh-1",
    "title": "Meta-analysis Models",
    "section": "\\(I^2\\) (Higgins and Thompson 2002)1",
    "text": "\\(I^2\\) (Higgins and Thompson 2002)1\nNote that we can have the same \\(I^2\\) in two completely different meta-analysis. An high \\(I^2\\) does not represent high heterogeneity. Let’s assume to have two meta-analysis with \\(k\\) studies and small (\\(n = 30\\)) vs large (\\(n = 500\\)) sample sizes.\nLet’s solve Equation 9 for \\(\\tau^2\\) (using filor::tau2_from_I2()) and we found that the same \\(I^2\\) can be obtained with two completely different \\(\\tau^2\\) values:\n\nn_1 &lt;- 30\nvi_1 &lt;- 1/n_1 + 1/n_1\ntau2_1 &lt;- filor::tau2_from_I2(0.8, vi_1)\ntau2_1\n#&gt; [1] 0.2666667\n\nn_2 &lt;- 500\nvi_2 &lt;- 1/n_2 + 1/n_2\ntau2_2 &lt;- filor::tau2_from_I2(0.8, vi_2)\ntau2_2\n#&gt; [1] 0.016\n\nsee https://www.meta-analysis-workshops.com/download/common-mistakes1.pdf"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#i2-higgins2002-fh-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#i2-higgins2002-fh-2",
    "title": "Meta-analysis Models",
    "section": "\\(I^2\\) (Higgins and Thompson 2002)",
    "text": "\\(I^2\\) (Higgins and Thompson 2002)\n\nn_1 &lt;- 30\nvi_1 &lt;- 1/n_1 + 1/n_1\ntau2_1 &lt;- filor::tau2_from_I2(0.8, vi_1)\ntau2_1\n#&gt; [1] 0.2666667\n\nn_2 &lt;- 500\nvi_2 &lt;- 1/n_2 + 1/n_2\ntau2_2 &lt;- filor::tau2_from_I2(0.8, vi_2)\ntau2_2\n#&gt; [1] 0.016\n\n\nIn other terms, the \\(I^2\\) can be considered a good index of heterogeneity only when the total variance (\\(\\tilde{v} + \\tau^2\\)) is similar."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#what-about-tildev",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#what-about-tildev",
    "title": "Meta-analysis Models",
    "section": "What about \\(\\tilde{v}\\)?",
    "text": "What about \\(\\tilde{v}\\)?\n\\(\\tilde{v}\\) is considered the “typical” within-study variability (see https://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate). There are different estimators but Equation 10 is the most common.\n\\[\n\\tilde{v} = \\frac{(k-1) \\sum w_i}{(\\sum w_i)^2 - \\sum w_i^2}\n\\tag{10}\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#what-about-tildev-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#what-about-tildev-1",
    "title": "Meta-analysis Models",
    "section": "What about \\(\\tilde{v}\\)?",
    "text": "What about \\(\\tilde{v}\\)?\nIn the hypothetical case where \\(\\sigma^2_1 = \\dots = \\sigma^2_k\\), \\(\\tilde{v}\\) is just \\(\\sigma^2\\). This fact is commonly used to calculate the statistical power analytically (Borenstein et al. 2009, chap. 29).\n\nvtilde &lt;- function(wi){\n  k &lt;- length(wi)\n  (k - 1) * sum(wi) / (sum(wi)^2 - sum(wi^2))\n}\n\nk &lt;- 20\n\n# same vi\nvi &lt;- rep((1/30 + 1/30), k)\nhead(vi)\n\n#&gt; [1] 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n\nvtilde(1/vi)\n\n#&gt; [1] 0.06666667\n\n# heterogeneous vi\nn &lt;- 10 + rpois(k, 30 - 10)\nvi &lt;- sim_vi(k = k, n1 = n)\nvtilde(1/vi)\n\n#&gt; [1] 0.06037917"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#what-about-tildev-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#what-about-tildev-2",
    "title": "Meta-analysis Models",
    "section": "What about \\(\\tilde{v}\\)?",
    "text": "What about \\(\\tilde{v}\\)?\nUsing simulations we can see that \\(\\tilde{v}\\) with heterogenenous variances (i.e., sample sizes in this case) can be approximated by the central tendency of the sample size distribution. Note that we are fixing \\(\\sigma^2 = 1\\) thus we are not including uncertainty.\n\n\nCode\nk &lt;- 100 # number of studies\nn &lt;- 30 # sample size\n\nvti &lt;- rep(NA, 1e5)\n\nfor(i in 1:1e5){\n  ni &lt;- rpois(k, n)\n  vi &lt;- 1/ni + 1/ni\n  vti[i] &lt;- vtilde(1/vi)\n}\n\n# vtilde calculated from lambda\nvt &lt;- 1/n + 1/n"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#h2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#h2",
    "title": "Meta-analysis Models",
    "section": "\\(H^2\\)",
    "text": "\\(H^2\\)\nThe \\(H^2\\) is an alternative index of heterogeneity. Is calculated as:\n\\[\nH^2 = \\frac{Q}{k - 1}\n\\]\nWe defined \\(Q\\) as the weighted sum of squares representing the total variability. \\(k - 1\\) is the expected value of the \\(\\chi^2\\) statistics (i.e., sum of squares) when \\(\\tau^2 = 0\\) (or \\(\\lambda = 0\\)).\nThus \\(H^2\\) is the ratio between total heterogeneity and sampling variability. Higher \\(H^2\\) is associated with higher heterogeneity relative to the sampling variability. \\(H^2\\) is not a measure of absolute heterogeneity."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#h2-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#h2-1",
    "title": "Meta-analysis Models",
    "section": "\\(H^2\\)",
    "text": "\\(H^2\\)\nWhen we are fitting a RE model, the \\(I^2\\) and \\(H^2\\) equations are slightly different (Higgins and Thompson 2002). See also the metafor source code.\n\nk &lt;- 100\nmu &lt;- 0.5\ntau2 &lt;- 0.1\nn &lt;- 30\n\ndat &lt;- sim_studies(k = k, es = mu, tau2 = tau2, n1 = n)\nfit_re &lt;- rma(yi, vi, data = dat, method = \"REML\")\nfit_ee &lt;- rma(yi, vi, data = dat, method = \"EE\")\n\n# H2 with EE model\n\ntheta_ee &lt;- fit_ee$b[[1]] # weighted.mean(dat$yi, 1/dat$vi)\nwi &lt;- 1/dat$vi\nQ &lt;- with(dat, sum((1/vi)*(yi - theta_ee)^2))\nc(Q, fit_ee$QE) # same\n#&gt; [1] 258.8639 258.8639\n\nc(H2 = fit_ee$QE / (fit_ee$k - fit_ee$p), H2_model = fit_ee$H2) # same\n#&gt;       H2 H2_model \n#&gt; 2.614787 2.614787\n\n# H2 with RE model\n\nvt &lt;- vtilde(1/dat$vi)\nc(H2 = fit_re$tau2 / vt + 1, H2_model = fit_re$H2) # same\n#&gt;       H2 H2_model \n#&gt; 2.627768 2.627768"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals",
    "title": "Meta-analysis Models",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nWhat is reported in the model summary as ci.lb and ci.ub refers to the 95% confidence interval representing the uncertainty in estimating the effect (or a meta-regression parameter).\nWithout looking at the equations, let’s try to implement this idea using simulations.\n\nchoose \\(k\\), \\(\\tau^2\\) and \\(n\\)\nsimulate data (several times) accordingly and fit the RE model\nextract the estimated effect size\ncompare the simulated sampling distribution with the analytical result"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-1",
    "title": "Meta-analysis Models",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nk &lt;- 30\nn &lt;- 30\ntau2 &lt;- 0.05\nmu &lt;- 0.5\nnsim &lt;- 5e3\n\n# true parameters (see Borenstein, 2009; Chapter 29)\nvt &lt;- 1/n + 1/n\nvs &lt;- (vt + tau2)/ k\nse &lt;- sqrt(vs)\n\nmui &lt;- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  dat &lt;- sim_studies(k = k, es = mu, tau2 = tau2, n1 = n)\n  fit &lt;- rma(yi, vi, data = dat)\n  mui[i] &lt;- coef(fit)[1]\n}\n\n# standard error\nc(simulated = sd(mui), analytical = fit$se)\n#&gt;  simulated analytical \n#&gt; 0.06258738 0.06425927\n\n# confidence interval\nrbind(\n  \"simulated\"  = quantile(mui, c(0.05, 0.975)),\n  \"analytical\" = c(\"2.5%\" = fit$ci.lb, \"97.5%\" = fit$ci.ub)\n)\n#&gt;                   5%     97.5%\n#&gt; simulated  0.3988312 0.6225649\n#&gt; analytical 0.4431912 0.6950829"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-2",
    "title": "Meta-analysis Models",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nhist(mui, breaks = 50, freq = FALSE, main = \"Sampling Distribution\", xlab = latex2exp::TeX(\"$\\\\mu_{\\\\theta}$\"))\ncurve(dnorm(x, mu, se), add = TRUE, col = \"firebrick\", lwd = 1.5)"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-3",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-3",
    "title": "Meta-analysis Models",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nNow the equation for the 95% confidence interval should be more clear. The standard error is a function of the within study sampling variances (depending mainly on \\(n\\)), \\(\\tau^2\\) and \\(k\\). As we increase \\(k\\) the standard error tends towards zero.\n\\[\nCI = \\hat \\mu_{\\theta} \\pm z SE_{\\mu_{\\theta}}\n\\]\n\\[\nSE_{\\mu_{\\theta}} = \\sqrt{\\frac{1}{\\sum^{k}_{i = 1}w^{\\star}_i}}\n\\]\n\\[\nw^{\\star}_i = \\frac{1}{\\sigma^2_i + \\tau^2}\n\\]"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-4",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#confidence-intervals-4",
    "title": "Meta-analysis Models",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nWe can also see it analytically, there is a huge impact of \\(k\\).\n\n\nCode\n# true parameters (see Borenstein, 2009; Chapter 29)\nvt &lt;- 1/n + 1/n\nvs &lt;- (vt + tau2)/ k\nse &lt;- sqrt(vs)\n\nk &lt;- c(10, 50, 100, 500, 1000, 5000)\nn &lt;- c(10, 50, 100, 500, 1000, 5000)\ntau2 &lt;- c(0, 0.05, 0.1, 0.2)\n\ndd &lt;- expand.grid(k = k, n = n, tau2 = tau2)\n\ndd$vt &lt;- with(dd, 1/n + 1/n)\ndd$vs &lt;- with(dd, (vt + tau2)/ k)\ndd$se &lt;- sqrt(dd$vs)\n\ndd$k &lt;- as_tex_label(dd$k, \"$k = %s$\")\n\nggplot(dd, aes(x = n, y = se, color = factor(tau2))) +\n  geom_line() +\n  facet_wrap(~k, labeller = label_parsed) +\n  labs(color = latex2exp::TeX(\"\\\\tau^2\")) +\n  xlab(\"Sample Size (n)\") +\n  ylab(latex2exp::TeX(\"$SE_{\\\\mu_{\\\\theta}}$\"))"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#prediction-intervals-pi",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#prediction-intervals-pi",
    "title": "Meta-analysis Models",
    "section": "Prediction intervals (PI)",
    "text": "Prediction intervals (PI)\nWe could say that the CI is not completely taking into account the between-study heterogeneity (\\(\\tau^2\\)). After a meta-analysis we would like to know how confident we are in the parameters estimation BUT also what would be the expected effect running a new experiment tomorrow?.\nThe prediction interval (IntHout et al. 2016; Riley, Higgins, and Deeks 2011) is exactly the range of effects that I expect in predicting a new study."
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#pi-for-a-sample-mean",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#pi-for-a-sample-mean",
    "title": "Meta-analysis Models",
    "section": "PI for a sample mean",
    "text": "PI for a sample mean\nTo understand the concept, let’s assume to have a sample \\(X\\) of size \\(n\\) and we estimate the mean \\(\\overline X\\). The PI is calculated as1:\n\\[\nPI = \\overline X \\pm t_{\\alpha/2} s_x \\sqrt{1 + \\frac{1}{n}}\n\\]\nWhere \\(s\\) is the sample standard deviation. Basically we are combining the uncertainty in estimating \\(\\overline X\\) (i.e, \\(\\frac{s_x}{n}\\)) with the standard deviation of the data \\(s_x\\). Compare it with the confidence interval containing only \\(\\frac{s_x}{n}\\).\nNotice that the equation, in particular the usage of \\(t\\) vs \\(z\\) depends on assuming \\(s_x\\) to be known or estimated. See https://online.stat.psu.edu/stat501/lesson/3/3.3, https://en.wikipedia.org/wiki/Prediction_interval and https://www.bryanshalloway.com/2021/03/18/intuition-on-uncertainty-of-predictions-introduction-to-prediction-intervals/"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#pi-in-meta-analysis",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#pi-in-meta-analysis",
    "title": "Meta-analysis Models",
    "section": "PI in meta-analysis",
    "text": "PI in meta-analysis\nFor meta-analysis the equation1 is conceptually similar but with different quantities.\n\\[\nPI = \\hat \\mu_{\\theta} \\pm z \\sqrt{\\tau^2 + SE_{\\mu_{\\theta}}}\n\\]\nBasically we are combining all the sources of uncertainty. As long as \\(\\tau^2 \\neq 0\\) the PI is greater than the CI (in the EE model they are the same). Thus even with very precise \\(\\mu_{\\theta}\\) estimation, large \\(\\tau^2\\) leads to uncertain predictions.\nWhen a \\(t\\) distribution is assumed, the quantiles are calculated using \\(k - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#pi-in-meta-analysis-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#pi-in-meta-analysis-1",
    "title": "Meta-analysis Models",
    "section": "PI in meta-analysis",
    "text": "PI in meta-analysis\nIn R the PI can be calculated using predict(). By default the model assume a standard normal distribution thus using \\(z\\) scores. To use the Riley, Higgins, and Deeks (2011) approach (\\(t\\) distribution) the model need to be fitted using test = \"t\".\n\nk &lt;- 100\ndat &lt;- sim_studies(k = k, es = 0.5, tau2 = 0.1, n1 = 30)\nfit_z &lt;- rma(yi, vi, data = dat, test = \"z\") # test = \"z\" is the default\npredict(fit_z) # notice pi.ub/pi.lb vs ci.ub/ci.lb\n\n#&gt; \n#&gt;    pred     se  ci.lb  ci.ub  pi.lb  pi.ub \n#&gt;  0.4874 0.0348 0.4191 0.5557 0.0231 0.9518\n\n# manually\nfit_z$b[[1]] + qnorm(c(0.025, 0.975)) * sqrt(fit_z$se^2 + fit_z$tau2)\n\n#&gt; [1] 0.02305362 0.95179763\n\nfit_t &lt;- rma(yi, vi, data = dat, test = \"t\")\npredict(fit_t) # notice pi.ub/pi.lb vs ci.ub/ci.lb\n\n#&gt; \n#&gt;    pred     se  ci.lb  ci.ub  pi.lb  pi.ub \n#&gt;  0.4874 0.0348 0.4183 0.5566 0.0173 0.9575\n\n# manually\nfit_z$b[[1]] + qt(c(0.025, 0.975), k - 2) * sqrt(fit_t$se^2 + fit_t$tau2)\n\n#&gt; [1] 0.01724804 0.95760321"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-1",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-1",
    "title": "Meta-analysis Models",
    "section": "Aggregated vs raw data",
    "text": "Aggregated vs raw data\nMeta-analysis is about data aggregation (calculating the effect size at level-2) before modelling. What about using raw data instead? Is aggregating harmful or harmless?\n\nk &lt;- 30\ntau2 &lt;- 0.1\nes &lt;- 0.3\nn0 &lt;- 20 + rpois(k, 50 - 20)\nn1 &lt;- 20 + rpois(k, 50 - 20)\n\nout &lt;- vector(mode = \"list\", length = k) \n\ndeltai &lt;- rnorm(k, 0, sqrt(tau2))\n\nfor(i in 1:k){\n    g0 &lt;- rnorm(n0[i], 0, 1)\n    g1 &lt;- rnorm(n1[i], es + deltai[i], 1)\n    di &lt;- data.frame(\n        study = i,\n        y = c(g0, g1),\n        x = rep(c(\"g0\", \"g1\"), c(n0[i], n1[i]))\n    )\n    out[[i]] &lt;- di\n}\n\nsim &lt;- do.call(rbind, out)\n\nhead(sim)\n\n#&gt;   study          y  x\n#&gt; 1     1  0.8184228 g0\n#&gt; 2     1 -1.1395138 g0\n#&gt; 3     1 -2.2432348 g0\n#&gt; 4     1  0.5565674 g0\n#&gt; 5     1  0.1663299 g0\n#&gt; 6     1 -1.0107637 g0"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-2",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-2",
    "title": "Meta-analysis Models",
    "section": "Aggregated vs raw data",
    "text": "Aggregated vs raw data\n\nsimMeta &lt;- sim |&gt; \n    group_by(study, x) |&gt; \n    summarise(m = mean(y),\n              sd = sd(y),\n              n = n()) |&gt; \n    pivot_wider(names_from = x,\n                values_from = c(m, sd, n))\n\nsimMeta &lt;- escalc(\"SMD\", \n       m1i = m_g1, m2i = m_g0, \n       sd1i = sd_g1, sd2i = sd_g0,\n       n1i = n_g1, n2i = n_g0,\n       data = simMeta)\n\nhead(simMeta)\n\n#&gt; \n#&gt;   study        m_g0       m_g1     sd_g0     sd_g1 n_g0 n_g1      yi     vi \n#&gt; 1     1  0.19200189 0.02464804 0.9414959 1.0709007   42   47 -0.1639 0.0452 \n#&gt; 2     2  0.08279314 0.08984458 1.0244343 0.7629781   56   48  0.0077 0.0387 \n#&gt; 3     3  0.18937040 0.50453016 0.9848663 0.9530404   57   46  0.3222 0.0398 \n#&gt; 4     4  0.09351035 0.34070072 0.9089565 0.9384300   50   48  0.2656 0.0412 \n#&gt; 5     5 -0.17711014 0.70898606 0.9628739 0.8628356   67   61  0.9610 0.0349 \n#&gt; 6     6 -0.15473455 0.08080807 0.8631814 0.8925961   55   54  0.2664 0.0370"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-3",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-3",
    "title": "Meta-analysis Models",
    "section": "Aggregated vs raw data",
    "text": "Aggregated vs raw data\n\nfit_lme4 &lt;- lmer(y ~ x + (x|study), data = sim)\nfit_rma &lt;- rma(yi, vi, data = simMeta)\n\nsummary(fit_lme4)\n\n#&gt; Linear mixed model fit by REML ['lmerMod']\n#&gt; Formula: y ~ x + (x | study)\n#&gt;    Data: sim\n#&gt; \n#&gt; REML criterion at convergence: 8664.5\n#&gt; \n#&gt; Scaled residuals: \n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.0370 -0.6750  0.0010  0.6673  3.2886 \n#&gt; \n#&gt; Random effects:\n#&gt;  Groups   Name        Variance Std.Dev. Corr \n#&gt;  study    (Intercept) 0.000351 0.01873       \n#&gt;           xg1         0.114007 0.33765  -1.00\n#&gt;  Residual             0.988385 0.99418       \n#&gt; Number of obs: 3044, groups:  study, 30\n#&gt; \n#&gt; Fixed effects:\n#&gt;             Estimate Std. Error t value\n#&gt; (Intercept) -0.02191    0.02552  -0.859\n#&gt; xg1          0.27976    0.07145   3.915\n#&gt; \n#&gt; Correlation of Fixed Effects:\n#&gt;     (Intr)\n#&gt; xg1 -0.466\n#&gt; optimizer (nloptwrap) convergence code: 0 (OK)\n#&gt; boundary (singular) fit: see help('isSingular')"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-4",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#aggregated-vs-raw-data-4",
    "title": "Meta-analysis Models",
    "section": "Aggregated vs raw data",
    "text": "Aggregated vs raw data\n\nsummary(fit_rma)\n\n#&gt; \n#&gt; Random-Effects Model (k = 30; tau^2 estimator: REML)\n#&gt; \n#&gt;   logLik  deviance       AIC       BIC      AICc   \n#&gt; -12.4731   24.9461   28.9461   31.6807   29.4077   \n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.0964 (SE = 0.0361)\n#&gt; tau (square root of estimated tau^2 value):      0.3105\n#&gt; I^2 (total heterogeneity / total variability):   70.30%\n#&gt; H^2 (total variability / sampling variability):  3.37\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 29) = 96.8771, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval   ci.lb   ci.ub      \n#&gt;   0.2719  0.0677  4.0181  &lt;.0001  0.1393  0.4045  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#references",
    "href": "slides/06-meta-analysis/03-meta-analysis-models/meta-analysis-models.html#references",
    "title": "Meta-analysis Models",
    "section": "References",
    "text": "References\n\n\nBorenstein, Michael, Larry V Hedges, Julian P T Higgins, and Hannah R Rothstein. 2009. “Introduction to Meta-Analysis.” https://doi.org/10.1002/9780470743386.\n\n\nGambarota, Filippo, and Gianmarco Altoè. 2024. “Understanding Meta-Analysis Through Data Simulation with Applications to Power Analysis.” Advances in Methods and Practices in Psychological Science 7 (January). https://doi.org/10.1177/25152459231209330.\n\n\nHarrer, Mathias, Pim Cuijpers, Toshi Furukawa, and David Ebert. 2021. Doing Meta-Analysis with r: A Hands-on Guide. 1st ed. London, England: CRC Press.\n\n\nHedges, Larry V, and Jacob M Schauer. 2019. “Statistical Analyses for Studying Replication: Meta-Analytic Perspectives.” Psychological Methods 24 (October): 557–70. https://doi.org/10.1037/met0000189.\n\n\nHiggins, Julian P T, and Simon G Thompson. 2002. “Quantifying Heterogeneity in a Meta-Analysis.” Statistics in Medicine 21 (June): 1539–58. https://doi.org/10.1002/sim.1186.\n\n\nIntHout, Joanna, John P A Ioannidis, Maroeska M Rovers, and Jelle J Goeman. 2016. “Plea for Routinely Presenting Prediction Intervals in Meta-Analysis.” BMJ Open 6 (July): e010247. https://doi.org/10.1136/bmjopen-2015-010247.\n\n\nRiley, Richard D, Julian P T Higgins, and Jonathan J Deeks. 2011. “Interpretation of Random Effects Meta-Analyses.” BMJ 342 (February): d549. https://doi.org/10.1136/bmj.d549."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb-1",
    "title": "Publication Bias",
    "section": "Publication Bias (PB)",
    "text": "Publication Bias (PB)\nThe PB is a very critical most problematic aspects of meta-analysis. Essentially the probability of publishing a paper (~and thus including into the meta-analysis) is not the same regardless of the result."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-disclaimer",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-disclaimer",
    "title": "Publication Bias",
    "section": "Publication Bias Disclaimer!",
    "text": "Publication Bias Disclaimer!\nWe cannot (completely) solve the PB using statistical tools. The PB is a problem related to the publishing process and publishing incentives\n\n\npre-registrations, multi-lab studies, etc. can (almost) completely solve the problem filling the literature with unbiased studies\n\n\n\n\nthere are statistical tools to detect, estimate and correct for the publication bias. As every statistical method, they are influenced by statistical assumptions, number of studies and sample size, heterogeneity, etc."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---the-big-picture",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---the-big-picture",
    "title": "Publication Bias",
    "section": "Publication Bias (PB) - The Big Picture1",
    "text": "Publication Bias (PB) - The Big Picture1\n\n\n\n\n\n\n\n\n\nThanks to the Wolfgang Viechtbauer’s course https://www.wvbauer.com/doku.php/course_ma"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\nThe easiest way to understand the PB is by simulating what happen without the PB. Let’s simulate a lot of studies (under a EE model) keeping all the results without selection (the ideal world).\n\nset.seed(2023)\nk &lt;- 1e3\nn &lt;- round(runif(k, 10, 100))\ntheta &lt;- 0.3\ndat &lt;- sim_studies(k = k, es = theta, tau2 = 0, n1 = n)\ndat &lt;- summary(dat)\n# compute 1 tail pvalue\ndat$pval1 &lt;- 1 - pnorm(dat$zi)\nht(dat)\n#&gt; \n#&gt;        id      yi     vi n1 n2    sei      zi   pval   ci.lb  ci.ub       pval1 \n#&gt; 1       1  0.3483 0.0406 52 52 0.2015  1.7287 0.0839 -0.0466 0.7431 0.041927744 \n#&gt; 2       2  0.3762 0.0605 40 40 0.2460  1.5291 0.1262 -0.1060 0.8585 0.063119366 \n#&gt; 3       3  0.0634 0.0911 25 25 0.3018  0.2101 0.8336 -0.5281 0.6549 0.416800171 \n#&gt; 4       4  0.4101 0.0487 46 46 0.2206  1.8588 0.0631 -0.0223 0.8426 0.031530757 \n#&gt; 5       5 -0.0476 0.1160 13 13 0.3405 -0.1398 0.8888 -0.7151 0.6199 0.555581669 \n#&gt; 995   995  0.3584 0.0950 24 24 0.3083  1.1625 0.2450 -0.2458 0.9625 0.122511729 \n#&gt; 996   996  0.3939 0.1697 17 17 0.4120  0.9562 0.3390 -0.4135 1.2014 0.169484321 \n#&gt; 997   997  0.5205 0.0486 35 35 0.2204  2.3610 0.0182  0.0884 0.9525 0.009112230 \n#&gt; 998   998  0.4206 0.0815 29 29 0.2854  1.4737 0.1406 -0.1388 0.9801 0.070283435 \n#&gt; 999   999  0.0625 0.0244 83 83 0.1562  0.3999 0.6893 -0.2438 0.3687 0.344631179 \n#&gt; 1000 1000  0.5547 0.0416 37 37 0.2039  2.7201 0.0065  0.1550 0.9544 0.003263493"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-1",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\n\npar(mfrow = c(1, 3))\nhist(dat$yi, breaks = 50, col = \"dodgerblue\", main = \"Effect Size\")\nplot(dat$yi, dat$pval1, pch = 19, col = ifelse(dat$pval1 &lt;= 0.05, scales::alpha(\"firebrick\", 0.5), scales::alpha(\"black\", 0.5)),\n     main = \"P value (one tail) ~ Effect size\")\nabline(h = 0.05)\nplot(dat$yi, dat$pval, pch = 19, col = ifelse(dat$pval &lt;= 0.05, scales::alpha(\"firebrick\", 0.5), scales::alpha(\"black\", 0.5)),\n     main = \"P value (two tails) ~ Effect size\")\nabline(h = 0.05)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-2",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\nThen, let’s assume that our publishing system is very strict (extreme). You can publish only if \\(p \\leq 0.05\\) on the expected direction. Then the true population of effect sizes will be truncated. Essentially we are assuming that \\(P(1|p \\leq 0.05) = 1\\) and \\(P(1|p \\leq 0.05) = 0\\).\n\n# selecting\nsign &lt;- dat$pval1 &lt;= 0.05 & dat$zi &gt; 0\ndat_pb &lt;- dat[sign, ]\ndat_un &lt;- dat[sample(1:nrow(dat), sum(sign)), ]\n\n# fitting EE model for the full vs selected (ignore k differences)\nfit &lt;- rma(yi, vi, method = \"EE\", data = dat_un)\nfit_pb &lt;- rma(yi, vi, method = \"EE\", data = dat_pb)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-3",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-3",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\nThen, let’s assume that our publishing system is very strict (extreme). You can publish only if \\(p \\leq 0.05\\) on the expected direction. Then the true population of effect sizes will be truncated. Essentially we are assuming that \\(P(1|p \\leq 0.05) = 1\\) and \\(P(1|p \\leq 0.05) = 0\\).\n\nround(compare_rma(fit, fit_pb), 3)\n#&gt; fit: rma(yi = yi, vi = vi, data = dat_un, method = \"EE\")\n#&gt; fit_pb: rma(yi = yi, vi = vi, data = dat_pb, method = \"EE\")\n#&gt;                fit fit_pb\n#&gt; b (intrcpt)  0.289  0.436\n#&gt; se           0.009  0.008\n#&gt; zval        32.003 51.811\n#&gt; pval         0.000  0.000\n#&gt; ci.lb        0.271  0.420\n#&gt; ci.ub        0.307  0.453\n#&gt; I2           0.955  0.000\n#&gt; tau2         0.000  0.000"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-4",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-4",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\nThe situation is even worse when we simulate a null effect. This strict selection results in committing type-1 error:\n\nset.seed(2023)\nk &lt;- 1e3\nn &lt;- round(runif(k, 10, 100))\ndat0 &lt;- sim_studies(k = k, es = 0, tau2 = 0, n1 = n)\ndat0 &lt;- summary(dat0)\n# compute 1 tail pvalue\ndat0$pval1 &lt;- 1 - pnorm(dat0$zi)\n# selecting\nsign &lt;- dat0$pval1 &lt;= 0.05 & dat0$zi &gt; 0\ndat_pb0 &lt;- dat0[sign, ]\ndat_un0 &lt;- dat0[sample(1:nrow(dat0), sum(sign)), ]\n\n# fitting EE model for the full vs selected (ignore k differences)\nfit0 &lt;- rma(yi, vi, method = \"EE\", data = dat_un0)\nfit_pb0 &lt;- rma(yi, vi, method = \"EE\", data = dat_pb0)\nround(compare_rma(fit0, fit_pb0), 3)\n#&gt; fit0: rma(yi = yi, vi = vi, data = dat_un0, method = \"EE\")\n#&gt; fit_pb0: rma(yi = yi, vi = vi, data = dat_pb0, method = \"EE\")\n#&gt;               fit0 fit_pb0\n#&gt; b (intrcpt) -0.006   0.363\n#&gt; se           0.027   0.026\n#&gt; zval        -0.220  14.015\n#&gt; pval         0.826   0.000\n#&gt; ci.lb       -0.059   0.312\n#&gt; ci.ub        0.047   0.414\n#&gt; I2           0.000   0.000\n#&gt; tau2         0.000   0.000"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-5",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-5",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\nAssuming to pick a very precise (\\(n = 1000\\)) and a very unprecise (\\(n = 20\\)) study, which one is more likely to have an effect size close to the true value?\n\nThe precise study has a lower \\(\\epsilon_i\\) thus is closer to \\(\\theta\\). This relationship create a very insightful visual representation.\n\n\nWhat could be the shape of the plot when plotting the precision (e.g., the sample size or the inverse of the variance) as a function of the effect size?"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-6",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-under-an-ee-model-6",
    "title": "Publication Bias",
    "section": "PB under an EE model",
    "text": "PB under an EE model\n\n#|code-fold: true\nplot(dat$yi, sqrt(dat$vi), ylim=rev(range(dat$vi)), pch = 19, col = scales::alpha(\"black\", 0.5), cex = 1.5)\nabline(v = theta, lwd = 3, col = \"firebrick\")"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---funnel-plot",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---funnel-plot",
    "title": "Publication Bias",
    "section": "Publication Bias (PB) - Funnel Plot",
    "text": "Publication Bias (PB) - Funnel Plot\nWe created a funnel plot. This is a visual tool to check the presence of asymmetry that could be caused by publication bias. If meta-analysis assumptions are respected, and there is no publication bias:\n\neffects should be normally distributed around the average effect\nmore precise studies should be closer to the average effect\nless precise studies could be equally distributed around the average effect"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---funnel-plot-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---funnel-plot-1",
    "title": "Publication Bias",
    "section": "Publication Bias (PB) - Funnel Plot",
    "text": "Publication Bias (PB) - Funnel Plot\nThe plot assume the typical funnel shape and there are not missing spots on the at the bottom. The presence of missing spots is a potential index of publication bias.\n\n\nCode\nfit &lt;- rma(yi, vi, method = \"EE\", data = dat)\ndat$pb &lt;- dat$pval &lt;= 0.05\n\nwith(dat[dat$pb, ],\n     plot(yi, sei,\n          ylim = rev(range(dat$sei)),\n          xlab = latex2exp::TeX(\"$y_i$\"),\n          ylab = latex2exp::TeX(\"$\\\\sqrt{\\\\sigma_i^2}$\"),\n          xlim = range(dat$yi),\n          pch = 19,\n          col = scales::alpha(\"firebrick\", 0.5))\n)\n\nwith(dat[!dat$pb, ],\n     points(yi, sei, col = scales::alpha(\"black\", 0.5), pch = 19)\n)\n\nabline(v = fit$b[[1]], col = \"black\", lwd = 1.2)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---funnel-plot-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---funnel-plot-2",
    "title": "Publication Bias",
    "section": "Publication Bias (PB) - Funnel Plot",
    "text": "Publication Bias (PB) - Funnel Plot\nThe plot assume the typical funnel shape and there are not missing spots on the at the bottom. The presence of missing spots is a potential index of publication bias."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#robustness-to-pb---fail-safe-n",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#robustness-to-pb---fail-safe-n",
    "title": "Publication Bias",
    "section": "Robustness to PB - Fail-safe N",
    "text": "Robustness to PB - Fail-safe N\nThe Fail-safe N (Rosenthal 1979) idea is very simple. Given a meta-analysis with a significant result (i.e., \\(p \\leq \\alpha\\)). How many null studies (i.e., \\(\\hat \\theta = 0\\)) do I need to obtain \\(p &gt; \\alpha\\)?\n\nmetafor::fsn(yi, vi, data = dat)\n#&gt; \n#&gt; Fail-safe N Calculation Using the Rosenthal Approach\n#&gt; \n#&gt; Observed Significance Level: &lt;.0001\n#&gt; Target Significance Level:   0.05\n#&gt; \n#&gt; Fail-safe N: 832741"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#robustness-to-pb---fail-safe-n-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#robustness-to-pb---fail-safe-n-1",
    "title": "Publication Bias",
    "section": "Robustness to PB - Fail-safe N",
    "text": "Robustness to PB - Fail-safe N\nThere are several criticism to the Fail-safe N procedure:\n\n\nis not actually detecting the PB but suggesting the required PB size to remove the effect. A very large N suggest that even with PB, it is unlikely that the results could be completely changed by actually reporting null studies\n\n\n\n\nOrwin (1983) proposed a new method calculating the number of studies required to reduce the effect size to a given target\n\n\n\n\nRosenberg (2005) proposed a method similar to Rosenthal (1979) but combining the (weighted) effect sizes and not the p-values."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#detecting-pb---egger-regression",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#detecting-pb---egger-regression",
    "title": "Publication Bias",
    "section": "Detecting PB - Egger Regression",
    "text": "Detecting PB - Egger Regression\nA basic method to test the funnel plot asymmetry is using an the Egger regression test. Basically we calculate the relationship between \\(y_i\\) and \\(\\sqrt{\\sigma^2_i}\\). In the absence of asimmetry, the line slope should be not different from 0.\nWe can use the metafor::regtest() function:\n\negger &lt;- regtest(fit)\negger\n#&gt; \n#&gt; Regression Test for Funnel Plot Asymmetry\n#&gt; \n#&gt; Model:     fixed-effects meta-regression model\n#&gt; Predictor: standard error\n#&gt; \n#&gt; Test for Funnel Plot Asymmetry: z = -0.3621, p = 0.7173\n#&gt; Limit Estimate (as sei -&gt; 0):   b =  0.3061 (CI: 0.2601, 0.3520)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---egger-regression",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#publication-bias-pb---egger-regression",
    "title": "Publication Bias",
    "section": "Publication Bias (PB) - Egger Regression",
    "text": "Publication Bias (PB) - Egger Regression\n\nThis is a standard (meta) regression thus the number of studies, the precision of each study and heterogeneity influence the reliability (power, type-1 error rate, etc.) of the procedure."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---trim-and-fill",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---trim-and-fill",
    "title": "Publication Bias",
    "section": "Correcting PB - Trim and Fill",
    "text": "Correcting PB - Trim and Fill\nThe Trim and Fill method (Duval and Tweedie 2000) is used to impute the hypothetical missing studies according to the funnel plot and recomputing the meta-analysis effect. Shi and Lin (Shi and Lin 2019) provide an updated overview of the method with some criticisms.\n\n\nset.seed(2023)\nk &lt;- 100 # we increased k to better show the effect\ntheta &lt;- 0.5\ntau2 &lt;- 0.1\nn &lt;- runif(k, 10, 100)\ndat &lt;- sim_studies(k, theta, tau2, n)\ndat &lt;- summary(dat)\ndatpb &lt;- dat[dat$pval &lt;= 0.1 & dat$zi &gt; 0, ]\nfit &lt;- rma(yi, vi, data = datpb, method = \"REML\")"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---trim-and-fill-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---trim-and-fill-1",
    "title": "Publication Bias",
    "section": "Correcting PB - Trim and Fill",
    "text": "Correcting PB - Trim and Fill\nNow we can use the metafor::trimfill() function:\n\ntaf &lt;- metafor::trimfill(fit)\ntaf\n#&gt; \n#&gt; Estimated number of missing studies on the left side: 15 (SE = 5.4670)\n#&gt; \n#&gt; Random-Effects Model (k = 84; tau^2 estimator: REML)\n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.0562 (SE = 0.0146)\n#&gt; tau (square root of estimated tau^2 value):      0.2371\n#&gt; I^2 (total heterogeneity / total variability):   61.61%\n#&gt; H^2 (total variability / sampling variability):  2.60\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 83) = 210.3501, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se     zval    pval   ci.lb   ci.ub      \n#&gt;   0.5934  0.0339  17.5084  &lt;.0001  0.5270  0.6598  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThe trim-and-fill estimates that 15 are missing. The new effect size after including the studies is reduced and closer to the simulated value (but in this case still significant)."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---trim-and-fill-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---trim-and-fill-2",
    "title": "Publication Bias",
    "section": "Correcting PB - Trim and Fill",
    "text": "Correcting PB - Trim and Fill\nWe can also visualize the funnel plot highligting the points that are included by the method.\n\nfunnel(taf)\n\n\n\nCode\nfunnel(taf)\negg &lt;- regtest(fit)\negg_npb &lt;- regtest(taf)\nse &lt;- seq(0,1.8,length=100)\nlines(coef(egg$fit)[1] + coef(egg$fit)[2]*se, se, lwd=3, col = \"black\")\nlines(coef(egg_npb$fit)[1] + coef(egg_npb$fit)[2]*se, se, lwd=3, col = \"firebrick\")\nlegend(\"topleft\", legend = c(\"Original\", \"Corrected\"), fill = c(\"black\", \"firebrick\"))"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nThis funnel plot show an evident asymmetry on the left side. Is there evidence of publication bias? What do you think?\n\nset.seed(2024)\nk &lt;- 50\nn1 &lt;- round(runif(k, 10, 200))\nn2 &lt;- round(runif(k, 10, 50))\ndat1 &lt;- sim_studies(k, 0, 0, n1, add = list(x = 0))\ndat2 &lt;- sim_studies(k, 0.5, 0.05, n2, add = list(x = 1))\ndat &lt;- rbind(dat1, dat2)\nfit &lt;- rma(yi, vi, dat = dat)\nfunnel(fit)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-1",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nThe data are of course simulated and this is the code. What do you think now?\n\nset.seed(2024)\nk &lt;- 50\nn1 &lt;- round(runif(k, 10, 200))\nn2 &lt;- round(runif(k, 10, 50))\ndat1 &lt;- sim_studies(k, 0, 0, n1, add = list(x = 0))\ndat2 &lt;- sim_studies(k, 0.5, 0.05, n2, add = list(x = 1))\ndat &lt;- rbind(dat1, dat2)\nfit &lt;- rma(yi, vi, dat = dat)\nfunnel(fit)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-2",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nIn fact, these are two unbiased population of effect sizes. Extra source of heterogeneity could create asymmetry not related to PB.\n\npar(mfrow = c(1, 2))\nfunnel(fit)\nfunnel(fit, col = dat$x + 1)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-3",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-3",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nAlso the methods to detect/correct for PB are committing a false alarm:\n\nregtest(fit)\n#&gt; \n#&gt; Regression Test for Funnel Plot Asymmetry\n#&gt; \n#&gt; Model:     mixed-effects meta-regression model\n#&gt; Predictor: standard error\n#&gt; \n#&gt; Test for Funnel Plot Asymmetry: z =  6.2569, p &lt; .0001\n#&gt; Limit Estimate (as sei -&gt; 0):   b = -0.2067 (CI: -0.3460, -0.0675)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-4",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-4",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nAlso the methods to detect/correct for PB are committing a false alarm:\n\ntrimfill(fit)\n#&gt; \n#&gt; Estimated number of missing studies on the left side: 32 (SE = 6.3553)\n#&gt; \n#&gt; Random-Effects Model (k = 132; tau^2 estimator: REML)\n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.2183 (SE = 0.0337)\n#&gt; tau (square root of estimated tau^2 value):      0.4672\n#&gt; I^2 (total heterogeneity / total variability):   86.77%\n#&gt; H^2 (total variability / sampling variability):  7.56\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 131) = 639.7238, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval    ci.lb   ci.ub    \n#&gt;   0.0281  0.0457  0.6142  0.5391  -0.0615  0.1177    \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-5",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-5",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nThe regtest can be applied also with moderators. The idea should be to take into account the moderators effects and then check for asymmetry.\n\nfitm &lt;- rma(yi, vi, mods = ~x, data = dat)\nregtest(fitm)\n#&gt; \n#&gt; Regression Test for Funnel Plot Asymmetry\n#&gt; \n#&gt; Model:     mixed-effects meta-regression model\n#&gt; Predictor: standard error\n#&gt; \n#&gt; Test for Funnel Plot Asymmetry: z = -1.0277, p = 0.3041"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-6",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#why-the-funnel-plot-can-be-misleading-6",
    "title": "Publication Bias",
    "section": "Why the funnel plot can be misleading?",
    "text": "Why the funnel plot can be misleading?\nIn fact, the funnel plot on the raw dataset and on residuals looks quite different because the asymmetry was caused by the moderator.\n\n\nCode\ndat$ri &lt;- residuals(fitm)\nfitr &lt;- rma(ri, vi, data = dat)\npar(mfrow = c(1, 2))\nplot_regtest(fit, main = \"Full model\")\nplot_regtest(fitr, main = \"Residuals\")"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---selection-models-sm",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---selection-models-sm",
    "title": "Publication Bias",
    "section": "Correcting PB - Selection Models (SM)",
    "text": "Correcting PB - Selection Models (SM)\nSM are more than a tool for correcting for the PB. SM are formal models of PB that can help us understanding and simulating the PB.\nThe SM are composed by two parts:\n\nEffect size model: the unbiased data generation process. In our case basically the sim_studies() function.\nSelection model: the assumed process generating the biased selection of effect sizes\n\nSelection models can be based on the p-value (e.g., p-curve or p-uniform) and/or the effect size and variance (Copas model). We will see only models based on the p-value."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---selection-models-sm-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---selection-models-sm-1",
    "title": "Publication Bias",
    "section": "Correcting PB - Selection Models (SM)",
    "text": "Correcting PB - Selection Models (SM)\nFormally, the random-effect meta-analysis probability density function (PDF) can be written as (e.g., Citkowicz and Vevea 2017):\n\\[\nf\\left(y_i \\mid \\beta, \\tau^2 ; \\sigma_i^2\\right)=\\frac{\\phi\\left(\\frac{y_i-\\Delta_i}{\\sqrt{\\sigma_i^2+\\tau^2}}\\right)}{\\int_{-\\infty}^{\\infty}  \\phi\\left(\\frac{Y_i-\\Delta_i}{\\sqrt{\\sigma_i^2+\\tau^2}}\\right) d y_i}\n\\]\nWithout going into details, this is the PDF without any selection process (i.e., the effect sizes model)."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---selection-models-sm-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#correcting-pb---selection-models-sm-2",
    "title": "Publication Bias",
    "section": "Correcting PB - Selection Models (SM)",
    "text": "Correcting PB - Selection Models (SM)\nIf we have a function linking the p-value with the probability of publishing (a weight function) \\(w(p_i)\\) we can include it in the previous PDF, creating a weighted PDF.\n\\[\nf\\left(y_i \\mid \\beta, \\tau^2 ; \\sigma_i^2\\right)=\\frac{\\mathrm{w}\\left(p_i\\right) \\phi\\left(\\frac{y_i-\\Delta_i}{\\sqrt{\\sigma_i^2+\\tau^2}}\\right)}{\\int_{-\\infty}^{\\infty} \\mathrm{w}\\left(p_i\\right) \\phi\\left(\\frac{Y_i-\\Delta_i}{\\sqrt{\\sigma_i^2+\\tau^2}}\\right)d y_i}\n\\]\nEssentially, this new model take into account the selection process (the weight function) to estimate a new meta-analysis. In case of no selection (all weigths are the same) the model is the standard random-effects meta-analysis."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function",
    "title": "Publication Bias",
    "section": "SM - Weigth function",
    "text": "SM - Weigth function\nThe weigth function is a simple function that links the p-value with the probability of publishing. The simple example at the beginning (publishing only significant p-values) is a step weigth function.\n\np &lt;- c(0, 0.05, 0.05, 1)\nw &lt;- c(1, 1, 0, 0)\n\nplot(p, w, type = \"l\", xlab = \"p value\", ylab = \"Probability of Publishing\")"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function-1",
    "title": "Publication Bias",
    "section": "SM - Weigth function",
    "text": "SM - Weigth function\nWe can add more steps to express a more complex selection process:\n\np &lt;- c(0.001, 0.01, 0.05, 0.1, 0.8, 1)\nw &lt;- c(1, 1, 0.9, 0.5, 0.1, 0.1)\nplot(p, w, type = \"s\", xlab = \"p value\", ylab = \"Probability of Publishing\")"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function-2",
    "title": "Publication Bias",
    "section": "SM - Weigth function",
    "text": "SM - Weigth function\nOr we can draw a smooth function assuming certain parameters:\n\nwbeta &lt;- function(p, a = 1, b = 1) p^(a - 1) * (1 - p)^(b - 1)\npval &lt;- seq(0, 1, 0.01)\n\nplot(pval, wbeta(pval, 1, 1), type = \"l\", ylim = c(0, 1), col = 1, lwd = 2,\n     xlab = \"p value\", ylab = \"Probability of Publishing\")\nlines(pval, wbeta(pval, 1, 2), col = 2, lwd = 2)\nlines(pval, wbeta(pval, 1, 5), col = 3, lwd = 2)\nlines(pval, wbeta(pval, 1, 50), col = 4, lwd = 2)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function-3",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-function-3",
    "title": "Publication Bias",
    "section": "SM - Weigth function",
    "text": "SM - Weigth function\nWhatever the function, the SM estimate the parameters of the function and the meta-analysis parameters taking into account the weigths.\nClearly, in the presence of no bias the two models (with and without weights) are the same while with PB the estimation is different, probably reducing the effect size.\nIf the SM is correct (not possible in reality), the SM estimate the true effect even in the presence of bias. This is the strenght and elegance of the SM."
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-functions",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---weigth-functions",
    "title": "Publication Bias",
    "section": "SM - Weigth functions",
    "text": "SM - Weigth functions\nThere are several weight functions:\n\nthe step model\nthe negative-exponential model\nthe beta model\n…\n\nFor an overview see the metafor documentation https://wviechtb.github.io/metafor/reference/selmodel.html"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---step-model",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---step-model",
    "title": "Publication Bias",
    "section": "SM - Step model",
    "text": "SM - Step model\nThe step model approximate the selection process with thresholds \\(\\alpha\\) and the associated weight \\(w(p_i)\\). For example:\n\nsteps &lt;- c(0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50, 0.65, 0.75, 0.90, 0.95, 0.99, 0.995, 1)\nmoderate_pb &lt;- c(1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 0.55, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50)\nsevere_pb &lt;- c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35, 0.30, 0.25, 0.10, 0.10, 0.10, 0.10)\n\npar(mfrow = c(1, 2))\nplot(steps, moderate_pb, type = \"s\", xlab = \"p value\", ylab = \"Probability of Selection\", main = \"Moderate PB\", ylim = c(0, 1))\nabline(v = steps, col = \"grey\")\nplot(steps, severe_pb, type = \"s\", xlab = \"p value\", ylab = \"Probability of Selection\", main = \"Severe PB\", ylim = c(0, 1))\nabline(v = steps, col = \"grey\")"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---negative-exponential",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#sm---negative-exponential",
    "title": "Publication Bias",
    "section": "SM - Negative-Exponential",
    "text": "SM - Negative-Exponential\nThe Negative-Exponential model is very simple and intuitive. The weight function is \\(e^{-\\delta p_i}\\) thus the single parameter \\(\\delta\\) is the amount of bias. When \\(\\delta = 0\\) there is no bias.\n\nwnegexp &lt;- function(p, delta){\n  exp((-delta)*p)\n}\n\n\ncurve(wnegexp(x, 0), ylim = c(0, 1), col = 1, lwd = 2, xlab = \"p value\", ylab = \"Probability of Selection\")\ncurve(wnegexp(x, 1), add = TRUE, col = 2, lwd = 2)\ncurve(wnegexp(x, 5), add = TRUE, col = 3, lwd = 2)\ncurve(wnegexp(x, 30), add = TRUE, col = 4, lwd = 2)\n\nlegend(\"topright\", legend = latex2exp::TeX(sprintf(\"$\\\\delta = %s$\", c(1, 2, 3, 4))), fill = 1:4)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb",
    "title": "Publication Bias",
    "section": "Simulating data with PB",
    "text": "Simulating data with PB\nThe strategy to simulate biased data is to sample from the sim_studies() function but to keep the studies using a probabilistic sampling based on the weight function.\n\nset.seed(2024)\n\nk &lt;- 500 # high number to check the results\nes &lt;- 0 # H0 true\ntau2 &lt;- 0.1\ndelta &lt;- 5\ndat &lt;- vector(mode = \"list\", k)\n\ni &lt;- 1\nwhile(i &lt;= k){\n  # generate data\n  n &lt;- runif(1, 10, 100)\n  d &lt;- summary(sim_studies(1, es, tau2, n))\n  # get one-tail p-value\n  pi &lt;- 1 - pnorm(d$zi)\n  # get wi\n  wpi &lt;- wnegexp(pi, delta)\n  keep &lt;- rbinom(1, 1, wpi) == 1\n  if(keep){\n    dat[[i]] &lt;- d\n    i &lt;- i + 1\n  }\n}\n\ndat &lt;- do.call(rbind, dat)\nfit &lt;- rma(yi, vi, data = dat)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-1",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-1",
    "title": "Publication Bias",
    "section": "Simulating data with PB",
    "text": "Simulating data with PB\nLet’s see some plots:\n\n\nCode\npar(mfrow = c(1, 3))\nhist(dat$yi, breaks = 50, col = \"dodgerblue\")\nhist(1 - pnorm(dat$zi), breaks = 50, col = \"dodgerblue\")\nplot(dat$yi, dat$sei, ylim = c(rev(range(dat$sei)[2]), 0), xlim = c(-1, 2))"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-2",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-2",
    "title": "Publication Bias",
    "section": "Simulating data with PB",
    "text": "Simulating data with PB\nLet’s see the model result:\n\nfit &lt;- rma(yi, vi, data = dat)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-3",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-3",
    "title": "Publication Bias",
    "section": "Simulating data with PB",
    "text": "Simulating data with PB\nLet’s see the Egger regression test and the trim-and-fill procedure:\n\nregtest(fit)\n#&gt; \n#&gt; Regression Test for Funnel Plot Asymmetry\n#&gt; \n#&gt; Model:     mixed-effects meta-regression model\n#&gt; Predictor: standard error\n#&gt; \n#&gt; Test for Funnel Plot Asymmetry: z = 4.4739, p &lt; .0001\n#&gt; Limit Estimate (as sei -&gt; 0):   b = 0.2017 (CI: 0.1235, 0.2799)\ntrimfill(fit)\n#&gt; \n#&gt; Estimated number of missing studies on the left side: 106 (SE = 14.6182)\n#&gt; \n#&gt; Random-Effects Model (k = 606; tau^2 estimator: REML)\n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.0474 (SE = 0.0049)\n#&gt; tau (square root of estimated tau^2 value):      0.2176\n#&gt; I^2 (total heterogeneity / total variability):   56.94%\n#&gt; H^2 (total variability / sampling variability):  2.32\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; Q(df = 605) = 1399.3991, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se     zval    pval   ci.lb   ci.ub      \n#&gt;   0.2927  0.0121  24.1497  &lt;.0001  0.2689  0.3164  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-4",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-4",
    "title": "Publication Bias",
    "section": "Simulating data with PB",
    "text": "Simulating data with PB\nThe two methods are detecting the PB but not correcting it appropriately. Let’s see the SM using a negexp method:\n\nsel &lt;- selmodel(fit, type = \"negexp\", alternative = \"greater\")\nsel\n#&gt; \n#&gt; Random-Effects Model (k = 500; tau^2 estimator: ML)\n#&gt; \n#&gt; tau^2 (estimated amount of total heterogeneity): 0.0800 (SE = 0.0118)\n#&gt; tau (square root of estimated tau^2 value):      0.2828\n#&gt; \n#&gt; Test for Heterogeneity:\n#&gt; LRT(df = 1) = 115.9867, p-val &lt; .0001\n#&gt; \n#&gt; Model Results:\n#&gt; \n#&gt; estimate      se    zval    pval    ci.lb   ci.ub    \n#&gt;   0.0519  0.0381  1.3609  0.1735  -0.0228  0.1266    \n#&gt; \n#&gt; Test for Selection Model Parameters:\n#&gt; LRT(df = 1) = 46.6783, p-val &lt; .0001\n#&gt; \n#&gt; Selection Model Results:\n#&gt; \n#&gt; estimate      se     zval    pval   ci.lb   ci.ub      \n#&gt;   4.7526  0.3818  12.4494  &lt;.0001  4.0044  5.5008  *** \n#&gt; \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-5",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#simulating-data-with-pb-5",
    "title": "Publication Bias",
    "section": "Simulating data with PB",
    "text": "Simulating data with PB\nWe can also plot the results:\n\nplot(sel)"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-sensitivity-analysis",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#pb-sensitivity-analysis",
    "title": "Publication Bias",
    "section": "PB Sensitivity analysis",
    "text": "PB Sensitivity analysis\n\nThe SM is correctly detecting, estimating and correcting the PB. But we simulated a pretty strong bias with \\(k = 500\\) studies. In reality meta-analyses have few studies.\nVevea and Woods (2005) proposed to fix the weight function parameters to certain values representing different degree of selection and check how the model changes.\nIf the model parameters are affected after taking into account the SM, this could be considered as an index of PB.\nThis approach is really interesting in general but especially when \\(k\\) is too small for estimating the SM\nsee ?selmodel for information about performing sensitivity analysis with pre-specified weight functions"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#more-on-sm-and-publication-bias",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#more-on-sm-and-publication-bias",
    "title": "Publication Bias",
    "section": "More on SM and Publication Bias",
    "text": "More on SM and Publication Bias\n\nThe SM documentation of metafor::selmodel() https://wviechtb.github.io/metafor/reference/selmodel.html\nWolfgang Viechtbauer overview of PB https://www.youtube.com/watch?v=ucmOCuyCk-c\nHarrer et al. (2021) - Doing Meta-analysis in R - Chapter 9\nMcShane, Böckenholt, and Hansen (2016) for a nice introduction about publication bias and SM\nAnother good overview by Jin, Zhou, and He (2015)\nSee also Guan and Vandekerckhove (2016), Maier, Bartoš, and Wagenmakers (2023) and Bartoš et al. (2022) for Bayesian approaches to PB"
  },
  {
    "objectID": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#references",
    "href": "slides/06-meta-analysis/05-publication-bias/publication-bias.html#references",
    "title": "Publication Bias",
    "section": "References",
    "text": "References\n\n\nBartoš, František, Maximilian Maier, Daniel S Quintana, and Eric-Jan Wagenmakers. 2022. “Adjusting for Publication Bias in JASP and r: Selection Models, PET-PEESE, and Robust Bayesian Meta-Analysis.” Advances in Methods and Practices in Psychological Science 5 (July): 251524592211092. https://doi.org/10.1177/25152459221109259.\n\n\nCitkowicz, Martyna, and Jack L Vevea. 2017. “A Parsimonious Weight Function for Modeling Publication Bias.” Psychological Methods 22 (March): 28–41. https://doi.org/10.1037/met0000119.\n\n\nDuval, S, and R Tweedie. 2000. “Trim and Fill: A Simple Funnel-Plot-Based Method of Testing and Adjusting for Publication Bias in Meta-Analysis.” Biometrics 56 (June): 455–63. https://doi.org/10.1111/j.0006-341x.2000.00455.x.\n\n\nGuan, Maime, and Joachim Vandekerckhove. 2016. “A Bayesian Approach to Mitigation of Publication Bias.” Psychonomic Bulletin & Review 23 (February): 74–86. https://doi.org/10.3758/s13423-015-0868-6.\n\n\nHarrer, Mathias, Pim Cuijpers, Toshi Furukawa, and David Ebert. 2021. Doing Meta-Analysis with r: A Hands-on Guide. 1st ed. London, England: CRC Press.\n\n\nJin, Zhi-Chao, Xiao-Hua Zhou, and Jia He. 2015. “Statistical Methods for Dealing with Publication Bias in Meta-Analysis.” Statistics in Medicine 34 (January): 343–60. https://doi.org/10.1002/sim.6342.\n\n\nMaier, Maximilian, František Bartoš, and Eric-Jan Wagenmakers. 2023. “Robust Bayesian Meta-Analysis: Addressing Publication Bias with Model-Averaging.” Psychological Methods 28 (February): 107–22. https://doi.org/10.1037/met0000405.\n\n\nMcShane, Blakeley B, Ulf Böckenholt, and Karsten T Hansen. 2016. “Adjusting for Publication Bias in Meta-Analysis: An Evaluation of Selection Methods and Some Cautionary Notes: An Evaluation of Selection Methods and Some Cautionary Notes.” Perspectives on Psychological Science: A Journal of the Association for Psychological Science 11 (September): 730–49. https://doi.org/10.1177/1745691616662243.\n\n\nOrwin, Robert G. 1983. “A Fail-SafeN for Effect Size in Meta-Analysis.” Journal of Educational Statistics 8 (June): 157–59. https://doi.org/10.3102/10769986008002157.\n\n\nRosenberg, Michael S. 2005. “The File-Drawer Problem Revisited: A General Weighted Method for Calculating Fail-Safe Numbers in Meta-Analysis.” Evolution; International Journal of Organic Evolution 59 (February): 464–68. https://doi.org/10.1111/j.0014-3820.2005.tb01004.x.\n\n\nRosenthal, Robert. 1979. “The File Drawer Problem and Tolerance for Null Results.” Psychological Bulletin 86 (May): 638–41. https://doi.org/10.1037/0033-2909.86.3.638.\n\n\nShi, Linyu, and Lifeng Lin. 2019. “The Trim-and-Fill Method for Publication Bias: Practical Guidelines and Recommendations Based on a Large Database of Meta-Analyses: Practical Guidelines and Recommendations Based on a Large Database of Meta-Analyses.” Medicine 98 (June): e15987. https://doi.org/10.1097/MD.0000000000015987.\n\n\nVevea, Jack L, and Carol M Woods. 2005. “Publication Bias in Research Synthesis: Sensitivity Analysis Using a Priori Weight Functions.” Psychological Methods 10 (December): 428–43. https://doi.org/10.1037/1082-989X.10.4.428."
  },
  {
    "objectID": "teamworks.html",
    "href": "teamworks.html",
    "title": "Psychometrics4Neuroscience",
    "section": "",
    "text": "Per la suddivisione nei diversi gruppi potete completare questo documento.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\n\n\n\n\nLavoro di Gruppo 1 - Simulazione Monte Carlo\n\n\n\n\nLavoro di Gruppo 2 - Analisi di dati ERP\n\n\n\n\nLavoro di Gruppo 3 - Metanalisi\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teamworks/02-erp-analysis/02-erp-analysis.html",
    "href": "teamworks/02-erp-analysis/02-erp-analysis.html",
    "title": "Lavoro di Gruppo 2 - Analisi di dati ERP",
    "section": "",
    "text": "Dataset\nQuesto lavoro di gruppo richiede di effettuare l’analisi di un dataset ERP.\nIl dataset è parte di ERPcore, e consiste in un esperimento con 40 partecipanti esposti alla visione passiva di quattro tipologie di stimoli:\n\n\nVolti\nVolti scrambled\nAutomobili\nAutomobili scrambled\n\nQuesto tipo di paradigma è tipicamente usato per studiare i processi corticali sottostanti l’elaborazione di volti, e si associano ad uno specifico potenziale evento-relato, la N170.\nI dati sono quelli già usati nelle esercitazioni sulla visualizzazione di dati ERP, quindi sono già preprocessati e privi di artefatti. In alternativa potete nuovamente effettuare il download a questo link.\n\n\nStep da eseguire per lo svolgimento del progetto\n\nImportare i dati in un unico dataframe in R\nEseguire l’esplorazione del dataset rispetto alla differenza tra facce e facce scrambled su tutti gli elettrodi\n2a. Creare una rappresentazione grafica delle waveform delle due condizioni sperimentali per tutti gli elettrodi 2b. Riportare le statistiche descrittive per le due condizioni sperimentali nella finestra 150-190 ms (per tutti gli elettrodi)\nEseguire l’analisi statistica con un mixed-effects model per spiegare la differenza tra facce e facce scrambled nella finestra 150-190 ms in quattro cluster di elettrodi: Cluster Anteriore Destro (F4,FC4, F8), Cluster Anteriore Sinistro (F3, FC3, F7), Cluster Posteriore Destro (PO8, P8, PO4), Cluster Posteriore Sinistro (PO7, P7, PO3)\nEseguire l’analisi statistica con l’approccio mass univariate con la gestione dei confronti multipli attraverso l’approccio cluster-mass permutation per spiegare la differenza tra facce e facce scrambled usando tutti gli elettrodi e tutti i time points a disposizione.\nCommentare i risultati di entrambi i metodi, evidenziando pro e contro di ognuno\n\n\n\nAspetti generali\n\nOgni step deve essere accompagnato da una spiegazione narrativa e dove pertinente da rappresentazioni grafiche e tabelle che spieghino in maniera chiara i risultati\nTutti gli step devono essere prodotti in un documento Quarto (html o pdf) riproducibile e self-contained\nChi vuole può preparare una presentazione in Quarto da utilizzare durante l’esame"
  }
]