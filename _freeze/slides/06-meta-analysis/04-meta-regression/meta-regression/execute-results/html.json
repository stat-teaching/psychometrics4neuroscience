{
  "hash": "ef5798a7f897910053f301f86d153654",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meta-regression\"\nexecute: \n  echo: true\nknitr:\n  opts_chunk: \n    collapse: true\n    comment: \"#>\"\n---\n\n\n\n\n\n\n\n\n# Meta-analysis as (weighted) linear regression {.section}\n\n## MA as (weighted) linear regression\n\nBoth the EE and RE model can be seen as standard (weighted) linear regression models. Precisely, there is a difference in fitting a meta-analysis using `lm` or `lme4::lmer()` and `rma` (see [https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer](https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer)).\n\n. . .\n\nBeyond these differences a general the EE and RE models are intercept-only linear regressions.\n\n$$\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n$$\n\nThe EE model:\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nThe RE model:\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\epsilon_i \n$$\n\n## MA as (weighted) linear regression\n\nIn the EE model $\\beta_0$ is $\\theta$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)$\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nIn the RE model $\\beta_0$ is $\\mu_{\\theta}$ and $\\beta_{0_i}$ are the $\\delta_i$.\n\n## Explaining $\\tau^2$\n\nSo far we simply assumed $\\tau^2 = 0$ (for the EE model) or estimated it using the RE model.\n\n. . .\n\nWe can extend the intercept-only meta-analysis by including study-level predictors (as in standard linear regression) to explain the estimated true heterogeneity.\n\n## Explaining $\\tau^2$\n\nLet's make an example where we simulate a meta-analysis with $k = 100$ studies. Beyond the effect size, we extracted an experimental condition where 50 studies where lab-based experiments $x_{lab}$ and 50 studies where online experiments.\n\nWe assume that there could be a **lab effect** thus we included a predictor in the model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 100\nn <- 10 + rpois(k, 40 - 10)\nexp <- rep(c(\"lab\", \"online\"), each = k/2)\n```\n:::\n\n\n\n\n## Explaining $\\tau^2$\n\nNow the model have a predictor $x$ (the type of experiment) and two parameters $\\beta_0$ and $\\beta_1$. Depending on the contrast coding (default to `contr.treatment()` in R) the $\\beta_0$ is different. Coding `exp` as 0 for lab-based experiments and 1 for online experiments:\n\n$$\ny_i = \\beta_0 + \\beta_1X_{1_i} + \\epsilon_i\n$$\n\n$$\ny_{\\text{lab}_i} = \\beta_0 + \\epsilon_i\n$$\n\n$$\ny_{\\text{online}_i} = \\beta_0 + \\beta_1 + \\epsilon_i\n$$\n\n## Explaining $\\tau^2$\n\nWhat is missing is the random-effect. Basically we still have $\\tau^2$ determining the $\\delta_i \\sim \\mathcal{N}(0, \\tau^2)$ but now is the residual $\\tau^2_r$. The heterogeneity after including the predictor.\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\beta_1X_{1_i} + \\epsilon_i\n$$ {#eq-metareg-cat}\n\n$$\n\\beta_{0_i} \\sim \\mathcal{N}(0, \\tau^2_r)\n$$\n\nClearly the difference between $\\tau^2$ (the total heterogeneity) and $\\tau^2_r$ (residual heterogeneity) is an index of the impact of $X$.\n\n## Simulating the $X$ effect\n\nTo simulate a meta-regression we just need to choose the parameters values ($\\beta_0$ and $\\beta_1$) and implement @eq-metareg-cat. Using treatment coding, $\\beta_0$ is the effect size when $X = 0$ (i.e., lab-based experiments) and $\\beta_1$ is the difference between lab and online experiments.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb0 <- 0.3 # lab-based effect size\nb1 <- 0.5 # online - lab-based --> online = b0 + b1\nexp_dummy <- ifelse(exp == \"lab\", 0, 1) # dummy version\nes <- b0 + b1 * exp_dummy\nht(data.frame(exp, exp_dummy, es))\n#>        exp exp_dummy  es\n#> 1      lab         0 0.3\n#> 2      lab         0 0.3\n#> 3      lab         0 0.3\n#> 4      lab         0 0.3\n#> 5      lab         0 0.3\n#> 95  online         1 0.8\n#> 96  online         1 0.8\n#> 97  online         1 0.8\n#> 98  online         1 0.8\n#> 99  online         1 0.8\n#> 100 online         1 0.8\n```\n:::\n\n\n\n\n## Simulating the $X$ effects\n\nNow we can use the `sim_studies()` function as usual. The difference is that `es` is no longer a single value but a vector (with different values according to the $X$ level) and `tau2` is $\\tau^2_r$ (this the leftover heterogeneity after including the $X$ effect)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntau2r <- 0.05 # residual heterogeneity\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(exp = exp))\nht(dat)\n#> \n#>      id      yi     vi n1 n2    exp \n#> 1     1  0.4809 0.0504 36 36    lab \n#> 2     2  0.2216 0.0385 46 46    lab \n#> 3     3  0.6249 0.0733 29 29    lab \n#> 4     4  0.3596 0.0484 36 36    lab \n#> 5     5 -0.3642 0.0353 60 60    lab \n#> 95   95  0.2620 0.0439 41 41 online \n#> 96   96  0.7063 0.0661 35 35 online \n#> 97   97  0.2812 0.0549 36 36 online \n#> 98   98  0.7043 0.0537 41 41 online \n#> 99   99  0.6778 0.0582 37 37 online \n#> 100 100  0.6097 0.0550 35 35 online\n```\n:::\n\n\n\n\n## Fitting a meta-regression Model\n\nTo fit a meta-regression we still use the `metafor::rma()` function, adding the `mods = ~` parameter with the model formula (same as the right-hand side of a `y ~ x` call in `lm`). The name of the predictor in the formula need to match a column of the `data = ` dataframe.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- rma(yi, vi, mods = ~ exp, data = dat, method = \"REML\")\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#>   logLik  deviance       AIC       BIC      AICc   \n#> -20.2793   40.5587   46.5587   54.3136   46.8140   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0369 (SE = 0.0126)\n#> tau (square root of estimated tau^2 value):             0.1922\n#> I^2 (residual heterogeneity / unaccounted variability): 41.96%\n#> H^2 (unaccounted variability / sampling variability):   1.72\n#> R^2 (amount of heterogeneity accounted for):            66.76%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 168.1380, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 84.6513, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.2357  0.0420  5.6173  <.0001  0.1535  0.3180  *** \n#> exponline    0.5488  0.0596  9.2006  <.0001  0.4319  0.6657  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n\n\n## Intepreting a meta-regression Model\n\nThe output is similar to the RE model with few additions:\n\n- Everything related to the heterogeneity ($H^2$, $I^2$, $Q$, etc.) is now about **residual heterogeneity**\n- There is the (pseudo) $R^2$\n- There is an overall test for the moderators $Q_M$\n- There is a section (similar to standard regression models) with the estimated parameters, standard error and Wald test\n\n## Model parameters\n\n`intrcpt` and `exponline` are the estimates of $\\beta_0$ and $\\beta_1$. The interpretation depends on the scale of the effect size and the contrast coding.\n\nWe can plot the model results using the `metafor::regplot()`^[The functions is made for numerical variables thus is less appropriate for categorical variables].\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregplot(fit)\n```\n\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n\n## Omnibus Moderator Test\n\nThe `Test of Moderators` section report the so-called omnibus test for model coeffiecients. Is a simultaneous test for 1 or more coefficients where $H_0: \\beta_j = 0$.\n\nIn this case, **coefficient 2** means that we are testing only the 2nd coefficient $\\beta_1$. By default, the intercept is ignored. In fact, the `exponline` line and the omnibus test are the same (the $\\chi^2$ is just the $z^2$)\n\n\n\n\n::: {.cell}\n\n```\n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 84.6513, p-val < .0001\n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.2357  0.0420  5.6173  <.0001  0.1535  0.3180  *** \n#> exponline    0.5488  0.0596  9.2006  <.0001  0.4319  0.6657  ***\n```\n:::\n\n\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can also test any combination of parameters. For example we could test if lab-based experiments and online experiments are both different from 0. This is the same as fitting a model without the intercept^[see [https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept](https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept) on removing the intercept] thus estimating the cell means [see @Schad2020-ht].\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# now we are testing two coefficients\nfit_no_int <- rma(yi, vi, mods = ~ 0 + exp, data = dat)\n```\n:::\n\n\n\n\n## General Linear Hypotheses Testing (GLHT)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_no_int\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0369 (SE = 0.0126)\n#> tau (square root of estimated tau^2 value):             0.1922\n#> I^2 (residual heterogeneity / unaccounted variability): 41.96%\n#> H^2 (unaccounted variability / sampling variability):   1.72\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 168.1380, p-val < .0001\n#> \n#> Test of Moderators (coefficients 1:2):\n#> QM(df = 2) = 374.2227, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se     zval    pval   ci.lb   ci.ub      \n#> explab       0.2357  0.0420   5.6173  <.0001  0.1535  0.3180  *** \n#> exponline    0.7845  0.0424  18.5113  <.0001  0.7014  0.8676  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nA more elegant way is by using the GLHT framework. Basically we provide a contrast matrix expressing linear combinations of model parameters to be tested. In our case $\\text{lab} = \\beta_0 = 0$ and $\\text{online} = \\beta_0 + \\beta_1 = 0$.\n\nPractically, the matrix formulation is the following:\n\n$$\n\\begin{pmatrix}  \n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}  \n\\beta_0\\\\\n\\beta_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}  \n0\\\\\n0\n\\end{pmatrix}\n$$\n\nIn R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nC <- rbind(c(1, 0), c(1, 1))\nB <- coef(fit)\nC %*% B # same as coef(fit)[1] and coef(fit)[1] +  coef(fit)[2]\n#>           [,1]\n#> [1,] 0.2357498\n#> [2,] 0.7845130\n```\n:::\n\n\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can use the `anova()` function providing the model and the hypothesis matrix.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fit) # the default\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 84.6513, p-val < .0001\nanova(fit, X = C)\n#> \n#> Hypotheses:                           \n#> 1:             intrcpt = 0 \n#> 2: intrcpt + exponline = 0 \n#> \n#> Results:\n#>    estimate     se    zval   pval     \n#> 1:   0.2357 0.0420  5.6173 <.0001 *** \n#> 2:   0.7845 0.0424 18.5113 <.0001 *** \n#> \n#> Omnibus Test of Hypotheses:\n#> QM(df = 2) = 374.2227, p-val < .0001\n```\n:::\n\n\n\n\nNotice that is the same as the model without the intercept.\n\n## Likelihood Ratio Test (LRT)\n\nAs in standard regression modelling, we can also compare models using LRT. The `anova()` function will compute the LRT when two (nested) models are provided. In this case we compared a null (intercept-only) model with the model including the predictor.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the null model\nfit0 <- rma(yi, vi, data = dat, method = \"REML\")\nanova(fit0, fit, refit = TRUE) # refit = TRUE because LRT with REML is not meaningful, using ML instead\n#> \n#>         df      AIC      BIC     AICc   logLik     LRT   pval       QE  tau^2 \n#> Full     3  45.3744  53.1899  45.6244 -19.6872                168.1380 0.0352 \n#> Reduced  2 105.8863 111.0966 106.0100 -50.9431 62.5118 <.0001 314.8233 0.1095 \n#>              R^2 \n#> Full             \n#> Reduced 67.8604%\n```\n:::\n\n\n\n\n## $R^2$\n\nThe $R^2$ value reported in the model output is not calculated as in standard regression analysis.\n\n$$\nR^2 = 1 - \\frac{\\tau^2_r}{\\tau^2}\n$$\n\nBasically is the percentage of heterogeneity reduction from the intercept-only model to the model including predictors.\n\nIn R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(1 - fit$tau2/fit0$tau2)*100\n#> [1] 66.76063\nfit$R2\n#> [1] 66.76063\n```\n:::\n\n\n\n\n## $R^2$\n\nDespite useful, the $R^2$ has some limitations:\n\n- @Lopez-Lopez2014-it showed that precise estimations require a large number of studies $k$ \n- Sometimes could results in negative values (usually truncated to zero)\n- Depends on the $\\tau^2$ estimator\n\nMore about $R^2$ and limitations can be found:\n\n- [https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i](https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i)\n- [https://www.metafor-project.org/doku.php/tips:ci_for_r2](https://www.metafor-project.org/doku.php/tips:ci_for_r2)\n\n## Numerical predictor\n\nThe same logic of simulating a meta-regression can be applied to numerical predictors. We still have $\\beta_0$ and $\\beta_1$ but $X$ has more levels. Let's simulate an impact of the average participants' age on the effect size.\n\n- $\\beta_0$ is the effect size when **age** is zero\n- $\\beta_1$ is the expected increase in the effect size for a unit increase in `age`\n\nHow we can choose plausible values for the parameters and parametrize the model correctly?\n\n## Parametrize $\\beta_0$\n\nThe intepretation (and the inference) of $\\beta_0$ is strongly dependent on the type of numerical predictor. An age of zero is (probably) empirically meaningless thus the  $\\beta_0$ is somehow not useful.\n\nWe can for example mean-center (or other type of centering procedure) moving the zero on a meaningful value.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nage <- 10:50 # the raw vector\nage0 <- age - mean(age) # centering on the mean\nage20 <- age - min(age) # centering on the minimum\n\nht(data.frame(age, age0, age20))\n#>    age age0 age20\n#> 1   10  -20     0\n#> 2   11  -19     1\n#> 3   12  -18     2\n#> 4   13  -17     3\n#> 5   14  -16     4\n#> 36  45   15    35\n#> 37  46   16    36\n#> 38  47   17    37\n#> 39  48   18    38\n#> 40  49   19    39\n#> 41  50   20    40\n```\n:::\n\n\n\n\n## Parametrize $\\beta_0$\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n\n## Parametrize $\\beta_0$\n\nUsing different parametrizations will only affect the estimation (and the interpretation) of $\\beta_0$. Other parameters and indexes will be the same.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 100\nb0 <- 0.2 # effect size when age 0\nb1 <- 0.05 # slope (random for now)\nage <- round(runif(k, 20, 50)) # sampling from uniform distribution\ntau2r <- 0.05\nn <- 10 + rpois(k, 30 - 10)\n\nes <- b0 + b1 * age # raw\n\nage0 <- age - mean(age)\nage20 <- age - 20\n\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(age = age, age0 = age0, age20 = age20))\n\nfit <- rma(yi, vi, mods = ~ age, data = dat)\nfit0 <- rma(yi, vi, mods = ~ age0, data = dat)\nfit20 <- rma(yi, vi, mods = ~ age20, data = dat)\n\n# showing the intercept\ncompare_rma(fit, fit0, fit20, extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>                fit   fit0  fit20\n#> b (intrcpt)  0.155  1.963  1.190\n#> se           0.164  0.039  0.078\n#> zval         0.947 50.555 15.241\n#> pval         0.344  0.000  0.000\n#> ci.lb       -0.166  1.887  1.037\n#> ci.ub        0.476  2.040  1.342\n#> R2          68.810 68.810 68.810\n#> I2          58.854 58.854 58.854\n#> tau2         0.087  0.087  0.087\n\n  # showing the intercept\ncompare_rma(fit, fit0, fit20, b = \"age\", extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>            fit   fit0  fit20\n#> b (age)  0.052  0.052  0.052\n#> se       0.005  0.005  0.005\n#> zval    11.340 11.340 11.340\n#> pval     0.000  0.000  0.000\n#> ci.lb    0.043  0.043  0.043\n#> ci.ub    0.061  0.061  0.061\n#> R2      68.810 68.810 68.810\n#> I2      58.854 58.854 58.854\n#> tau2     0.087  0.087  0.087\n```\n:::\n\n\n\n\n## Choosing $\\beta_1$\n\nThe core of the model is $\\beta_1$ that is the **age** effect. Compared to the categorical case where $\\beta_1$ is just the standardized difference between two conditions, with numerical $X$ choosing a meaningful $\\beta_1$ is more challenging.\n\nTwo (maybe more) strategies:\n\n- simulating a lot of effects sizes fixing $beta_0$ and $\\beta_1$ and see the expected range of $y_i$\n- fixing a certain $R^2$ and choose the $\\beta_1$ producing that $R^2$\n- ...\n\n## $\\beta_1$ by simulations\n\nA strategy could be to simulate from the generative model a large number of studies and see the expected range of effect size [@Gelman2020-tg, Chapter 5 and p. 97]. A large number of unplausible values suggest that the chosen $\\beta_1$ is probably not appropriate.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 1e3\nn <- 30\ntau2 <- 0\nx <- runif(k, 20, 50) # age\nb0 <- 0.1\nb1 <- c(0.001, 0.05, 0.2)\nesl <- lapply(b1, function(b) b0 + b*x)\ndatl <- lapply(esl, function(es) sim_studies(k = k, es = es, tau2 = tau2, n1 = n, add = list(x = x)))\nnames(datl) <- b1\ndat <- dplyr::bind_rows(datl, .id = \"b1\")\nht(dat)\n#> \n#>         b1   id     yi     vi n1 n2        x \n#> 1    0.001    1 0.0249 0.0743 30 30 39.41982 \n#> 2    0.001    2 0.3599 0.0850 30 30 24.53982 \n#> 3    0.001    3 0.1112 0.0552 30 30 47.02552 \n#> 4    0.001    4 0.3305 0.0705 30 30 42.67976 \n#> 5    0.001    5 0.0313 0.0537 30 30 37.48619 \n#> 2995   0.2  995 9.5151 0.0613 30 30 47.89667 \n#> 2996   0.2  996 4.9303 0.0749 30 30 23.45822 \n#> 2997   0.2  997 9.4805 0.0696 30 30 45.64827 \n#> 2998   0.2  998 7.3192 0.0603 30 30 36.08561 \n#> 2999   0.2  999 5.0941 0.0863 30 30 24.74852 \n#> 3000   0.2 1000 5.8356 0.0882 30 30 28.56949\n```\n:::\n\n\n\n\n## $\\beta_1$ by simulations\n\nClearly given the limited range of the $x$ variable (`age`) some $\\beta_1$ values are implausible leading to effect sizes that are out of a meaningful empirical range.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndat$b1 <- factor(dat$b1, labels = latex2exp::TeX(sprintf(\"$\\\\beta_1 = %s$\", unique(dat$b1))))\ndat |> \n  ggplot(aes(x = x, y = yi)) +\n  geom_point() +\n  facet_wrap(~b1, scales = \"free_y\", labeller = label_parsed) +\n  xlab(\"Age\") +\n  ylab(latex2exp::TeX(\"$y_i$\"))\n```\n\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n\n\n## Fixing $R^2$\n\nWe can use the approach by @Lopez-Lopez2014-it where predictors $x$ are sampled from a standard normal distribution (or standardized). $\\beta_1$ is calculated as $\\beta_1 = \\sqrt{\\tau^2 R^2}$ and the residual heterogeneity as $\\tau^2_r = \\tau^2 - \\beta^2_1$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 100\nn <- 30\ntau2 <- 0.3\nR2 <- 0.4\nb0 <- 0.1\nb1_2 <- tau2 * R2\nb1 <- sqrt(b1_2)\ntau2r <- tau2 - b1_2\n```\n:::\n\n\n\n\n## Fixing $R^2$\n\nWe can check the simulation approach:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 1e3\n1 - tau2r/tau2\n#> [1] 0.4\nx <- rnorm(k)\nes <- b0 + b1 * x\ndat <- sim_studies(k, es, tau2r, n1 = 1e3, add = list(x = x))\nfit <- rma(yi, vi, data = dat, mods = ~x)\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 1000; tau^2 estimator: REML)\n#> \n#>    logLik   deviance        AIC        BIC       AICc   \n#> -547.4249  1094.8498  1100.8498  1115.5671  1100.8740   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.1734 (SE = 0.0079)\n#> tau (square root of estimated tau^2 value):             0.4164\n#> I^2 (residual heterogeneity / unaccounted variability): 98.86%\n#> H^2 (unaccounted variability / sampling variability):   87.86\n#> R^2 (amount of heterogeneity accounted for):            41.74%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 998) = 87658.6376, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 708.4432, p-val < .0001\n#> \n#> Model Results:\n#> \n#>          estimate      se     zval    pval   ci.lb   ci.ub      \n#> intrcpt    0.1000  0.0133   7.5463  <.0001  0.0740  0.1260  *** \n#> x          0.3474  0.0131  26.6166  <.0001  0.3219  0.3730  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n\n\n## $R^2$ using simulations\n\nThe results from @Lopez-Lopez2014-it (and also our previous simulation) suggested that we need a large number of studies for precise $R^2$ estimations. Let's check using simulations the sampling distribution of $R^2$ using a plausible meta-analysis scenario.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 40 # number of studies\nn <- 10 + rpois(k, 40 - 10) # sample size\ntau2 <- 0.05 # tau ~ 0.22\nR2 <- 0.3\nb0 <- 0.1\nb1_2 <- tau2 * R2\nb1 <- sqrt(b1_2)\ntau2r <- tau2 - b1_2\nnsim <- 1e3\n\nR2i <- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  x <- rnorm(k)\n  dat <- sim_studies(k = k, es = b0 + b1*x, tau2 = tau2r, n1 = n, add = list(x))\n  fit <- rma(yi, vi, data = dat, mods = ~x)\n  R2i[i] <- fit$R2\n}\n```\n:::\n\n\n\n\n## $R^2$ using simulations\n\nWe estimated the true $R^2$ correctly but there is a lot of uncertainty with a plausible meta-analysis scenario. There are a lot of meta-analysis also with lower $k$ worsening the results.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\n\n## References\n\n::: {#refs}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}