{
  "hash": "347b3cd5a9dc78aca9967089c64b68fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 2025-05-09\n---\n\n\n\n\n# Esercizi\n\n## Meta-analisi\n\nDal pacchetto `psymetadata` provate a scegliere un dataset ed analizzarlo e applicare i modelli che abbiamo visto sia per stimare gli effetti che publication bias. Scegliete il dataset che volete, questi sono un paio di consigliati.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"psymetadata\")\n\nlibrary(psymetadata)\n\ndata(\"gnambs2020\")\ndata(\"spaniol2020\")\n```\n:::\n\n\n\n\n## Mixed-effects models\n\nIl dataset `data/rt.rds` contiene un esperimento di **tempi di reazione** (colonna `rt`). L'ipotesi principale è una differenza in funzione della congruenza dello stimolo (`congruence`). Scegliere il modello più adatto, intepretare gli effetti, etc.\n\n- c'è anche una colonna con la data dell'esperimento. Vedere se c'è un impatto nell'effetto e nei tempi di reazione in funzione al periodo della giornata (mattina < 12:00pm, pomeriggio 12-17, sera dopo le 17:00).\n- vedere relazione tra accuratezza (`correct`) e tempi di reazione\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- readRDS(here::here(\"data\", \"rt.rds\"))\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id          local_date congruence    rt correct trial_number\n1  1 16/06/2022 09:18:11          c 809.6       1            1\n2  1 16/06/2022 09:18:12          c 484.8       1            2\n3  1 16/06/2022 09:18:13          i 386.3       1            3\n4  1 16/06/2022 09:18:15          c 676.3       1            4\n5  1 16/06/2022 09:18:16          i 542.0       1            5\n6  1 16/06/2022 09:18:18          c 924.7       1            6\n```\n\n\n:::\n:::\n\n\n\n\nIl dataset lo potete trovare su Github o scaricarlo [qui](../data/rt.rds).\n\n## Permutazioni\n\nAbbiamo visto velocemente come implementare un test di permutazione per la differenza tra due gruppi.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 100\nx <- rep(0:1, each = N/2) # dummy\ny <- 0.5 * x + rnorm(N, 0, 1) # 0.5 effect size + random noise\n\nB <- 5000 # numero di permutazioni\n\ntp <- rep(NA, B) # preallochiamo il vettore\ntp[1] <- t.test(y ~ x)$statistic # prima permutazione i dati osservati\n\nfor(i in 2:B){\n    xp <- sample(x)\n    tp[i] <- t.test(y ~ xp)$statistic\n}\n\nhist(tp)\nabline(v = tp[1])\npoints(tp[1], 0, pch = 19, cex = 2, col = \"firebrick\")\n```\n\n::: {.cell-output-display}\n![](2025-05-09_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# p-value with permutations\nmean(abs(tp) >= abs(tp[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0512\n```\n\n\n:::\n:::\n\n\n\n\nPer un test ad un campione, è necessario permutare il segno:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- rnorm(N, 0.3, 1)\ntp <- rep(NA, B)\ntp[1] <- t.test(y, mu = 0)$statistic\n\nfor(i in 2:B){\n    s <- sample(c(-1, 1), N, replace = TRUE)\n    yp <- y * s\n    tp[i] <- t.test(yp, mu = 0)$statistic\n}\n\nhist(tp)\nabline(v = tp[1])\npoints(tp[1], 0, pch = 19, cex = 2, col = \"firebrick\")\n```\n\n::: {.cell-output-display}\n![](2025-05-09_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# p-value with permutations\nmean(abs(tp) >= abs(tp[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0268\n```\n\n\n:::\n:::\n",
    "supporting": [
      "2025-05-09_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}