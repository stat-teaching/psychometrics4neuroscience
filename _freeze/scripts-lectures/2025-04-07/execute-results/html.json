{
  "hash": "0a30c3c49df47f0b4140d67f1edbaa69",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"2025-04-07\"\nformat: html\n---\n\n\n\n## Topics\n\nFacciamo un'approfondimento su un'applicazione interessante del modello probit alle decisioni [signal detection theory](../materials/signal-detection-theory.qmd)\n\n## Assignment\n\nPer oggi facciamo una simulazione, descritta in questo [documento](2025-04-07_extra/2025-04-07_simulazione.qmd)\n\n## Simulazioni\n\nAbbiamo visto alcune strategie di simulazione, in particolare per calcolare la potenza statistica. Ad esempio nel caso di un t-test assumendo due popolazioni a varianza uguale ($\\sigma = 1$) e differenza tra le medie $d = 0.3$ abbiamo:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 30 # per gruppo\nd <- 0.3 # effect size\ns <- 1 # pooled standard deviation\ndf <- n * 2 - 2 # degrees of freedom\nalpha <- 0.05\n\nnu <- d * sqrt((n * n) / (n + n)) # observed t-value (or non-centrality parameter)\ntc <- qt(1 - alpha/2, df) # critical t-value\n\n1 - pt(tc, df, nu) + pt(-tc, df, nu) # potenza\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2078518\n```\n\n\n:::\n\n```{.r .cell-code}\npwr::pwr.t.test(n, d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 30\n              d = 0.3\n      sig.level = 0.05\n          power = 0.2078518\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\nIn alternativa usando le simulazioni:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnsim <- 1e3\np <- rep(NA, nsim)\n\nfor(i in 1:length(p)){\n    g0 <- rnorm(n, 0, 1)\n    g1 <- rnorm(n, d, 1)\n    p[i] <- t.test(g1, g0)$p.value\n}\n\nmean(p <= alpha)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.204\n```\n\n\n:::\n:::\n\n\n\nLo stesso lo possiamo vedere come modello lineare:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- n * 2\nb0 <- 0 # intercetta, media gruppo 0\nb1 <- d # slope, differenza tra i due gruppi\ns <- 1  # standard deviation residua\n\ndat <- data.frame(\n    x = rep(0:1, each = n)\n)\n\ndat$y <- rnorm(N, b0 + b1 * dat$x, s)\n\nfit <- lm(y ~ x, data = dat)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.15553 -0.49610  0.01076  0.63257  2.38245 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)  0.04311    0.17159   0.251    0.803\nx            0.25190    0.24266   1.038    0.304\n\nResidual standard error: 0.9398 on 58 degrees of freedom\nMultiple R-squared:  0.01824,\tAdjusted R-squared:  0.001314 \nF-statistic: 1.078 on 1 and 58 DF,  p-value: 0.3035\n```\n\n\n:::\n:::\n\n\n\nIn questo caso il parametro di effect size è:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb1 / s # differenza tra gruppi diviso per standard deviation residua\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(fit)[2] / sigma(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        x \n0.2680318 \n```\n\n\n:::\n\n```{.r .cell-code}\ndata.frame(effectsize::cohens_d(y ~ x, data = dat))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Cohens_d   CI     CI_low   CI_high\n1 -0.2680318 0.95 -0.7752847 0.2415063\n```\n\n\n:::\n:::\n\n\n\nOvviamente anche la potenza sarà lo stesso.\n\nNel caso di un disegno pre-post, le osservazioni dello stesso soggetto sono correlate. Per simulare dei dati correlati posso usare il pacchetto `MASS::mvrnorm()` oppure con la formula di un mixed-model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- 0.7\nR <- r + diag(1 - r, 2) # matrice di correlazione\nX <- MASS::mvrnorm(n, c(0, d), R)\napply(X, 2, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.006866262 0.238129522\n```\n\n\n:::\n\n```{.r .cell-code}\napply(X, 2, sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.183033 1.031994\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]\n[1,] 1.0000000 0.6902159\n[2,] 0.6902159 1.0000000\n```\n\n\n:::\n:::\n\n\n\nPer quanto riguarda il mixed-model il parametro cruciale è la deviazione standard delle intercette. Possiamo partire dall'Intraclass Correlation Coefficient (ICC) che determina la correlazione tra osservazioni dentro un cluster.\n\n$$\n\\mbox{ICC} = \\rho_{pre-post}\n$$\n$$\n\\mbox{ICC} = \\frac{\\sigma^2_{\\beta_0}}{\\sigma^2_{\\beta_0} + \\sigma^2_{\\epsilon}} \\\\\n$$\nSe assumiamo che la varianza totale sia uno, allora:\n\n$$\n\\sigma^2_{\\beta_0{_i}} + \\sigma^2_{\\epsilon} = 1\n$$\n\n$$\n\\mbox{ICC} = \\sigma^2_{\\beta_0{_i}}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n\nr <- 0.7 # icc = r\nb0 <- 0\nb1 <- d\nsb0 <- sqrt(r)\ns <- sqrt(1 - sb0^2)\n\ndat <- data.frame(\n    x = rep(0:1, each = n),\n    id = rep(1:n, 2)\n)\n\nb0i <- rnorm(n, 0, sb0)\ndat$y <- rnorm(N, with(dat, b0 + b0i[id] + b1 * x), s)\n\nfit <- lmer(y ~ x + (1|id), data = dat)\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ x + (1 | id)\n   Data: dat\n\nREML criterion at convergence: 128.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7887 -0.5160  0.0831  0.6159  1.4381 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.1978   0.4448  \n Residual             0.3179   0.5639  \nNumber of obs: 60, groups:  id, 30\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   0.1023     0.1311   0.780\nx             0.5246     0.1456   3.603\n\nCorrelation of Fixed Effects:\n  (Intr)\nx -0.555\n```\n\n\n:::\n\n```{.r .cell-code}\nperformance::icc(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.384\n  Unadjusted ICC: 0.338\n```\n\n\n:::\n:::\n\n\n\n## ICC\n\nNei mixed-models è utile capire ed utilizzare l'ICC. Simuliamo dati pre-post con diversi gradi di intraclass correlation (simuliamo più osservazioni di pre-post così è più chiaro il pattern):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyverse)\n\nicc <- c(0, 0.5, 0.8)\nn <- 10\nnt <- 100\nb0 <- 0\nb1 <- 0\n\nsb0 <- sqrt(icc)\ns <- sqrt(1 - sb0^2)\n\ndat <- expand.grid(\n    id = 1:n,\n    x = c(0, 1),\n    nt = 1:nt\n)\n\ny <- vector(mode = \"list\", length = length(icc))\n\nfor(i in 1:length(y)){\n    b0i <- rnorm(n, 0, sb0[i])\n    y[[i]] <- rnorm(nrow(dat), with(dat, b0 + b0i[id] + b1 * x), s[i])\n}\n\nnames(y) <- paste0(\"y_icc\", icc)\ndat <- cbind(dat, y)\n\ndat |> \n    pivot_longer(starts_with(\"y\"),\n                 names_to = \"icc\",\n                 values_to = \"y\") |> \n    mutate(icc = parse_number(icc)) |> \n    ggplot(aes(x = factor(id), y = y)) +\n    geom_boxplot() +\n    facet_wrap(~icc) +\n    xlab(\"Cluster\")\n```\n\n::: {.cell-output-display}\n![](2025-04-07_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "2025-04-07_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}