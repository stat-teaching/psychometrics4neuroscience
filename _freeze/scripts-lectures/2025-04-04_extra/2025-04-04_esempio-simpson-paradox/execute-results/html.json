{
  "hash": "400364f3ed79e3e1e43a5e6190c1df08",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 2025-04-04\nexecute:\n    echo: false\n---\n\n::: {.cell}\n\n:::\n\n\n\n\nIn psicologia e neuroscienze alcuni esperimenti includono delle variabili che possono variare tra soggetti, nonostante siano manipolate sperimentalmente.\n\nAd esempio, in psicofisica gli stimoli vengono spesso *adattati* ai soggetti e quindi non tutti i soggetti sono sottoposti allo stesso tipo di stimolazione.\n\nIpotizziamo che siamo interessati a capire la sensibilità al contrasto (visibilità rispetto allo sfondo) di un gruppo di soggetti. A livello individuale possiamo ipotizzare che la relazione vera di due soggetti sia ad esempio:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\nSolitamente siamo interessati a stimare la *soglia* percettiva ed eventualmente la *slope*. La soglia percettiva è il livello di $x$ (contrasto) necessario a ad avere una certa percentuale di visibilità (e.g., 50%).\n\nGli esperimenti possono essere tarati per adattare lo stimolo (contrasto) alle risposte permettendo di focalizzare i trial sulla parte della curva di interesse. Se proviamo a simulare due ipotetici esperimenti:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\nOra carichiamo un dataset con un esperimento di questo tipo.\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  id trial       x01 visibility\n1  1     1 0.2069943          0\n2  2     1 0.6339033          1\n3  3     1 0.7137630          0\n4  4     1 0.6853990          0\n5  5     1 0.2117152          0\n6  6     1 0.2450111          0\n```\n\n\n:::\n:::\n\n\n\n\nPossiamo anche vedere i pattern individuali:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nFittiamo i nostri modelli per soggetto e vediamo il pattern di parametri:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nPerfetto, ora fittiamo il nostro modello:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(lmerTest)\n\nfit <- glmer(visibility ~ x01 + (x01||id), data = dat, family = binomial(link = \"logit\"))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: visibility ~ x01 + (x01 || id)\n   Data: dat\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   7387.3    7416.2   -3689.7    7379.3      9996 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.2114 -0.4091 -0.3261 -0.2499  8.6903 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 2.217    1.489   \n id.1   x01         1.896    1.377   \nNumber of obs: 10000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -6.342      1.013  -6.258 3.91e-10 ***\nx01            8.738      2.017   4.333 1.47e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n    (Intr)\nx01 -0.984\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggeffects)\nplot(ggeffect(fit))\n```\n\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nL'effetto fisso stimato dal modello è 8.74. Al netto dello *shrinkage*, questo è decisamente inferiore rispetto alla media delle slope stimate sui singoli soggetti. Quale potrebbe essere il motivo?\n\nIl problema principale è che abbiamo un effetto del cluster (soggetti) sulla nostra variabile $x$ (vi dice qualcosa il Simpson's paradox?). Ogni soggetto ha il suo esperimento con un incremento chiaro (e consistente) della visibilità in funzione del contrasto MA i livelli di contrasto di ogni soggetto sono diversi uno dall'altro.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nQuindi in realtà non stiamo stimando esattamente quello che vorremmo, ovvero l'effetto medio (e la sua variabilità) del contrasto in ogni soggetto. Idealmente dovremmo calcolarlo su ogni soggetto e poi fare la media.\n\nPer fare questo è necessario trasformare la $x$, centrando i valori di contrasto sulla media di ogni soggetto.\n\n\n\n\n```r\ncmc <- function(x, cluster){\n  x - cm(x, cluster)\n}\ncm <- function(x, cluster){\n    cmm <- tapply(x, cluster, mean)\n    cmn <- tapply(x, cluster, length) \n    cmm[as.character(cluster)]\n}\n```\n\n::: {.cell}\n::: {.cell-output-display}\n![](2025-04-04_esempio-simpson-paradox_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_ex$x01_cmc <- cmc(dat_ex$x01, dat_ex$id)\nfit_cmc <- glmer(visibility ~ x01_cmc + (x01_cmc||id), data = dat_ex, family = binomial(link = \"logit\"))\nsummary(fit_cmc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: visibility ~ x01_cmc + (x01_cmc || id)\n   Data: dat_ex\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   7081.7    7110.5   -3536.8    7073.7      9996 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5490 -0.4042 -0.3101 -0.2293  6.2565 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.2294   0.4789  \n id.1   x01_cmc     7.6120   2.7590  \nNumber of obs: 10000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -2.15515    0.05998  -35.93   <2e-16 ***\nx01_cmc     18.17924    1.03817   17.51   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\nx01_cmc -0.224\n```\n\n\n:::\n:::\n\n\n\nSe erroneamente (qualche volta viene fatto), decidiamo di aggregare i dati a livello del soggetto. Possiamo nel migliore dei casi attenuare o distorcere la stima oppure stimare un pattern anche opposto.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_agg <- dat_ex |> \n    group_by(id) |> \n    summarise(p = mean(visibility),\n              n = n(),\n              x01 = mean(x01))\nhead(dat_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n     id     p     n   x01\n  <int> <dbl> <int> <dbl>\n1     1  0.11   100 0.171\n2     2  0.08   100 0.623\n3     3  0.12   100 0.680\n4     4  0.21   100 0.679\n5     5  0.02   100 0.180\n6     6  0.17   100 0.264\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_agg <- glmer(p ~ x01 + (1|id), data = dat_agg, weights = n, family = binomial(link = \"logit\"))\nsummary(fit_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: p ~ x01 + (1 | id)\n   Data: dat_agg\nWeights: n\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    633.0     640.8    -313.5     627.0        97 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.62242 -0.44308  0.02905  0.35862  1.33912 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n id     (Intercept) 0.2064   0.4543  \nNumber of obs: 100, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.9989     0.1605 -12.455   <2e-16 ***\nx01          -0.0477     0.3052  -0.156    0.876    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n    (Intr)\nx01 -0.938\n```\n\n\n:::\n:::\n",
    "supporting": [
      "2025-04-04_esempio-simpson-paradox_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}