{
  "hash": "0689ef9805efcfa436fa1ae36184667a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Signal Detection Theory\nformat: html\n---\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::load_all()\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(here)\n\nmtheme <- function(){\n    theme_minimal(20)\n}\n\ntheme_set(mtheme())\n\nfuns <- filor::get_funs(here(\"R\", \"utils-glm_phd.R\"))\n```\n:::\n\n\n\n\n\n# Probit link {.section}\n\n## Probit link\n\n- The mostly used *link function* when using a binomial GLM is the **logit link**. The **probit** link is another *link function* that can be used. The overall approach is the same between **logit** and **probit** models. The only difference is the parameter interpretation (i.e., no odds ratios) and the specific link function (and the inverse) to use.\n- The **probit** model use the **cumulative normal distribution** but the actual difference with a **logit** functions is neglegible.\n\n## Probit link\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n## Probit link\n\nWhen using the **probit link** the parameters are interpreted as difference in *z-scores* associated with a unit increase in the predictors. In fact probabilities are mapped into *z-scores* using the cumulative normal distribution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- 0.7\np2 <- 0.5\n\nqlogis(c(p1, p2)) # log(odds(p1)), logit link\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8472979 0.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\nqnorm(c(p1, p2)) # probit link\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5244005 0.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\nlog(odds_ratio(p1, p2)) # ~ beta1, logit link\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8472979\n```\n\n\n:::\n\n```{.r .cell-code}\npnorm(p1) - pnorm(p2) # ~beta1, probit link\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.06657389\n```\n\n\n:::\n:::\n\n\n\n\n## Probit link\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n## Signal Detection Theory\n\nIl modello probit è utilizzato per stimare i parametri della **signal detection theory**.\n\nBrevemente l'idea è quella di modellare decisioni binarie (o anche come rating) rispetto a come uno stimolo viene percepito ed elaborato internamente.\n\nLa teoria (nella sua versione di base) assume che uno stimolo (segnale) venga elaborato e l'informazione contenuta sostenga un qualche tipo di decisione su questo stimolo.\n\nAd esempio, immaginiamo di voler valutare la capacità di un radiologo di rilevare la presenza di un'anomalia in una radiografia. Possiamo immaginare di prendere 100 radiografie. 50 di queste contengono un'anomalia (signal trials) mentre 50 non la contengono (catch trials).\n\nPer ogni radiografia, chiediamo ai radiologi di valutare se rilevano un'anomalia oppure no.\n\nIncrociando lo stimolo (signal o catch) e la risposta (presente o assente) otteniamo una tipica tabella di contingenza 2x2, simile a quello che si ottiene nei test diagnostici.\n\n|              | Segnale: Si | Segnale: No            |\n|--------------|-------------|------------------------|\n| **Risposta: Si** | Hit (H)     | False Alarm (FA)       |\n| **Risposta: No** | Miss (M)    | Correct Rejection (CR) |\n\nIn questo tipo di classificazione solitamente è ottimale massimizzare gli Hit (o True Positive) e minimizzare i False Alarm (False Positive).\n\nLa teoria formalizza che le distribuzioni del segnale e del rumore sono delle Gaussiane standard. La distribuzione del rumore ha $\\mu = 0$ mentre la distribuzione del segnale ha $\\mu = d'$. In questo modo il parametro $d'$ (pronunciato d-prime) rappresenta il grado di separazione tra segnale e rumore.\n\nUna radiografia che contiene un segno chiaramente visibile avrà molta separazione tra le due distribuzioni mentre una radiografia con un segnale molto debole avrà più sovrapposizione.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\nOra, questa rappresentazione interna del segnale e del rumore che dipende dal tipo di stimolo e dall'abilità del soggetto. Tuttavia noi non osserviamo direttamente questa variabile latente ma la riposta si/no del soggetto.\n\nIl soggetto quindi, in base ad un qualche tipo di regola interna, decide di rispondere. La SDT formalizza questa regola interna come una soglia (*criterio*) che viene decisa internamente dal soggetto. Se in quel trial (radiografia) il segnale supera la soglia, il soggetto risponde **Si**, se non supera la soglia il soggetto risponde no.\n\nQuindi con la stessa intensità del segnale $d'$ soggetti diversi o lo stesso soggetto in condizioni diverse può avere un pattern di risposte diverse.\n\nCi sono alcuni punti importanti:\n\n- qualcunque criterio si scelga (in condizioni plausibili) non è mai possibile annullare i falsi allarmi e massimizzare gli hit\n- quando il criterio è nel mezzo tra le due distribuzioni ($d'/2$) viene definito unbiased\n- quando il soggetto (a prescindere dal segnale) tende a dare più risposte si viene definito un criterio liberale\n- quando il soggetto (a prescindere dal segnale) tende a dare più risposte no viene definito un criterio conservatore\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\nQuindi, per ogni possibile criterio (assumendo di poterlo variare sperimentalmente) abbiamo una diversa tabella di contingenza. Se lo facciamo tante volte, otteniamo una curva:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nd <- 1\ndat <- sim_sdt(1e3, d = d, 0.5)\nmid <- d/2\ncr <- c(-Inf, seq(mid - 4, mid + 4, 0.001), Inf)\nres <- sdt(is_signal = dat$is_signal, x = dat$x, c = cr)\n\ndata.frame(res) |> \n    ggplot(aes(x = pfa, y = phit)) +\n    geom_line() +\n    ylim(c(0, 1)) +\n    scale_x_reverse(limits = c(1, 0)) +\n    geom_abline(slope = -1, col = alpha(\"black\", 0.5)) +\n    xlab(\"P (FA)\") +\n    ylab(\"P (Hit)\") +\n    ggtitle(\"d' = 1\")\n```\n\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nQuesta in altri contesti (come quello dei test diagnostici) viene chiamata curva di ROC. Infatti l'*area under the curve* (AUC) assumendo la normalità delle due distribuzioni è:\n\n$$\n\\mbox{AUC} = \\Phi(\\frac{d'}{\\sqrt{2}})\n$$\nQuindi:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- 1 # dalla simulazione precedente\npnorm(1 / sqrt(2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7602499\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(res) |> \n    pivot_longer(c(phit, pfa, pmiss, pcr)) |> \n    ggplot(aes(x = c, y = value, color = name)) +\n    geom_line() +\n    theme(legend.title = element_blank()) +\n    xlab(\"Criterio\") +\n    ylab(\"Probabilità\")\n```\n\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nTornando all'esperimento delle radiografie, quello che osserviamo empiricamente è qualcosa di questo tipo (dati simulati usando `sim_sdt()`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- sim_sdt(100, 1, c = 0.5) |> \n    select(-x)\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  say_signal is_signal\n1          0         0\n2          1         1\n3          0         0\n4          1         1\n5          0         0\n6          0         1\n```\n\n\n:::\n:::\n\n\n\n\nDove `is_signal` indica se la radiografia contiene il segnale o no e `say_signal` indica la risposta del soggetto.\n\nIn questo caso il $d'$ è la distanza tra la distribuzione latente di segnale e rumore e $c$ è il criterio di risposta.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- sdt(is_signal = dat$is_signal, dat$say_signal)\ncl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$hit\n[1] 12\n\n$miss\n[1] 13\n\n$fa\n[1] 4\n\n$cr\n[1] 21\n\n$phit\n[1] 0.48\n\n$pfa\n[1] 0.16\n\n$pmiss\n[1] 0.52\n\n$pcr\n[1] 0.84\n\n$c\n[1] NA\n```\n\n\n:::\n:::\n\n\n\n\nPossiamo semplicemente calcolare la distanza tra le due distribuzioni, assumendo che siano gaussiane a varianza 1:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# dprime\nqnorm(cl$phit) - qnorm(cl$pfa)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9443043\n```\n\n\n:::\n\n```{.r .cell-code}\n# criterio\n-(qnorm(cl$phit) + qnorm(cl$pfa)) / 2 # - perchè per convenzione c negativo = liberale, c positivo = conservatore\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5223057\n```\n\n\n:::\n:::\n\n\n\n\nGli stessi parametri possono essere stimati con un `glm` binomiale con link function `probit`. Infatti il criterio è il punto di mezzo tra signal e noise mentre il $d'$ non è altro che la distanza tra le due distribuzioni (di segnale e rumore).\n\nSe facciamo un modello predicendo le risposte (binarie) con il tipo di trial (binario) otteniamo esattamente questi parametri.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$say_signal01 <- as.integer(as.character(dat$say_signal))\n\nfit <- glm(say_signal01 ~ is_signal, data = dat, family = binomial(link = \"probit\"))\n\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = say_signal01 ~ is_signal, family = binomial(link = \"probit\"), \n    data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept) -0.05015    0.25078  -0.200    0.841  \nis_signal0  -0.94430    0.39204  -2.409    0.016 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.687  on 49  degrees of freedom\nResidual deviance: 56.601  on 48  degrees of freedom\nAIC: 60.601\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\n\n\nL'intercetta è la probabilità (in $z$ scores) di rispondere Si quando il segnale è 0 (catch). Quindi è la probabilità di fare falsi allarmi.\n\nLa slope è la distanza (in $z$ scores) tra i trial con il segnale e con il rumore che è esattamente il concetto di $d'$. Cambia solo il segno rispetto a quello calcolato manualmente.\n\nPer calcolare anche il criterio nel modo convenzionale è sufficiente centrare il predittore `is_signal`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- glm(say_signal01 ~ is_signal, \n           data = dat,\n           contrasts = list(is_signal = contr.sum(2)/2), # -0.5, 0.5\n           family = binomial(link = \"probit\"))\n\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = say_signal01 ~ is_signal, family = binomial(link = \"probit\"), \n    data = dat, contrasts = list(is_signal = contr.sum(2)/2))\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)  -0.5223     0.1960  -2.665  0.00771 **\nis_signal1    0.9443     0.3920   2.409  0.01601 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.687  on 49  degrees of freedom\nResidual deviance: 56.601  on 48  degrees of freedom\nAIC: 60.601\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\n\nAttenzione che per come è parametrizzato, il criterio ha il segno opposto rispetto a quello convenzionale.\n\nIl vantaggio è che possiamo inserire dei predittori sia per il criterio che per il $d'$. Ad esempio, immaginiamo che ci siano 100 radiografie che indagano un'ipotetica condizione a bassa mortalità vs una condizione ad alta mortalità. Potremmo immaginare che in funzione dell'incentivo decisionale lo stile di risposta possa cambiare (da più a meno conservativo/liberale).\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  say_signal is_signal          x cond\n1          0         0 -1.0198272  low\n2          1         1  1.3471905  low\n3          1         0  0.6164624  low\n4          1         1  0.4093837  low\n5          0         0 -1.1217480  low\n6          1         1  0.3081716  low\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_low <- glm(say_signal ~ is_signal,\n               subset = cond == \"low\",\n               contrasts = list(is_signal = -contr.sum(2)/2),\n               data = dat, \n               family = binomial(link = \"probit\"))\n\nfit_high <- glm(say_signal ~ is_signal,\n               subset = cond == \"high\",\n               contrasts = list(is_signal = -contr.sum(2)/2),\n               data = dat, \n               family = binomial(link = \"probit\"))\n\n\nfit <- glm(say_signal ~ is_signal * cond, \n           contrasts = list(is_signal = -contr.sum(2)/2),\n           data = dat, \n           family = binomial(link = \"probit\"))\n\n\ncar::compareCoefs(fit_low, fit_high, fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCalls:\n1: glm(formula = say_signal ~ is_signal, family = binomial(link = \"probit\"),\n   data = dat, subset = cond == \"low\", contrasts = list(is_signal = \n  -contr.sum(2)/2))\n2: glm(formula = say_signal ~ is_signal, family = binomial(link = \"probit\"),\n   data = dat, subset = cond == \"high\", contrasts = list(is_signal = \n  -contr.sum(2)/2))\n3: glm(formula = say_signal ~ is_signal * cond, family = binomial(link = \n  \"probit\"), data = dat, contrasts = list(is_signal = -contr.sum(2)/2))\n\n                   Model 1 Model 2 Model 3\n(Intercept)        -0.5246  0.4992  0.4992\nSE                  0.0197  0.0197  0.0197\n                                          \nis_signal1          1.0031  1.0405  1.0405\nSE                  0.0395  0.0394  0.0394\n                                          \ncondlow                            -1.0238\nSE                                  0.0279\n                                          \nis_signal1:condlow                 -0.0374\nSE                                  0.0558\n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(multcomp)\n\nglht(fit, \n     linfct = c(\n         \"-(Intercept) == 0\",\n         # criterion low\n         \"-(Intercept) + condlow == 0\",\n         # dprime condition high\n         \"is_signal1 == 0\",\n         # dprime condition low\n         \"is_signal1 + is_signal1:condlow == 0\",\n         # difference between criterion\n         \"condlow == 0\",\n         # difference between dprime\n         \"is_signal1:condlow == 0\"\n     )\n) |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t Simultaneous Tests for General Linear Hypotheses\n\nFit: glm(formula = say_signal ~ is_signal * cond, family = binomial(link = \"probit\"), \n    data = dat, contrasts = list(is_signal = -contr.sum(2)/2))\n\nLinear Hypotheses:\n                                     Estimate Std. Error z value Pr(>|z|)    \n-(Intercept) == 0                    -0.49919    0.01971 -25.325   <1e-05 ***\n-(Intercept) + condlow == 0          -1.52300    0.04409 -34.544   <1e-05 ***\nis_signal1 == 0                       1.04048    0.03942  26.394   <1e-05 ***\nis_signal1 + is_signal1:condlow == 0  1.00313    0.03948  25.406   <1e-05 ***\ncondlow == 0                         -1.02381    0.02790 -36.699   <1e-05 ***\nis_signal1:condlow == 0              -0.03735    0.05579  -0.669    0.928    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n```\n\n\n:::\n:::\n\n\n\n\nInfine, un aspetto interessante è che in qualunque caso, il criterio unbiased è quello che massimizza l'accuratezza intesa come HIT + CR.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- sim_sdt(1e4, 1, 0)\ncr <- seq(-3, 3, 0.1)\nres <- sdt(dat$is_signal, x = dat$x, c = cr)\nres <- data.frame(res)\n\nres |> \n    mutate(acc = 0.5 * (phit + pcr)) |> \n    ggplot(aes(x = c, y = acc)) +\n    geom_line() +\n    xlab(\"Criterio\") +\n    ylab(\"pCR + pHIT\")\n```\n\n::: {.cell-output-display}\n![](signal-detection-theory_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\nPer tutti gli esempi ho simulato i dati usando due funzioni custom:\n\n\n\n\n```r\nsim_sdt <- function(nt, d, c = 0, ps = 0.5, sr = 1){\n  ns <- floor(ps * nt)\n  nn <- nt - ns\n  is_signal <- rep(c(0, 1), nn, ns)\n  x <- ifelse(is_signal == 1, rnorm(ns, d/2, sr), rnorm(nn, -d/2, 1))\n  say_signal <- ifelse(x > c, 1, 0)\n  is_signal <- factor(is_signal, levels = c(1,0))\n  say_signal <- factor(say_signal, levels = c(1,0))\n  data.frame(say_signal, is_signal, x)\n}\nsdt <- function(is_signal, say_signal = NULL, x = NULL, c = NULL){\n\n  if(is.null(say_signal)){\n    say_signal <- lapply(c, function(ci) ifelse(x > ci, 1, 0))\n  }else{\n    say_signal <- list(say_signal)\n    c <- NA\n  }\n\n  hit <- miss <- fa <- cr <- rep(0, length(c))\n\n  for(i in 1:length(c)){\n    hit[i] <- sum(is_signal == 1 & say_signal[[i]] == 1)\n    miss[i] <- sum(is_signal == 1 & say_signal[[i]] == 0)\n    fa[i] <- sum(is_signal == 0 & say_signal[[i]] == 1)\n    cr[i] <- sum(is_signal == 0 & say_signal[[i]] == 0)\n  }\n\n  list(hit = hit,\n       miss = miss,\n       fa = fa,\n       cr = cr,\n       phit = hit / (hit + miss),\n       pfa = fa / (fa + cr),\n       pmiss = miss / (miss + hit),\n       pcr = cr / (cr + fa),\n       c = c)\n}\n```\n\n\n\n\n## Esempio con dati veri\n\nPartendo da questo tutorial [https://vuorre.com/posts/sdt-regression/index.html](https://vuorre.com/posts/sdt-regression/index.html) usiamo il dataset `data/sdt-example.rds`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- readRDS(here(\"data\", \"sdt-example.rds\"))\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  pid   trial stimulus response\n  <fct> <int> <fct>    <fct>   \n1 1         1 Old      New     \n2 1         2 Old      New     \n3 1         3 Old      New     \n4 1         4 Old      New     \n5 1         5 Old      New     \n6 1         6 Old      New     \n```\n\n\n:::\n:::\n\n\n\n\n- per ogni soggetto calcoliamo i parametri di SDT (Hit, FA, etc.)\n- calcoliamo manualmente $d'$ e criterio con il pacchetto `psycho::dprime()`\n- fittiamo un modello probit multilivello per stimare i parametri e confrontiamoli\n",
    "supporting": [
      "signal-detection-theory_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}