{
  "hash": "f092c7b5057a99f1ffc89713bf279078",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multilevel and Multivariate Meta-analysis\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Quick recap of the two-level model\n\nWhat we did so far about the two-level model (fixed/equal or random) is combining primary studies summarising each study with an effect size and precision measure.\n\n![From https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/images/multilevel-model_col_sep.png)\n\nIn this model, effect sizes (and variances) are considered independent because they are collected on different participants. In other terms each row of a meta-analysis dataset is assumed independent.\n\nIn this example from the `dat.bcg` dataset (`?dat.bcg`) each row comes from a different study with different participants.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### calculate log risk ratios and corresponding sampling variances\ndat <- escalc(measure=\"RR\", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  trial               author year tpos  tneg cpos  cneg ablat     alloc      yi \n1     1              Aronson 1948    4   119   11   128    44    random -0.8893 \n2     2     Ferguson & Simes 1949    6   300   29   274    55    random -1.5854 \n3     3      Rosenthal et al 1960    3   228   11   209    42    random -1.3481 \n4     4    Hart & Sutherland 1977   62 13536  248 12619    52    random -1.4416 \n5     5 Frimodt-Moller et al 1973   33  5036   47  5761    13 alternate -0.2175 \n6     6      Stein & Aronson 1953  180  1361  372  1079    44 alternate -0.7861 \n      vi \n1 0.3256 \n2 0.1946 \n3 0.4154 \n4 0.0200 \n5 0.0512 \n6 0.0069 \n```\n\n\n:::\n:::\n\n\n\n\nMore formally, the two-level random-effects model can be written as:\n\n$$\ny_i = \\mu_{\\theta} + \\delta_i + \\epsilon_i\n$$\n\n$$\n\\delta_i \\sim \\mathcal{N}(0, \\tau^2)\n$$\n\n$$\n\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_{\\epsilon_i})\n$$\n\n## Dependency\n\nThere are situations where effect sizes (and variances) are no longer independent. There are mainly two sources of dependency:\n\n1. multiple effect sizes within the same paper but with different participants\n2. multiple effect sizes collected on the same pool of participants\n\nThe first case refer to a situation where the effect sizes are nested within a paper and given that they will share a similar methodology, same authors, etc. they are likely more similar to each other compared to effect sizes from different papers. We can call this situation a **multilevel** dataset.\n\nIn the second case, the effects are correlated because they are collected on the same pool of participants thus sampling errors are correlated. This is the case where multiple outcome measures are collected or multiple time-points (like a longitudinal design). We can call this situation a **multivariate** dataset.\n\nImportantly, the two type of meta-analysis will be very similar both formally and from the R implementation point of view but they are clearly distincted from an empirical point of view.\n\n## Multilevel meta-analysis\n\nThe multilevel data structure can be easily depicted in the figure below.\n\n![From https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/images/multilevel-model2_col_sep.png)\n\nAlso this picture clearly show the data structure and important parameters:\n\n![](https://raw.githubusercontent.com/shared-research/simulating-meta-analysis/refs/heads/main/documents/paper/img/multilevel.svg)\n\nWe can have several levels beyond the two-level model but usually common meta-analyses have a maximum of 3-4 levels. For example, it is common in experimental Psychology to have papers with more than one experiment with different participants.\n\nMore formally, a three-level model can be written as:\n\n\\begin{align}\n\\begin{gathered}\ny_{ij} = \\mu_{\\theta} + \\delta_i + \\zeta_{ij} + \\epsilon_{ij}\n\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\delta_i\\sim \\mathcal{N}(0, \\tau^2)\n\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\zeta_{ij} \\sim \\mathcal{N}(0, \\omega^2)\n\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\epsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_{\\epsilon_{ij}}^{2})\n\n\\end{gathered}\n\\end{align}\n\nThe only addition is an extra source of heterogeneity $\\omega^2$ that can be intepreted as the true heterogeneity between effects nested within the same paper (or whatever is the cluster).\n\nA data structure in this case need to have an index for the cluster and an index for the effect. For example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3l <- expand.grid(\n    paper = 1:10,\n    effect = 1:3\n)\n\ndat3l <- dat3l[order(dat3l$paper), ]\n\nhead(dat3l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   paper effect\n1      1      1\n11     1      2\n21     1      3\n2      2      1\n12     2      2\n22     2      3\n```\n\n\n:::\n:::\n\n\n\nEffects within the same paper are more likely to be similar compared to effects between different papers. This degree of similarity is essentially the intraclass correlation defined as the proportion of variance explained by the clustering.\n\n$$\n\\mbox{ICC} = \\frac{\\tau^2}{\\omega^2 + \\tau^2}\n$$\n\nA practical example can be seen with the `dat.konstantopoulos2011` dataset (see also the `metafor` blog post [https://www.metafor-project.org/doku.php/analyses:konstantopoulos2011](https://www.metafor-project.org/doku.php/analyses:konstantopoulos2011))\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3l <- dat.konstantopoulos2011\nhead(dat3l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  district school study year     yi    vi \n1       11      1     1 1976 -0.180 0.118 \n2       11      2     2 1976 -0.220 0.118 \n3       11      3     3 1976  0.230 0.144 \n4       11      4     4 1976 -0.300 0.144 \n5       12      1     5 1989  0.130 0.014 \n6       12      2     6 1989 -0.260 0.014 \n```\n\n\n:::\n:::\n\n\n\n\nHere the effect sizes comes from schools (collected on participants) nested within districts. Each district has one or more schools that are likely to have within-district similarity.\n\nWe can start by fitting the standard two-level model but here we are ignoring the (possibile) ICC.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2l <- rma(yi, vi, data = dat3l)\nsummary(fit2l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRandom-Effects Model (k = 56; tau^2 estimator: REML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-16.8455   33.6910   37.6910   41.7057   37.9218   \n\ntau^2 (estimated amount of total heterogeneity): 0.0884 (SE = 0.0202)\ntau (square root of estimated tau^2 value):      0.2974\nI^2 (total heterogeneity / total variability):   94.70%\nH^2 (total variability / sampling variability):  18.89\n\nTest for Heterogeneity:\nQ(df = 55) = 578.8640, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub     \n  0.1279  0.0439  2.9161  0.0035  0.0419  0.2139  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nWe need to change the fitting function from `rma` to `rma.mv` (`mv` for multivariate but also multilevel). Essentially we need to specify that we have two clustering levels (beyond the usual first level of the two-level model) using the `random =` argument.\n\nThe two-level model can be fitted also using `rma.mv` and the result will be practically the same (beyond small numerical differences due to the different algorithm). The two-level model can be written as:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2l.mv <- rma.mv(yi, vi, random = ~ 1|study, data = dat3l)\nsummary(fit2l.mv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 56; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n-16.8455   33.6910   37.6910   41.7057   37.9218   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed  factor \nsigma^2    0.0884  0.2974     56     no   study \n\nTest for Heterogeneity:\nQ(df = 55) = 578.8640, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub     \n  0.1279  0.0439  2.9161  0.0035  0.0419  0.2139  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nBoth these models are not entirely correct. We have two options here:\n\n1. aggregating the effects reducing the three-level structure to a two-level structure\n2. fitting a proper three-level model\n\nFor the aggregation, the idea is to essentially perform a two-level fixed effect model for each cluster thus having a (weighted) aggregated effect and sampling variance.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3l_l <- split(dat3l, dat3l$district)\nfit3l_l <- lapply(dat3l_l, function(x) data.frame(predict(rma(yi, vi, data = x, method = \"EE\"))))\n\ndat3l_agg <- do.call(rbind, fit3l_l)\nfit3l_agg <- rma(pred, se^2, data = dat3l_agg)\n\nsummary(fit3l_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRandom-Effects Model (k = 11; tau^2 estimator: REML)\n\n  logLik  deviance       AIC       BIC      AICc   \n -2.0621    4.1242    8.1242    8.7293    9.8384   \n\ntau^2 (estimated amount of total heterogeneity): 0.0828 (SE = 0.0397)\ntau (square root of estimated tau^2 value):      0.2878\nI^2 (total heterogeneity / total variability):   98.10%\nH^2 (total variability / sampling variability):  52.60\n\nTest for Heterogeneity:\nQ(df = 10) = 415.9203, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub    \n  0.1960  0.0900  2.1785  0.0294  0.0197  0.3724  * \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nThis can de done in a more efficient way using the `metafor::aggregate()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3l_agg <- aggregate(dat3l, cluster = district, struct = \"ID\")\n# dat3l_agg <- aggregate(dat3l, cluster = district, rho = 0)\ndat3l_agg\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   district school study   year     yi    vi \n1        11    2.5   2.5 1976.0 -0.126 0.032 \n2        12    2.5   6.5 1989.0  0.067 0.004 \n3        18    2.0  10.0 1994.0  0.350 0.007 \n4        27    2.5  13.5 1976.0  0.500 0.001 \n5        56    2.5  17.5 1997.0  0.051 0.002 \n6        58    6.0  25.0 1976.0 -0.042 0.001 \n7        71    2.0  32.0 1997.0  0.886 0.004 \n8        86    4.5  37.5 1997.0 -0.029 0.000 \n9        91    3.5  44.5 2000.0  0.250 0.002 \n10      108    3.0  50.0 2000.0  0.015 0.006 \n11      644    2.5  54.5 1994.5  0.162 0.019 \n```\n\n\n:::\n:::\n\n\n\n\nThe argument `struct = \"ID\"` indicates that sampling errors are independent within each cluster (district).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3l_agg <- rma(yi, vi, data = dat3l_agg)\nsummary(fit3l_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRandom-Effects Model (k = 11; tau^2 estimator: REML)\n\n  logLik  deviance       AIC       BIC      AICc   \n -2.0621    4.1242    8.1242    8.7293    9.8384   \n\ntau^2 (estimated amount of total heterogeneity): 0.0828 (SE = 0.0397)\ntau (square root of estimated tau^2 value):      0.2878\nI^2 (total heterogeneity / total variability):   98.10%\nH^2 (total variability / sampling variability):  52.60\n\nTest for Heterogeneity:\nQ(df = 10) = 415.9203, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub    \n  0.1960  0.0900  2.1785  0.0294  0.0197  0.3724  * \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nThe aggregation can also be done within the `rma.mv` function. Essentially we can provide a (block) variance-covariance matrix instead of the `vi` element indicating how the effects are correlated within studies.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nV <- vcalc(vi = vi, cluster = district, obs = study, rho = 0, data = dat3l)\nrownames(V) <- colnames(V) <- paste0(\"dist\", dat3l$district)\nround(V, 2)[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       dist11 dist11 dist11 dist11 dist12 dist12 dist12 dist12 dist18 dist18\ndist11   0.12   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\ndist11   0.00   0.12   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\ndist11   0.00   0.00   0.14   0.00   0.00   0.00   0.00   0.00   0.00   0.00\ndist11   0.00   0.00   0.00   0.14   0.00   0.00   0.00   0.00   0.00   0.00\ndist12   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00\ndist12   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00\ndist12   0.00   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00\ndist12   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.02   0.00   0.00\ndist18   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.02   0.00\ndist18   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.04\n```\n\n\n:::\n\n```{.r .cell-code}\n# or in the block-form\nblsplit(V, dat3l$district, fun = function(x) round(x, 2))[1:3] # first 3 districts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`11`\n       dist11 dist11 dist11 dist11\ndist11   0.12   0.00   0.00   0.00\ndist11   0.00   0.12   0.00   0.00\ndist11   0.00   0.00   0.14   0.00\ndist11   0.00   0.00   0.00   0.14\n\n$`12`\n       dist12 dist12 dist12 dist12\ndist12   0.01   0.00   0.00   0.00\ndist12   0.00   0.01   0.00   0.00\ndist12   0.00   0.00   0.01   0.00\ndist12   0.00   0.00   0.00   0.02\n\n$`18`\n       dist18 dist18 dist18\ndist18   0.02   0.00   0.00\ndist18   0.00   0.04   0.00\ndist18   0.00   0.00   0.01\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3l_agg <- rma.mv(yi, V, data = dat3l, random = ~ 1|district)\nsummary(fit3l_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 56; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n-32.2165   64.4330   68.4330   72.4476   68.6637   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed    factor \nsigma^2    0.0828  0.2878     11     no  district \n\nTest for Heterogeneity:\nQ(df = 55) = 578.8640, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub    \n  0.1960  0.0900  2.1785  0.0294  0.0197  0.3724  * \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nAll these models are **exactly** the same. See [https://jepusto.com/posts/Sometimes-aggregating-effect-sizes-is-fine](https://jepusto.com/posts/Sometimes-aggregating-effect-sizes-is-fine) for a more detailed explanation of aggregating vs doing the model dropping the lowest nesting level.\n\nAt the same time these models assumes that sampling errors are independent (that is probably true) but they are ignoring that the effects could be dependent because they are nested within the same cluster.\n\nThe most appropriate model can be specified adding the nested level:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3l <- rma.mv(yi, vi, random = ~ 1|district/study, data = dat3l)\nsummary(fit3l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 56; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n -7.9587   15.9174   21.9174   27.9394   22.3880   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed          factor \nsigma^2.1  0.0651  0.2551     11     no        district \nsigma^2.2  0.0327  0.1809     56     no  district/study \n\nTest for Heterogeneity:\nQ(df = 55) = 578.8640, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub    \n  0.1847  0.0846  2.1845  0.0289  0.0190  0.3504  * \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nThe argument `1|district/study` means that effects (study) are nested within clusters (district).\n\nWe can see that the fixed part (Model Results) is the same (in terms of number of parameters not results) as the previous models but now we have two estimated variances, $\\omega^2$ and $\\tau^2$ as the picture above. \n\nAlso we can see that the sum of the two variances is similar to the heterogeneity estimated by previous models (slightly higher). The core difference is the fixed part where beyond differences in the estimated effects due to different weights, the standard error is very different.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr <- rbind(data.frame(predict(fit2l)), \n            data.frame(predict(fit3l_agg)),\n            data.frame(predict(fit3l)))\nrr$sigma2 <- c(fit2l$tau2, fit3l_agg$sigma2, sum(fit3l$sigma2))\nrr <- round(rr, 4)\nrr$model <- c(\"2l\", \"2l_agg\", \"3l\")\nrr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    pred     se  ci.lb  ci.ub   pi.lb  pi.ub sigma2  model\n1 0.1279 0.0439 0.0419 0.2139 -0.4612 0.7171 0.0884     2l\n2 0.1960 0.0900 0.0197 0.3724 -0.3950 0.7871 0.0828 2l_agg\n3 0.1847 0.0846 0.0190 0.3504 -0.4502 0.8197 0.0978     3l\n```\n\n\n:::\n:::\n\n\n\n\nIn particular, the two-level model (on the three-level) dataset is underestimating the standard error of the average effect because is considering each row as independent. The model with aggregation is similar to the three-level model while the model without aggregation is very different.\n\nThe difference is related to the ICC parameter:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3l$sigma2[1] / sum(fit3l$sigma2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6652655\n```\n\n\n:::\n:::\n\n\n\n\nThe model can be written in a form where the ICC is directly computed:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3l.icc <- rma.mv(yi, vi, random = ~study|district, data = dat3l)\n# rma.mv(yi, vi, random = ~study|district, data = dat3l, struct = \"CS\") # struct = \"CS\" by default\nsummary(fit3l.icc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 56; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n -7.9587   15.9174   21.9174   27.9394   22.3880   \n\nVariance Components:\n\nouter factor: district (nlvls = 11)\ninner factor: study    (nlvls = 56)\n\n            estim    sqrt  fixed \ntau^2      0.0978  0.3127     no \nrho        0.6653             no \n\nTest for Heterogeneity:\nQ(df = 55) = 578.8640, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub    \n  0.1847  0.0846  2.1845  0.0289  0.0190  0.3504  * \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n`random = ~study|district` is defined as `inner|outer` factors with a compound symmetry structure (`struct = CS`) by default. The idea is that each study is considered as a different outcome but we estimate a single $\\tau^2$ and a single $\\rho$ that is the correlation between different outcomes/effects. The two models are exactly the same, only with a different parametrization.\n\nChecking the impact of using a different correlation compared to ICC:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- seq(0.01, 0.99, length.out = 20)\nres <- vector(mode = \"list\", length = length(r))\n\nfor(i in 1:length(r)){\n    V <- vcalc(vi, cluster = district, obs = study, rho = r[i], data = dat3l)\n    fit <- rma.mv(yi, V, random = ~1|district, data = dat3l)\n    fits <- data.frame(predict(fit))\n    fits$sigma2 <- sum(fit$sigma2)\n    fits$r <- r[i]\n    res[[i]] <- fits\n}\n\nresd <- do.call(rbind, res)\nresd$model <- 0\n\nresd3l <- data.frame(predict(fit3l))\nresd3l$sigma2 <- sum(fit3l.icc$tau2)\nresd3l$r <- fit3l.icc$rho\nresd3l$model <- 1\n\nresd <- rbind(resd, resd3l)\n\nresd |> \n    pivot_longer(c(pred, se)) |> \n    ggplot(aes(x = r, y = value, color = factor(model))) +\n    geom_point(size = 3) +\n    facet_wrap(~name, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](multilevel-multivariate-meta-analysis_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\nClearly, the assumption of the three-level model is that $\\omega^2$ is the same for each cluster thus we are estimating a single $\\omega^2$.\n\n### Simulating data\n\nData simulation again here is very useful to understand the model. We need to generate two vectors of random effects compared to the two-level model. Let's start with a simple data structure with $k$ clusters (e.g., papers) each having $j$ nested effects.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 30\nj <- 3\n\ndat <- expand.grid(\n    effect = 1:j,\n    paper = 1:k\n)\ndat$id <- 1:nrow(dat)\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  effect paper id\n1      1     1  1\n2      2     1  2\n3      3     1  3\n4      1     2  4\n5      2     2  5\n6      3     2  6\n```\n\n\n:::\n:::\n\n\n\nNow we need to set the true parameters:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nes <- 0.3\ntau2 <- 0.15\nomega2 <- 0.05\n(icc <- tau2 / (tau2 + omega2)) # real icc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.75\n```\n\n\n:::\n\n```{.r .cell-code}\ndeltai <- rnorm(k, 0, tau2) # k random effects\nzetaij <- rnorm(nrow(dat), 0, omega2) # k * j (or the number of rows) random effects\n\ndat$deltai <- deltai[dat$paper]\ndat$zetaij <- zetaij\n\n# true effects\ndat$thetai <- with(dat, es + deltai + zetaij)\n\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  effect paper id      deltai        zetaij    thetai\n1      1     1  1  0.04967303 -0.0068029343 0.3428701\n2      2     1  2  0.04967303  0.0901059553 0.4397790\n3      3     1  3  0.04967303 -0.0098898288 0.3397832\n4      1     2  4 -0.10358568 -0.0002135816 0.1962007\n5      2     2  5 -0.10358568 -0.0242973401 0.1721170\n6      3     2  6 -0.10358568  0.1017387919 0.2981531\n```\n\n\n:::\n\n```{.r .cell-code}\ndat |> \n    filter(paper %in% sample(unique(paper), 10)) |> \n    ggplot(aes(x = thetai, y = paper)) +\n    geom_point(aes(color = factor(paper)))\n```\n\n::: {.cell-output-display}\n![](multilevel-multivariate-meta-analysis_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\nNow we can use the usual `sim_studies()` function or manually to generate a study for each row of this dataframe with the true parameters.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$yi <- NA\ndat$vi <- NA\ndat$n0 <- 10 + rpois(nrow(dat), 50)\ndat$n1 <- 10 + rpois(nrow(dat), 50)\n\nfor(i in 1:nrow(dat)){\n    g0 <- rnorm(dat$n0[i], 0, 1)\n    g1 <- rnorm(dat$n1[i], dat$thetai[i], 1)\n    dat$yi[i] <- mean(g1) - mean(g0)\n    dat$vi[i] <- var(g0)/dat$n0[i] + var(g1)/dat$n1[i]\n}\n\nfit <- rma.mv(yi, vi, random = ~ 1|paper/id, data = dat, sparse = TRUE)\nfit.icc <- rma.mv(yi, vi, random = ~ effect|paper, data = dat, sparse = TRUE)\n\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 90; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n 14.7427  -29.4854  -23.4854  -16.0195  -23.2030   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed    factor \nsigma^2.1  0.0107  0.1033     30     no     paper \nsigma^2.2  0.0015  0.0393     90     no  paper/id \n\nTest for Heterogeneity:\nQ(df = 89) = 119.1442, p-val = 0.0181\n\nModel Results:\n\nestimate      se     zval    pval   ci.lb   ci.ub      \n  0.3234  0.0272  11.8802  <.0001  0.2701  0.3768  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit.icc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 90; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n 14.7427  -29.4854  -23.4854  -16.0195  -23.2030   \n\nVariance Components:\n\nouter factor: paper  (nlvls = 30)\ninner factor: effect (nlvls = 3)\n\n            estim    sqrt  fixed \ntau^2      0.0122  0.1105     no \nrho        0.8736             no \n\nTest for Heterogeneity:\nQ(df = 89) = 119.1442, p-val = 0.0181\n\nModel Results:\n\nestimate      se     zval    pval   ci.lb   ci.ub      \n  0.3234  0.0272  11.8802  <.0001  0.2701  0.3768  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nWe can put everything within a function to generate data also with heterogeneous number of effects $j$ within each cluster.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_3l_studies <- function(k,\n                           j,\n                           es = 0,\n                           tau2_k = 0,\n                           tau2_j = 0,\n                           n0,\n                           n1 = NULL,\n                           sample_j = FALSE,\n                           sample_n = NULL,\n                           simulate = TRUE,\n                           raw = FALSE){\n    if(sample_j){\n        nj <- sample(1:j, k, replace = TRUE)\n    } else{\n        nj <- rep(j, k)\n    }\n    \n    study <- unlist(lapply(nj, function(x) 1:x))\n    paper <- rep(1:k, nj)\n    sim <- data.frame(paper, study)\n    \n    delta_k <- rnorm(k, 0, sqrt(tau2_k))\n    delta_j <- rnorm(nrow(sim), 0, sqrt(tau2_j))\n    \n    kj <- nrow(sim)\n    \n    if(!is.null(sample_n)){\n        n0 <- round(sample_n(kj))\n        n1 <- round(sample_n(kj))\n    } else{\n        if(length(n0) == 1) n0 <- rep(n0, nrow(sim))\n        if(length(n1) == 1) n1 <- n0\n    }\n    \n    es_kj <- es + delta_k[paper] + delta_j\n    \n    if(simulate){\n        ss <- sim_studies(nrow(sim), es_kj, n0, n1, raw = raw)\n        if(!raw){\n            ss <- do.call(rbind, ss)\n            res <- cbind(sim, ss)\n        } else{\n            res <- do.call(rbind, ss)\n            paper_r <- rep(paper, sapply(ss, nrow))\n            study_r <- rep(study, sapply(ss, nrow))\n            res <- cbind(res, paper = paper_r, study = study_r)\n        }\n        \n    } else{\n        res <- sim\n        res$es <- es\n        res$delta_k <- delta_k[paper]\n        res$delta_j <- delta_j\n        res$theta_kj <- es_kj\n    }\n    \n    return(res)\n    \n}\n\nsim_study <- function(es, n0, n1, raw = FALSE){\n    g0 <- rnorm(n0, 0, 1)\n    g1 <- rnorm(n1, es, 1)\n    \n    if(raw){\n        N <- n0 + n1\n        out <- data.frame(\n            subject = 1:N,\n            x = rep(0:1, c(n0, n1)),\n            y = c(g0, g1)\n        )\n    } else{\n        yi <- mean(g1) - mean(g0)\n        vi <- var(g0)/n0 + var(g1)/n1\n        out <- data.frame(\n            yi, vi\n        )\n    }\n    return(out)\n}\n\nsim_studies <- function(k, es, n0, n1 = NULL, raw = FALSE){\n    if(length(n0) == 1) n0 <- rep(n0, k)\n    if(length(n1) == 1) n1 <- rep(n1, k) \n    if(is.null(n1)) n1 <- n0\n    if(length(es) == 1) es <- rep(es, k)\n    \n    mapply(sim_study, es, n0, n1, raw = raw, SIMPLIFY = FALSE)\n}\n\ndat <- sim_3l_studies(k = 100, \n                      j = 5, \n                      es = 0.3, \n                      tau2_k = 0.1, \n                      tau2_j = 0.05, \n                      n0 = 50, \n                      n1 = 50)\n\nfit.3l.sim <- rma.mv(yi, vi, random = ~ 1|paper/study, data = dat)\nsummary(fit.3l.sim)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 500; method: REML)\n\n   logLik   Deviance        AIC        BIC       AICc   \n-204.3638   408.7276   414.7276   427.3655   414.7761   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed       factor \nsigma^2.1  0.1021  0.3196    100     no        paper \nsigma^2.2  0.0519  0.2277    500     no  paper/study \n\nTest for Heterogeneity:\nQ(df = 499) = 2449.4748, p-val < .0001\n\nModel Results:\n\nestimate      se     zval    pval   ci.lb   ci.ub      \n  0.3487  0.0347  10.0467  <.0001  0.2807  0.4167  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nSimilarly we can fit the corresponding model having the raw data to see the parameters estimated:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- sim_3l_studies(k = 100, \n                      j = 5, \n                      es = 0.3, \n                      tau2_k = 0.1, \n                      tau2_j = 0.05, \n                      n0 = 50, \n                      n1 = 50,\n                      raw = TRUE)\n\nget_es <- function(data){\n    dd <- data |> \n        group_by(x) |> \n        summarise(m = mean(y),\n                  sd = sd(y),\n                  n = n()) |> \n        pivot_wider(names_from = x, values_from = c(m, sd, n))\n    escalc(\"MD\", m1i = m_1, m2i = m_0, sd1i = sd_1, sd2i = sd_0, n1i = n_1, n2i = n_0,\n           data = dd)\n}\n\ndat_agg <- dat |> \n    group_by(paper, study) |> \n    nest() |> \n    mutate(es = map(data, get_es)) |> \n    unnest(es) |> \n    select(-data)\n\nfit3l <- rma.mv(yi, vi, random = ~1|paper/study, data = dat_agg)\nsummary(fit3l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 500; method: REML)\n\n   logLik   Deviance        AIC        BIC       AICc   \n-223.7331   447.4662   453.4662   466.1041   453.5147   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed       factor \nsigma^2.1  0.1053  0.3244    100     no        paper \nsigma^2.2  0.0602  0.2453    500     no  paper/study \n\nTest for Heterogeneity:\nQ(df = 499) = 2594.4472, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.2584  0.0354  7.3000  <.0001  0.1890  0.3277  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat$x <- factor(dat$x)\ncontrasts(dat$x) <- contr.sum(2)/2\n\nfit3l.lmer <- lmer_alt(y ~ x + (x||paper/study), data = dat)\nsummary(fit3l.lmer)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ x + (1 + re1.x1 || paper/study)\n   Data: data\n\nREML criterion at convergence: 143341\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9497 -0.6692 -0.0012  0.6658  4.0552 \n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n study.paper   re1.x1      0.05917  0.2432  \n study.paper.1 (Intercept) 0.01186  0.1089  \n paper         re1.x1      0.10547  0.3248  \n paper.1       (Intercept) 0.02764  0.1662  \n Residual                  1.00426  1.0021  \nNumber of obs: 50000, groups:  study:paper, 500; paper, 100\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)  0.13202    0.01789 98.97838   7.378 5.03e-11 ***\nx1          -0.25696    0.03540 99.00308  -7.258 8.96e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n   (Intr)\nx1 0.000 \noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00215331 (tol = 0.002, component 1)\n```\n\n\n:::\n:::\n\n\n\n\n# Multivariate meta-analysis\n\nAs introduced at the beginning the term multivariate is used here for data structure where the dependency arises from multiple effects being collected on the same pool of participants.\n\n![](https://raw.githubusercontent.com/shared-research/simulating-meta-analysis/refs/heads/main/documents/paper/img/multivariate.svg)\n\nFor example, in each primary study we did a group comparison (between two independent groups) on two measures. The two effect sizes are correlated because they are measured on the same participants.\n\nThe data structure is essentially the same but sampling errors are now correlated within clusters.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.mv <- expand.grid(\n    outcome = 1:2,\n    paper = 1:10\n)\n\nhead(dat.mv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  outcome paper\n1       1     1\n2       2     1\n3       1     2\n4       2     2\n5       1     3\n6       2     3\n```\n\n\n:::\n:::\n\n\n\nHow a single study looks like?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn0 <- 50\nn1 <- 50\n\nd <- c(0.3, 0.5)\n\nr <- 0.6\nR <- r + diag(1 - r, 2)\n\ng0 <- MASS::mvrnorm(n0, c(0, 0), R)\ng1 <- MASS::mvrnorm(n0, d, R)\n\nm0 <- apply(g0, 2, mean)\nm1 <- apply(g1, 2, mean)\n\nv0 <- apply(g0, 2, var)\nv1 <- apply(g1, 2, var)\n\nyi <- m1 - m0\nvi <- v0/n0 + v1/n1\nri <- cor(rbind(g0, g1))\nvvi <- diag(sqrt(vi)) %*% ri %*% diag(sqrt(vi))\nvvi <- data.frame(vvi)\nnames(vvi) <- c(\"v1i\", \"v2i\")\n\ncbind(yi, vi, vvi, n0, n1, outcome = c(1, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         yi         vi        v1i        v2i n0 n1 outcome\n1 0.5267601 0.03841446 0.03841446 0.02218897 50 50       1\n2 0.5152258 0.03490942 0.02218897 0.03490942 50 50       2\n```\n\n\n:::\n:::\n\n\n\n\nWe have two effects, two sampling variances and their correlation/covariance.\n\nFormally the model (for a single study) can be written as:\n\n\\begin{align}\n\\begin{gathered}\n\\begin{bmatrix}\ny_{1_i} \\\\\ny_{2_i} \\\\\ny_{3_i}\n\\end{bmatrix} \n=\n\\begin{bmatrix}\n\\mu_{{\\theta}_{1}} \\\\\n\\mu_{{\\theta}_{2}} \\\\\n\\mu_{{\\theta}_{3}}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\delta_{1_i} \\\\\n\\delta_{2_i} \\\\\n\\delta_{3_i}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\epsilon_{1_i} \\\\\n\\epsilon_{2_i} \\\\\n\\epsilon_{3_i}\n\\end{bmatrix}\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\begin{bmatrix}\n\\delta_{1_i} \\\\\n\\delta_{2_i} \\\\\n\\delta_{3_i}\n\\end{bmatrix}\n\\sim \\mathcal{MVN}(0, \\mathrm{T})\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\begin{bmatrix}\n\\epsilon_{1_i} \\\\\n\\epsilon_{2_i} \\\\\n\\epsilon_{3_i}\n\\end{bmatrix}\n\\sim \\mathcal{MVN}(0, \\mathrm{V})\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\mathrm{T} = \\begin{bmatrix}\n\\tau_1^2 & & & \\\\\n\\rho_{21}\\tau_2\\tau_1 & \\tau_2^2 & & \\\\\n\\rho_{31}\\tau_3\\tau_1 & \\rho_{32}\\tau_3\\tau_2 & \\tau_3^2\n\\end{bmatrix}\n\\end{gathered}\n\\end{align}\n\n\\begin{align}\n\\begin{gathered}\n\\mathrm{V} = \\begin{bmatrix}\n\\sigma^2_{\\epsilon_1} & & & \\\\\n\\rho_{s_{21}}\\sigma_{\\epsilon_2}\\sigma_{\\epsilon_1} & \\sigma^2_{\\epsilon_2} & & \\\\\n\\rho_{s_{31}}\\sigma_{\\epsilon_3}\\sigma_{\\epsilon_1} & \\rho_{s_{32}}\\sigma_{\\epsilon_3}\\sigma_{\\epsilon_2} & \\sigma^2_{\\epsilon_3}\n\\end{bmatrix}\n\\end{gathered}\n\\end{align}\n\nThe $\\mbox{V}$ matrix is the same that we created with `vcalc`. Basically is a block variance-covariance matrix with $k$ matrices (one for each paper/cluster) and number of rows/columns depending on how many outcomes are collected for each paper.\n\nThe $\\mbox{T}$ is a $p\\times p$ matrix with $p$ being the number of outcomes that represents the random-effects matrix. The diagonal is the true heterogeneity across studies for each outcome and the off-diagonal elements are the correlations between different outcomes across studies.\n\nThe multivariate model needs $\\mbox{V}$ (as the `vi` vector) and estimates $\\mbox{T}$ along with the vector of effect sizes.\n\nLet's see an example with the `dat.berkey1998` dataset (see also [https://www.metafor-project.org/doku.php/analyses:berkey1998](https://www.metafor-project.org/doku.php/analyses:berkey1998))\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dat.berkey1998\ndat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   trial           author year ni outcome      yi     vi    v1i    v2i \n1      1 Pihlstrom et al. 1983 14      PD  0.4700 0.0075 0.0075 0.0030 \n2      1 Pihlstrom et al. 1983 14      AL -0.3200 0.0077 0.0030 0.0077 \n3      2    Lindhe et al. 1982 15      PD  0.2000 0.0057 0.0057 0.0009 \n4      2    Lindhe et al. 1982 15      AL -0.6000 0.0008 0.0009 0.0008 \n5      3   Knowles et al. 1979 78      PD  0.4000 0.0021 0.0021 0.0007 \n6      3   Knowles et al. 1979 78      AL -0.1200 0.0014 0.0007 0.0014 \n7      4  Ramfjord et al. 1987 89      PD  0.2600 0.0029 0.0029 0.0009 \n8      4  Ramfjord et al. 1987 89      AL -0.3100 0.0015 0.0009 0.0015 \n9      5    Becker et al. 1988 16      PD  0.5600 0.0148 0.0148 0.0072 \n10     5    Becker et al. 1988 16      AL -0.3900 0.0304 0.0072 0.0304 \n```\n\n\n:::\n:::\n\n\n\n\n> Berkey et al. (1998) describe a meta-analytic multivariate model for the analysis of multiple correlated outcomes. The use of the model is illustrated with results from 5 trials comparing surgical and non-surgical treatments for medium-severity periodontal disease. Reported outcomes include the change in probing depth (PD) and attachment level (AL) one year after the treatment. The effect size measure used for this meta-analysis was the (raw) mean difference, calculated in such a way that positive values indicate that surgery was more effective than non-surgical treatment in decreasing the probing depth and increasing the attachment level. \n\nWe need to create the `V` matrix:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nV <- vcalc(vi=1, cluster=author, rvars=c(v1i, v2i), data=dat)\nround(V, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]\n [1,] 0.007 0.003 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n [2,] 0.003 0.008 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000\n [3,] 0.000 0.000 0.006 0.001 0.000 0.000 0.000 0.000 0.000 0.000\n [4,] 0.000 0.000 0.001 0.001 0.000 0.000 0.000 0.000 0.000 0.000\n [5,] 0.000 0.000 0.000 0.000 0.002 0.001 0.000 0.000 0.000 0.000\n [6,] 0.000 0.000 0.000 0.000 0.001 0.001 0.000 0.000 0.000 0.000\n [7,] 0.000 0.000 0.000 0.000 0.000 0.000 0.003 0.001 0.000 0.000\n [8,] 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.002 0.000 0.000\n [9,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.015 0.007\n[10,] 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.007 0.030\n```\n\n\n:::\n\n```{.r .cell-code}\nblsplit(V, dat$author, fun = round, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Pihlstrom et al.`\n      [,1]  [,2]\n[1,] 0.007 0.003\n[2,] 0.003 0.008\n\n$`Lindhe et al.`\n      [,1]  [,2]\n[1,] 0.006 0.001\n[2,] 0.001 0.001\n\n$`Knowles et al.`\n      [,1]  [,2]\n[1,] 0.002 0.001\n[2,] 0.001 0.001\n\n$`Ramfjord et al.`\n      [,1]  [,2]\n[1,] 0.003 0.001\n[2,] 0.001 0.002\n\n$`Becker et al.`\n      [,1]  [,2]\n[1,] 0.015 0.007\n[2,] 0.007 0.030\n```\n\n\n:::\n:::\n\n\n\n\nThen the model is the same as the three-level model with the ICC parametrization:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit.mv0 <- rma.mv(yi, V, random = ~outcome|trial, data = dat, struct = \"UN\")\nfit.mv0\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 10; method: REML)\n\nVariance Components:\n\nouter factor: trial   (nlvls = 5)\ninner factor: outcome (nlvls = 2)\n\n            estim    sqrt  k.lvl  fixed  level \ntau^2.1    0.3571  0.5976      5     no     AL \ntau^2.2    0.0356  0.1887      5     no     PD \n\n     rho.AL  rho.PD    AL  PD \nAL        1             -   5 \nPD  -0.6678       1    no   - \n\nTest for Heterogeneity:\nQ(df = 9) = 784.6078, p-val < .0001\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.2154  0.0592  3.6369  0.0003  0.0993  0.3315  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nWhat is missing is the fixed part. We are estimating an average outcome effect because we are not differentiating between outcomes. We just need to include `outcome` as a moderator:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit.mv1 <- rma.mv(yi, V, \n                  mods = ~ 0 + outcome, \n                  random = ~ outcome|trial, \n                  data = dat, struct = \"UN\")\nfit.mv1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 10; method: REML)\n\nVariance Components:\n\nouter factor: trial   (nlvls = 5)\ninner factor: outcome (nlvls = 2)\n\n            estim    sqrt  k.lvl  fixed  level \ntau^2.1    0.0327  0.1807      5     no     AL \ntau^2.2    0.0117  0.1083      5     no     PD \n\n    rho.AL  rho.PD    AL  PD \nAL       1             -   5 \nPD  0.6088       1    no   - \n\nTest for Residual Heterogeneity:\nQE(df = 8) = 128.2267, p-val < .0001\n\nTest of Moderators (coefficients 1:2):\nQM(df = 2) = 108.8616, p-val < .0001\n\nModel Results:\n\n           estimate      se     zval    pval    ci.lb    ci.ub      \noutcomeAL   -0.3392  0.0879  -3.8589  0.0001  -0.5115  -0.1669  *** \noutcomePD    0.3534  0.0588   6.0057  <.0001   0.2381   0.4688  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nNow we have the estimated treatment effect and the $\\mbox{T}$ matrix.\n\n## Multivariate as three-level model\n\nSometimes, the correlations between outcomes are missing and we need to put a plausible value. @Van_den_Noortgate2013-za showed that under some assumptions, fitting a three-level model (thus assuming independence) is actually estimating the effects and standard error in a similar way as the multivariate model including or guessing a correlation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit.mv1 <- rma.mv(yi, V, \n                  mods = ~ 0 + outcome, \n                  random = ~ outcome|trial, \n                  data = dat, \n                  struct = \"CS\")\n\nfit.mv.3l <- rma.mv(yi, \n                    vi, \n                    mods = ~ 0 + outcome, \n                    random = ~ 1|trial/outcome, \n                    data = dat)\n\n\n\nfit.mv1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 10; method: REML)\n\nVariance Components:\n\nouter factor: trial   (nlvls = 5)\ninner factor: outcome (nlvls = 2)\n\n            estim    sqrt  fixed \ntau^2      0.0250  0.1582     no \nrho        0.5290             no \n\nTest for Residual Heterogeneity:\nQE(df = 8) = 128.2267, p-val < .0001\n\nTest of Moderators (coefficients 1:2):\nQM(df = 2) = 79.9819, p-val < .0001\n\nModel Results:\n\n           estimate      se     zval    pval    ci.lb    ci.ub      \noutcomeAL   -0.3380  0.0782  -4.3229  <.0001  -0.4912  -0.1847  *** \noutcomePD    0.3636  0.0788   4.6163  <.0001   0.2092   0.5180  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nfit.mv.3l\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 10; method: REML)\n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed         factor \nsigma^2.1  0.0143  0.1196      5     no          trial \nsigma^2.2  0.0102  0.1012     10     no  trial/outcome \n\nTest for Residual Heterogeneity:\nQE(df = 8) = 124.9021, p-val < .0001\n\nTest of Moderators (coefficients 1:2):\nQM(df = 2) = 78.0792, p-val < .0001\n\nModel Results:\n\n           estimate      se     zval    pval    ci.lb    ci.ub      \noutcomeAL   -0.3323  0.0772  -4.3041  <.0001  -0.4836  -0.1810  *** \noutcomePD    0.3594  0.0780   4.6056  <.0001   0.2064   0.5123  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nThe advantage is that in the three-level model we are not imputing values.\n\n## Simulating data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_multi_meta <- function(k, \n                           p,\n                           mus,\n                           tau2s,\n                           ro = 0,\n                           rs = 0,\n                           n = NULL,\n                           sample_p = FALSE,\n                           sample_n = NULL,\n                           ranef = FALSE){\n    \n    RT <- ro + diag(1 - ro, p)\n    RS <- rs + diag(1 - rs, p)\n    S <- diag(sqrt(tau2s)) %*% RT %*% diag(sqrt(tau2s))\n    \n    TT <- MASS::mvrnorm(k, rep(0, p), S)\n    \n    yi <- vi <- deltai <- vvi <- vector(mode = \"list\", length = k)\n    \n    for(i in 1:k){\n        X0 <- MASS::mvrnorm(n, rep(0, p), RS)\n        X1 <- MASS::mvrnorm(n, mus + TT[i, ], RS)\n        mm0 <- apply(X0, 2, mean)\n        mm1 <- apply(X1, 2, mean)\n        \n        vv01 <- cov(X0)/n + cov(X1)/n\n        \n        yi[[i]] <- mm1 - mm0\n        vi[[i]] <- diag(vv01)\n        \n        vvi[[i]] <- vv01\n        deltai[[i]] <- TT[i, ]\n    }\n    \n    if(sample_p){\n        pi <- sample(1:p, k, replace = TRUE)\n    } else{\n        pi <- rep(p, k)\n    }\n    \n    study <- rep(1:k, each = p)\n    outcome <- rep(1:p, k)\n    \n    sim <- data.frame(\n        study,\n        outcome\n    )\n    \n    sim$yi <- unlist(yi)\n    sim$vi <- unlist(vi)\n    \n    vvi <- do.call(rbind, vvi)\n    vvi <- data.frame(vvi)\n    names(vvi) <- sprintf(\"v%si\", 1:ncol(vvi))\n    \n    sim <- cbind(sim, vvi)\n    \n    if(ranef){\n        sim$deltai <- unlist(deltai)\n    }\n    \n    # selecting studies\n    siml <- split(sim, sim$study)\n    for(i in 1:k){\n        siml[[i]] <- siml[[i]][1:pi[i], ]\n    }\n    sim <- do.call(rbind, siml)\n    sim$outcome <- factor(paste0(\"o\", sim$outcome))\n    rownames(sim) <- NULL\n    return(sim)\n}\n\ndat <- sim_multi_meta(k = 10, \n               p = 3, \n               mus = c(0, 0, 0), \n               tau2s = c(0.1, 0.1, 0.1), \n               ro = 0.5, \n               rs = 0.5, \n               n = 100)\n\nV <- vcalc(vi = 1, cluster = study, rvars = c(v1i, v2i, v3i), data = dat)\n\nfit.mv <- rma.mv(yi, \n                 V, \n                 mods = ~ 0 + outcome, \n                 random = ~ outcome|study, \n                 data = dat)\n\nfit.mv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 30; method: REML)\n\nVariance Components:\n\nouter factor: study   (nlvls = 10)\ninner factor: outcome (nlvls = 3)\n\n            estim    sqrt  fixed \ntau^2      0.0901  0.3002     no \nrho        0.3491             no \n\nTest for Residual Heterogeneity:\nQE(df = 27) = 174.6309, p-val < .0001\n\nTest of Moderators (coefficients 1:3):\nQM(df = 3) = 5.1281, p-val = 0.1627\n\nModel Results:\n\n           estimate      se    zval    pval    ci.lb   ci.ub    \noutcomeo1    0.2173  0.1043  2.0820  0.0373   0.0127  0.4218  * \noutcomeo2    0.1559  0.1049  1.4864  0.1372  -0.0497  0.3614    \noutcomeo3    0.0601  0.1050  0.5720  0.5673  -0.1457  0.2659    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nfit.mv.3l <- rma.mv(yi, \n                 vi, \n                 mods = ~ 0 + outcome, \n                 random = ~ 1|outcome/study, \n                 data = dat)\n\nfit.mv.3l\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 30; method: REML)\n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed         factor \nsigma^2.1  0.0202  0.1420      3     no        outcome \nsigma^2.2  0.0893  0.2989     30     no  outcome/study \n\nTest for Residual Heterogeneity:\nQE(df = 27) = 154.2751, p-val < .0001\n\nTest of Moderators (coefficients 1:3):\nQM(df = 3) = 2.4282, p-val = 0.4884\n\nModel Results:\n\n           estimate      se    zval    pval    ci.lb   ci.ub    \noutcomeo1    0.2168  0.1760  1.2315  0.2181  -0.1282  0.5618    \noutcomeo2    0.1560  0.1763  0.8847  0.3763  -0.1896  0.5016    \noutcomeo3    0.0633  0.1764  0.3589  0.7197  -0.2824  0.4091    \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}